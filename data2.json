[{"repo": "/bigclean/structure", "language": "C", "readme_contents": "Introduction\n==============\n\nSimple data structures practice.\n\nWhat included\n==============\n\n* c version, list(two implementions), stack and binary tree only.\n\n* java version, list, stack and binary tree only.\n\n* objective c version, list only.\n\n* cpp version, list only.\n\nNote\n=============\n\nBecuase these two language specific implemention is done in same period,\nso variable and functions names are mostly consistent.\n\nTodo\n==============\n\n* Add hashtable.\n\n* Add general tree.\n\n* Add ant build for java version.\n"}, {"repo": "/polarphp/polarphp", "language": "C++", "readme_contents": "<img width=\"350\" src =\"https://raw.githubusercontent.com/polarphp/polarphp/master/assets/images/polarphp.png?sanitize=true\"/>\n\n## Let the PHP language be great again \n\n## Why did I launch the `polarphp` project?\n\nWith the strong rise of `Go` and `NodeJS`, the market share of `PHP` has gradually been eroded, and the `PHP` official still sticks to the Web programming field. The more things you want to keep, the more you can't keep it. `polarphp` draws on the related features of `NodeJS` and `Go` to repackage `zendVM`, remove some of the old deprecated features and strong `Web` attributes of `PHP`, by implementing a new set of runtime framework `libpdk` , the `PHP` language is built into a true universal scripting language, empower `PHP`, let it have asynchronous programming, coroutine, thread, built-in `unicode` support, standard file `IO` and so on. So that the `PHP` programmer can not only do the `web` application, but also face the real server application. `polarphp` is not a new language, but a new compiler with runtime for the `PHP` language.\n\n## Main features\n\n- [ ] Compatible with the latest `PHP` language standard, removing obsolete language features\n- [ ] Built-in unicode standard support\n- [ ] Full-featured runtime library support, support for asynchronous programming, multi-threading and coroutine, etc.\n- [ ] Built-in package manager\n- [ ] Built-in document generator\n\n## Development plan\n\nDue to limited development resources, the development plan is tentatively scheduled as follows:\n\n1. Compile `zend VM` with `cmake` to generate `polarphp` custom version of `PHP` language virtual machine\n2. Language support project, language testing framework, porting `lit` test framework for `LLVM` project\n3. Implement `polarphp` driver to implement `PHP` code from the command line\n4. Regression testing of the `polarphp` virtual machine, tentatively running the language virtual machine related regression test of `PHP`\n5. Implement the built-in function of `polarphp`\n6. Publish the `docker` image of the core virtual machine\n7. Integrate the `libpdk` runtime framework\n8. Achieve user-friendly installation, try to install `polarphp` in a minimum of steps\n9. Implementation package manager\n10. Implement language widgets such as document generation tools, etc.\n\n## Start the experience\n\n> current we just test at macOS platform and you need run system in docker system.\n\n### clone polarphp repository\n```\ngit clone https://github.com/polarphp/polarphp.git\ncd polarphp\ngit submodule init\ngit submodule update\ngit checkout v0.0.1-alpha\n```\n### run build script\n```\n./devtools/scripts/build_polarphp.sh\n```\nAt this time, the script starts compiling the relevant image, which takes a long time. Please wait patiently. Wait for the compilation to complete, you run:\n```\ndocker images\n```\nAt this time, please confirm that there is the following docker image in the output:\n1. polarphp_base_env\n2. polarphp_debug\n\nIf there are no problems, we start testing whether polarphp is working properly in docker image.\n```\ndocker run --rm -it polarphp_debug\n```\nAfter entering the container, enter our polarphp command line program:\n```\npolar --version\n```\nIf you get the following output:\n```\npolarphp 0.0.1-git (built: 2019-01-27 12:22)\nCopyright (c) 2016-2018 The polarphp foundation (https://polar.foundation)\nZend Engine v3.3.0-dev, Copyright (c) 1998-2018 Zend Technologies\n```\n\nCongratulations, you have successfully compiled the polarphp runtime environment. When compiling the image, we put a test script in the ~/temp/ folder.\n```\nif (function_exists('\\php\\retrieve_version_str')) {\n    echo \"version str: \" . \\php\\retrieve_version_str() . \"\\n\";\n}\n\nif (function_exists('\\php\\retrieve_major_version')) {\n    echo \"major version: \" . \\php\\retrieve_major_version() . \"\\n\";\n}\n\nif (function_exists('\\php\\retrieve_minor_version')) {\n    echo \"minor version: \" . \\php\\retrieve_minor_version() . \"\\n\";\n}\n\nif (function_exists('\\php\\retrieve_patch_version')) {\n    echo \"patch version: \" . \\php\\retrieve_patch_version() . \"\\n\";\n}\n```\nYou can run the following command:\n```\npolar ~/temp/main.php\n```\nIf there are no errors, you will get the following output:\n\n```\nversion str: polarphp 0.0.1-git\nmajor version: 0\nminor version: 0\npatch version: 1\n```\nThank you for testing polarphp, what is the problem, you can put it in the github issue list\n\n## Community\n\nAt present, we only target Chinese users for the time being, so we use the communication method of WeChat and `QQ` group. The following is the QR code. Interested students can scan the code to join:\n\n> PS:Please indicate the scan code, for example: learn `polarphp` or `PHP` enthusiasts\n\n</div>\n<table>\n  <tbody>\n    <tr>\n      <td align=\"center\" valign=\"middle\">\n        <a href=\"https://www.oschina.net/\" target=\"_blank\">\n         <img width = \"200\" src=\"https://raw.githubusercontent.com/qcoreteam/zendapi/master/assets/images/qq.png\"/>\n        </a>\n      </td>\n      <td align=\"center\" valign=\"middle\">\n        <a href=\"https://gitee.com/?from=polarphp.org\" target=\"_blank\">\n          <img width = \"200\" src=\"https://raw.githubusercontent.com/qcoreteam/zendapi/master/assets/images/wechat.png\"/></div>\n        </a>\n      </td>\n    </tr><tr></tr>\n  </tbody>\n</table>\n\n## Currently has the following working groups\n\n1. Language core team\n2. Standard library team\n3. Ecosystem project team\n4. Document team\n5. Official website maintenance team\n\n## License\n\n`polarphp` is redeveloped on top of the `php` language project, following the agreement of the `php` project. For details, please see: [Project Agreement](/LICENSE)\n\n## Contribution code guidance\n===========================\n- [CODING_STANDARDS](CODING_STANDARDS)\n- [README.GIT-RULES](docs/README.GIT-RULES)\n- [README.MAILINGLIST_RULES](docs/README.MAILINGLIST_RULES)\n- [README.RELEASE_PROCESS](docs/README.RELEASE_PROCESS)\n\n## Acknowledgement\n<!--Acknowledgement begin-->\n<table>\n  <tbody>\n    <tr>\n      <td align=\"center\" valign=\"middle\">\n        <a href=\"https://www.oschina.net/\" target=\"_blank\">\n          <img width=\"177px\" src=\"https://raw.githubusercontent.com/polarphp/polarphp/master/assets/images/osc.svg?sanitize=true\">\n        </a>\n      </td>\n      <td align=\"center\" valign=\"middle\">\n        <a href=\"https://gitee.com/?from=polarphp.org\" target=\"_blank\">\n          <img width=\"177px\" src=\"https://raw.githubusercontent.com/polarphp/polarphp/master/assets/images/gitee.svg?sanitize=true\">\n        </a>\n      </td>\n      <td align=\"center\" valign=\"middle\">\n        <a href=\"http://www.hacknown.com/\" target=\"_blank\">\n          <img width=\"177px\" src=\"https://raw.githubusercontent.com/polarphp/polarphp/master/assets/images/hacknown.svg?sanitize=true\">\n        </a>\n      </td>\n    </tr><tr></tr>\n  </tbody>\n</table>\n<!--Acknowledgement end-->\n"}, {"repo": "/VirusTotal/c-vtapi", "language": "C", "readme_contents": "[![Build Status](https://travis-ci.org/VirusTotal/c-vtapi.svg?branch=travis)](https://travis-ci.org/VirusTotal/c-vtapi)\n\nVirusTotal C API library\nThis libary is designed to work with both the:\t\n\t* The public API https://www.virustotal.com/en/documentation/public-api/\n\t* The private API https://www.virustotal.com/en/documentation/private-api/\n\nRuntime Dependencies\n\t* curl or libcurl  (curl-devel package on some distributions)\n\t* janson version 2.2 (min) (2.5 or newer recommeded.  janson-devel on some distros)\n\nCompiling Dependencies\n\t* automake, autoconf  (might be autotools package on your platform)\n\t* gcc\n\t* libtool\n\nDebian or Ubuntu Dependencies:\n\tsudo apt-get install automake autoconf libtool libjansson-dev libcurl4-openssl-dev\n\nRedhat, Fedora, Centos or RPM based distros:\n\tyum install libtool jansson-devel\n\nTo compile on Linux, BSD, or Mac OS X:\n\nautoreconf -fi\n./configure\nmake\nsudo make install\n\nIf you wish to build the examples in the 'examples' directory:\nautoreconf -fi\n./configure --enable-examples\nmake\nsudo make install\n\nIf you have doxygen installed on your system you may optionally generate developer doxygen docs:\nmake doxygen-doc\n\nUsage on MS Windows is partially functioal now, but requires more patches to be fully supported.\n\nWindows compilation:\n\t* Installl mingw\n\t\t*  mingw32 gcc-g++\n\t\t*  mingw32-autoconf\n\t\t*  mingw32-automake\n\t* compile libcurl  (See their docs on windows compile)\n\nWindows compilation (MS Visual Studio)\n\t* install MS Visual Studio 2013\n\t* install CMake\n\t* Compile jansson  (see janson docs)\n\t* Compile curl  (see janson docs)\n\nSee Examples in the examples/ directory for some example test programs which use the API.\n\n\turl --apikey=YOUR_KEY --scan http://youtube.com\n\turl --apikey=YOUR_KEY --report http://youtube.com\n\n\tscan --help\n\t./scan --apikey YOUR_KEY --filescan /bin/ls\n\t./scan --apikey YOUR_KEY --report HASH\n"}, {"repo": "/airtrack/luna", "language": "C++", "readme_contents": "Linux & OSX: ![Build with clang](https://travis-ci.org/airtrack/luna.svg)\n\nLuna\n====\nAn interpreter of lua-like language written in C++ 11.\n\nBuild\n-----\n\n\tcmake -G \"Unix Makefiles\"\n\nor\n\n\tcmake -G Xcode\n\nAPI\n---\n\nGlobal function|Description\n---------------|-----------\nprint(...)|Print values to stdout\nputs(string)|Print a *string* to stdout\nipairs(table)|Returns a iterator to iterate array part of a *table*\npairs(table)|Returns a iterator to iterate a *table*(array and hash)\ntype(value)|Returns type of a *value*\ngetline()|Returns a line string which gets from stdin\nrequire(path)|Load the *path* module\n\nIO table|Description\n--------|-----------\nio.open(path [, mode])|Returns a file of *path* by *mode* when open success, otherwise returns nil and error description, *mode* is same with c function *fopen*, default is \"r\".\nio.stdin()|Returns a file of stdin\nio.stdout()|Returns a file of stdout\nio.stderr()|Returns a file of stderr\n\nFile table|Description\n----------|-----------\nfile:close()|Close file\nfile:flush()|Flush write buffer\nfile:read(...)|Read data from file, arguments could be number(read number bytes, returns as a string), \"\\*n\"(read a number and returns the number), \"\\*a\"(read whole file, returns as a string. Returns a empty string when on the end of file), \"\\*l\"(read a line, returns as a string without '\\\\n'), \"*L\"(read a line, returns as a string with '\\\\n'). Returns nil when on end of file.\nfile:seek([whence [, offset]])|Sets and gets the file position. *whence* could be \"set\", \"cur\", \"end\", *offset* is a number. If seek success, then returns the file position, otherwise returns nil and error description. Called with no argument, returns current position.\nfile:setvbuf(mode [, size])|Set the buffering mode for the output file. *mode* could be \"no\"(no buffering), \"full\"(full buffering), \"line\"(line buffering), *size* is a number specifies the size of the buffer, in bytes.\nfile:write(...)|Write the value of each argument to file, arguments could be string and number. If success, returns the file, otherwise returns nil and error description.\n\nMath table|Description\n----------|-----------\nmath.abs(x)|Same with c function *abs*\nmath.acos(x)|Same with c function *acos*\nmath.asin(x)|Same with c function *asin*\nmath.atan(x)|Same with c function *atan*\nmath.atan2(y, x)|Same with c function *atan2*\nmath.ceil(x)|Same with c function ceil\nmath.cos(x)|Same with c function *cos*\nmath.cosh(x)|Same with c function *cosh*\nmath.deg(x)|Returns the angle *x*(given in radians) in degrees.\nmath.exp(x)|Same with c function *exp*\nmath.floor(x)|Same with c function *floor*\nmath.frexp(x)|Same with c function *frexp*, returns significand of the given number in range of [0.5, 1) and exponent.\nmath.huge|The c macro HUGE_VAL\nmath.ldexp(m, e)|Same with c function *ldexp*\nmath.log(x [, base])|Same with c function *log*, the default for *base* is *e*.\nmath.max(x, ...)|Returns the maximum value\nmath.min(x, ...)|Returns the minimum value\nmath.modf(x)|Returns the integral part of *x* and the fractional part of *x*.\nmath.pi|The value of PI\nmath.pow(x, y)|Same with c function *pow*\nmath.rad(x)|Returns the angle(given in degrees) in radians.\nmath.random([m [, n]])|Returns a uniform pseudo-random number. When called with no arguments, returns a real number in the range [0, 1). When called with number *m*, returns a integer in the range [1, m]. When called with number *m* and *n*, returns a integer in the range [m, n].\nmath.randomseed(x)|Set *x* as the seed for the pseudo-random generator.\nmath.sin(x)|Same with c function *sin*\nmath.sinh(x)|Same with c function *sinh*\nmath.sqrt(x)|Same with c function *sqrt*\nmath.tan(x)|Same with c function *tan*\nmath.tanh(x)|Same with c function *tanh*\n\nString table|Description\n------------|-----------\nstring.byte(s [, i [, j]])|Returns the numerical codes of the characters s[*i*] to s[*j*]. The default value for *i* is 1.\nstring.char(...)|Returns a string with length equal to the number of arguments, in which each character has the numerical code equal to its corresponding argument.\nstring.len(s)|Returns the length of the string *s*.\nstring.lower(s)|Returns a string in which each character is lowercase.\nstring.upper(s)|Returns a string in which each character is uppercase.\nstring.reverse(s)|Returns a reverse string of the string *s*.\nstring.sub(s, i [, j])|Returns the substring of *s*[*i*..*j*].\n\nTable table|Description\n-----------|-----------\ntable.concat(t [, sep [, i [, j]]])|Concatenate *t*[*i*] .. *t*[*j*] to a string, insert *sep* between two elements, the default values for *i* is 1, *j* is #*t*, *sep* is an empty string.\ntable.insert(t, [pos ,] value)|Insert the *value* at position *pos*, by default, the *value* append to the table *t*. Returns true when insert success.\ntable.pack(...)|Pack all arguments into a table and returns it.\ntable.remove(t [, pos])|Remove the element at position *pos*, by default, remove the last element. Returns true when remove success.\ntable.unpack(t [, i [, j]])|Returns *t*[*i*] .. *t*[*j*] elements of table *t*, the default for *i* is 1, the default for *j* is #*t*.\n"}, {"repo": "/a-rodin/qstardict", "language": "C++", "readme_contents": "QStarDict is a StarDict clone written using Qt4. The user interface\nis similar to StarDict.\n\nMain features\n* Full support of StarDict dictionaries\n* Working in system tray\n* Scanning mouse selection and showing popup window with translation of the\n  selected word\n* Translations reformatting\n* Pronouncing translated word\n* Plugins support\n* KDE 4 plasmoid\n"}, {"repo": "/SharePoint/PnP-PowerShell", "language": "C#", "readme_contents": "\ufeff# SharePointPnP.PowerShell Commands #\n\n### Summary ###\nThis solution contains a library of PowerShell commands that allows you to perform complex provisioning and artifact management actions towards SharePoint. The commands use a combination of CSOM and REST behind the scenes, and can work against both SharePoint Online as SharePoint On-Premises.\n\n![SharePoint Patterns and Practices](https://devofficecdn.azureedge.net/media/Default/PnP/sppnp.png)\n  \n### Applies to ###\n-  Office 365 Multi Tenant (MT)\n-  Office 365 Dedicated (D)\n-  SharePoint 2013 on-premises\n-  SharePoint 2016 on-premises\n-  SharePoint 2019 on-premises\n\n### Prerequisites ###\nIn order to generate the Cmdlet help you need to have Windows Management Framework installed.\n\nIf it is not [pre-installed on your operating system](https://docs.microsoft.com/powershell/wmf/overview#wmf-availability-across-windows-operating-systems), you can find installation instructions in the [WMF release notes.](https://docs.microsoft.com/powershell/wmf/overview#wmf-release-notes)\n  \n### Solution ###\nSolution | Author(s)\n---------|----------\nSharePointPnP.PowerShell | Erwin van Hunen and countless community contributors\n\n### Disclaimer ###\n**THIS CODE IS PROVIDED *AS IS* WITHOUT WARRANTY OF ANY KIND, EITHER EXPRESS OR IMPLIED, INCLUDING ANY IMPLIED WARRANTIES OF FITNESS FOR A PARTICULAR PURPOSE, MERCHANTABILITY, OR NON-INFRINGEMENT.**\n\n\n----------\n\n# Commands included #\n[Navigate here for an overview of all cmdlets and their parameters](Documentation/readme.md)\n\n# Installation #\n\nThere are 2 ways to install the cmdlets. We recommend, where possible, to install them from the [PowerShell Gallery](https://www.powershellgallery.com). Check out the \"Getting Started with the Gallery\" section to make sure you have all requirements in place. Alternatively you can download the setup files and install the cmdlets directly.\n\n## PowerShell Gallery ##\n\nIf you main OS is Windows 10, or if you have [PowerShellGet](https://github.com/powershell/powershellget) installed, you can run the following commands to install the PowerShell cmdlets:\n\n|**SharePoint Version**|**Command to install**|\n|------------------|------------------|\n|SharePoint Online|```Install-Module SharePointPnPPowerShellOnline ```|\n|SharePoint 2019|```Install-Module SharePointPnPPowerShell2019```|\n|SharePoint 2016|```Install-Module SharePointPnPPowerShell2016```|\n|SharePoint 2013|```Install-Module SharePointPnPPowerShell2013```|\n\n*Notice*: if you install the latest PowerShellGet from Github, you might receive an error message stating \n>PackageManagement\\Install-Package : The version 'x.x.x.x' of the module 'SharePointPnPPowerShellOnline' being installed is not catalog signed.\n\nIn order to install the cmdlets when you get this error specify the -SkipPublisherCheck switch with the Install-Module cmdlet, e.g. ```Install-Module SharePointPnPPowerShellOnline -SkipPublisherCheck -AllowClobber```\n\n## Setup files ##\nYou can download the setup files from the [releases](https://github.com/officedev/pnp-powershell/releases) section of the PnP PowerShell repository. These files will up be updated on a monthly basis. Run the install and restart any open instances of PowerShell to use the cmdlets.\n\n# Updating #\nEvery month a new release will be made available of the PnP PowerShell Cmdlets. If you earlier installed the cmdlets using the setup file, simply download the [latest version](https://github.com/SharePoint/PnP-PowerShell/releases/latest) and run the setup. This will update your existing installation.\n\nIf you have installed the cmdlets using PowerShellGet with ```Install-Module``` from the PowerShell Gallery then you will be able to use the following command to install the latest updated version:\n\n```powershell\nUpdate-Module SharePointPnPPowerShell*\n``` \n\nThis will automatically load the module after starting PowerShell 3.0.\n\nYou can check the installed PnP-PowerShell versions with the following command:\n\n```powershell\nGet-Module SharePointPnPPowerShell* -ListAvailable | Select-Object Name,Version | Sort-Object Version -Descending\n```\n\n# Getting started #\n\nTo use the library you first need to connect to your tenant:\n\n```powershell\nConnect-PnPOnline \u2013Url https://yoursite.sharepoint.com \u2013Credentials (Get-Credential)\n```\n\nOr if you have Multi Factor Authentication enabled or if you are using a federated identity provider like AD FS, instead use:\n\n```powershell\nConnect-PnPOnline \u2013Url https://yoursite.sharepoint.com \u2013UseWebLogin\n```\n\nTo view all cmdlets, enter:\n\n```powershell\nGet-Command -Module *PnP*\n```\n\nAt the following links you will find a few videos on how to get started with the cmdlets:\n\n* https://channel9.msdn.com/blogs/OfficeDevPnP/PnP-Web-Cast-Introduction-to-Office-365-PnP-PowerShell\n* https://channel9.msdn.com/blogs/OfficeDevPnP/Introduction-to-PnP-PowerShell-Cmdlets\n* https://channel9.msdn.com/blogs/OfficeDevPnP/PnP-Webcast-PnP-PowerShell-Getting-started-with-latest-updates\n\n## Setting up credentials ##\nSee this [wiki page](https://github.com/OfficeDev/PnP-PowerShell/wiki/How-to-use-the-Windows-Credential-Manager-to-ease-authentication-with-PnP-PowerShell) for more information on how to use the Windows Credential Manager to setup credentials that you can use in unattended scripts.\n\n# Contributing #\n\nIf you want to contribute to this SharePoint Patterns and Practices PowerShell library, please [proceed here](CONTRIBUTING.md)\n\n## Building the source code ##\n\nIf you have set up the projects and you are ready to build the source code, make sure to build the SharePointPnP.PowerShellModuleFilesGenerator project first. This project will be executed after every build and it will generate the required PSD1 and XML files with cmdlet documentation in them.\n\nWhen you build the solution a postbuild script will copy the required files to a folder in your users folder called \n*C:\\Users\\\\\\<YourUserName\\>\\Documents\\WindowsPowerShell\\Modules\\SharePointPnPPowerShell\\<Platform\\>*. During build also the help and document files will be generated. If you have a session of PowerShell open in which you have used the PnP Cmdlets, make sure to close this PowerShell session first before you build. You will receive a build error otherwise because it tries to overwrite files that are in use.\n\nTo debug the cmdlets: launch PowerShell and attach Visual Studio to the powershell.exe process. In case you want to debug methods in PnP Sites Core, make sure that you open the PnP Sites Core project instead, and then attach Visual Studio to the powershell.exe. In case you see strange debug behavior, like it wants to debug PSReadLine.ps1, uninstall the PowerShell extension from Visual Studio.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/). For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n\n<img src=\"https://telemetry.sharepointpnp.com/pnp-powershell/readme\" /> \n"}, {"repo": "/google/kafel", "language": "C", "readme_contents": "# WHAT IS IT?\nKafel is a language and library for specifying syscall filtering policies.\nThe policies are compiled into BPF code that can be used with seccomp-filter.\n\nThis is NOT an official Google product.\n\n# Usage\n\n## With verbose error reporting\n```c\nstruct sock_fprog prog;\nkafel_ctxt_t ctxt = kafel_ctxt_create();\nkafel_set_input_string(ctxt, seccomp_policy);\nif (kafel_compile(ctxt, &prog)) {\n  fprintf(stderr, \"policy compilation failed: %s\", kafel_error_msg(ctxt));\n  kafel_ctxt_destroy(&ctxt);\n  exit(-1);\n}\nkafel_ctxt_destroy(&ctxt);\nprctl(PR_SET_SECCOMP, SECCOMP_MODE_FILTER, &prog, 0, 0);\nfree(prog.filter);\n```\n\n## Without verbose error reporting\n```c\nstruct sock_fprog prog;\nif (kafel_compile_string(seccomp_policy, &prog)) {\n  fputs(\"policy compilation failed\", stderr);\n  exit(-1);\n}\nprctl(PR_SET_SECCOMP, SECCOMP_MODE_FILTER, &prog, 0, 0);\nfree(prog.filter);\n```\n\n# Policy language\n\nA simple language is used to define policies.\n\nPolicy file consists of statements.\n\nA statement can be:\n * a constant definition\n * a policy definition\n * a policy definition statement\n * a default action statement\n\nPolicy definition statements placed at file scope will be added to the implicit\ntop level policy.\nThis top level policy is going to be compiled.\n\n## Default action statement\n\n```\nDEFAULT the_action\n```\n\nSpecifies that action `the_action` should be taken when no rule matches.\n\nThe default action must be specified just once.\n\nIf the policy file specifies no default actions, the default action will\nbe KILL\n\n## Numbers\n\nKafel supports following number notations:\n * Decimal `42`\n * Hexadecimal `0xfa1`\n * Octal `0777`\n * Binary `0b10101`\n\n## Constant definitions\n\nYou may define numeric constants to make your policies more readable.\nConstant definitions may be placed almost anywhere in the policy file.\nA constant definition cannot be placed inside of a policy definition.\nThe defined constants can then be used anywhere where a number is expected.\n\n```\n#define MYCONST 123\n```\n\n## Policy definitions\n\nPolicy definition is a list of action blocks and use statements separated by\ncommas.\n\n__samples/__ contains some example policies that demonstrate supported features.\n\n### Use statements\n\nA `USE someOtherPolicy` behaves as if `someOtherPolicy` body was pasted in its\nplace. You may only use policies defined before the use statement.\n\nWith use statements you can create meaningful groups of filtering rules that are\nbuilding blocks of bigger policies.\n\n### Action blocks\n\nAction block consist of a target and list of syscall matching rules separated\nwith commas.\n\nTarget of first rule matched is the policy decision.\n\nFollowing table list Kafel targets and their corresponding seccomp-filter\nreturn values.\n\nKafel                          | seccomp-filter\n------------------------------ | ---------------------------\n`ALLOW`                        | `SECCOMP_RET_ALLOW`\n`LOG`                          | `SECCOMP_RET_LOG`\n`KILL`, `KILL_THREAD`, `DENY`  | `SECCOMP_RET_KILL`\n`KILL_PROCESS`                 | `SECCOMP_RET_KILL_PROCESS`\n`USER_NOTIF`                   | `SECCOMP_RET_USER_NOTIF`\n`ERRNO(number)`                | `SECCOMP_RET_ERRNO+number`\n`TRAP(number)`                 | `SECCOMP_RET_TRAP+number`\n`TRACE(number)`                | `SECCOMP_RET_TRACE+number`\n\n### Syscall matching rules\n\nA rules consist of syscall name and optional list of boolean expressions.\n\nList of boolean expressions separated by commas.\nA comma is semantically equivalent to `||` but has the lowest precedence,\ntherefore it may be easier to read.\n\n#### Syscall naming\n\nNormally syscalls are specified by their names as defined in Linux kernel.\nHowever, you may also filter __custom syscalls__ that are not in the standard\nsyscall list.\nYou can either define a constant and use it in place of syscall name or\nutilize `SYSCALL` keyword.\n\n```\n#define mysyscall -1\n\nPOLICY my_const {\n  ALLOW {\n    mysyscall\n  }\n}\n\nPOLICY my_literal {\n  ALLOW {\n    SYSCALL[-1]\n  }\n}\n```\n\n#### Argument filtering\n\nBoolean expressions are used to filter syscalls based on their arguments.\nA expression resembles C language syntax, except that there are no\narithmetic operators.\n\n```\nsome_syscall(first_arg, my_arg_name) { first_arg == 42 && my_arg_name != 42 }\n```\n\nBitwise and (`&`) and or ('|') operators can be used to test for flags.\n\n```\nmmap { (prot & PROT_EXEC) == 0 },\nopen { flags == O_RDONLY|O_CLOEXEC }\n```\n\nYou don't have to declare arguments for well-known syscalls but can just use\ntheir regular names as specified in Linux kernel and `man` pages.\n\n```\nwrite { fd == 1 }\n```\n\n## Include directive\n\nIn order to simplify reuse and composition of policies, kafel provides include\nsupport.\n\n```\n#include \"some_other_file.policy\"\n```\n\nKafel looks for included files only under directories explicitly added to the\nsearch paths.\n\n```c\nkafel_include_add_search_path(ctxt, \"includes/path\");\n```\n\nAdds `includes/path` to search paths - the example include directive will refer\nthen to `includes/path/some_other_file.policy`.\n\nInclude directive is terminated by a newline or a semicolon.\nMultiple files, separated by whitespace, can be specified in one directive.\n\n```\n#include \"first.policy\" \"second.policy\"; #include \"third.policy\"\n```\n\n# Example\n\nWhen used with [nsjail](https://github.com/google/nsjail), the following command allows to create a fairly constrained environment for your shell\n\n```\n$ ./nsjail --chroot / --seccomp_string 'POLICY a { ALLOW { write, execve, brk, access, mmap, open, newfstat, close, read, mprotect, arch_prctl, munmap, getuid, getgid, getpid, rt_sigaction, geteuid, getppid, getcwd, getegid, ioctl, fcntl, newstat, clone, wait4, rt_sigreturn, exit_group } } USE a DEFAULT KILL' -- /bin/sh -i\n```\n```\n[2017-01-15T21:53:08+0100] Mode: STANDALONE_ONCE\n[2017-01-15T21:53:08+0100] Jail parameters: hostname:'NSJAIL', chroot:'/', process:'/bin/sh', bind:[::]:0, max_conns_per_ip:0, uid:(ns:1000, global:1000), gid:(ns:1000, global:1000), time_limit:0, personality:0, daemonize:false, clone_newnet:true, clone_newuser:true, clone_newns:true, clone_newpid:true, clone_newipc:true, clonew_newuts:true, clone_newcgroup:false, keep_caps:false, tmpfs_size:4194304, disable_no_new_privs:false, pivot_root_only:false\n[2017-01-15T21:53:08+0100] Mount point: src:'/' dst:'/' type:'' flags:0x5001 options:''\n[2017-01-15T21:53:08+0100] Mount point: src:'(null)' dst:'/proc' type:'proc' flags:0x0 options:''\n[2017-01-15T21:53:08+0100] PID: 18873 about to execute '/bin/sh' for [STANDALONE_MODE]\n/bin/sh: 0: can't access tty; job control turned off\n$ set\nIFS='\n'\nOPTIND='1'\nPATH='/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\nPPID='0'\nPS1='$ '\nPS2='> '\nPS4='+ '\nPWD='/'\n$ id\nBad system call\n$ exit\n[2017-01-15T21:53:17+0100] PID: 18873 exited with status: 159, (PIDs left: 0)\n```\n"}, {"repo": "/kimtg/arcadia", "language": "C", "readme_contents": "# Arcadia: An implementation of the Arc programming language #\r\n\r\nArc is a dialect of Lisp.\r\n\r\n## Build\r\n```\r\nmake\r\n```\r\n\r\nWith [readline](http://cnswww.cns.cwru.edu/php/chet/readline/rltop.html) support,\r\n```\r\nmake readline\r\n```\r\n\r\nWith [MinGW](http://www.mingw.org/),\r\n```\r\nmingw32-make mingw\r\n```\r\n\r\nFor Visual C++, use .sln file.\r\n\r\n## Run\r\n```\r\nUsage: arcadia [OPTIONS...] [FILES...]\r\n\r\nOPTIONS:\r\n    -h    print this screen.\r\n    -v    print version.\r\n```\r\n\r\n## Special form\r\n`assign do fn if mac quote`\r\n\r\n## Built-in\r\n`* + - / < > apply bound car ccc cdr close coerce cons cos disp err expt eval flushout infile int is len log macex maptable mod newstring outfile quit rand read readline scar scdr sin sqrt sread sref stderr stdin stdout string sym system t table tan trunc type write writeb`\r\n\r\n## Library\r\n`++ -- <= = >= aand abs accum acons adjoin afn aif alist all alref and andf assoc atend atom avg before best bestn caar cadr carif caris case caselet catch cddr check commonest compare complement compose consif conswhen copy copylist count counts cut dedup def do1 dotted drain each empty even fill-table find firstn flat for forlen get idfn iflet in insert-sorted insort insortnew intersperse isa isnt iso join keep keys last len< len> let list listtab loop map map1 mappend max med median mem memtable merge mergesort min mismatch most multiple n-of nearest no noisy-each nor nthcdr number obj odd on only ontable or orf pair point pop pos positive pr prn pull push pushnew quasiquote rand-choice rand-elt range reclist recstring reduce reinsert-sorted rem repeat retrieve rev rfn rotate round roundup rreduce set single some sort split sum summing swap tablist testify tuples trues union uniq unless until vals w/table w/uniq when whenlet while whiler whilet wipe with withs zap`\r\n\r\n## Features\r\n* Easy-to-understand mark-and-sweep garbage collection\r\n* Tail call optimization\r\n* Implicit indexing\r\n* [Syntax sugar](http://arclanguage.github.io/ref/evaluation.html) (`[]`, `~`, `.`, `!`, `:`)\r\n\r\n## See also\r\n* [Arc Tutorial](http://old.ycombinator.com/arc/tut.txt)\r\n* [Arc Documentation](http://arclanguage.github.io/ref/index.html)\r\n* [Try Arc: Arc REPL In Your Web Browser](http://tryarc.org/)\r\n\r\n## License ##\r\n\r\n   Copyright 2014-2019 Kim, Taegyoon\r\n\r\n   Licensed under the Apache License, Version 2.0 (the \"License\");\r\n   you may not use this file except in compliance with the License.\r\n   You may obtain a copy of the License at\r\n\r\n   [http://www.apache.org/licenses/LICENSE-2.0](http://www.apache.org/licenses/LICENSE-2.0)\r\n\r\n   Unless required by applicable law or agreed to in writing, software\r\n   distributed under the License is distributed on an \"AS IS\" BASIS,\r\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n   See the License for the specific language governing permissions and\r\n   limitations under the License.\r\n"}, {"repo": "/liudf0716/xkcptun", "language": "C", "readme_contents": "![xkcptun](https://github.com/liudf0716/xkcptun/blob/master/logo-big.png)\n\n[![Build Status][1]][2] \n[![Powered][3]][4]\n[![license][5]][6]\n[![PRs Welcome][7]][8]\n[![Issue Welcome][9]][10]\n[![OpenWRT][11]][12]\n[![KunTeng][13]][14]\n\n[1]: https://img.shields.io/travis/liudf0716/xkcptun.svg?style=plastic\n[2]: https://travis-ci.org/liudf0716/xkcptun\n[3]: https://img.shields.io/badge/KCP-Powered-blue.svg?style=plastic\n[4]: https://github.com/skywind3000/kcp\n[5]: https://img.shields.io/badge/license-GPLV3-brightgreen.svg?style=plastic\n[6]: https://github.com/KunTengRom/xfrp/blob/master/LICENSE\n[7]: https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=plastic\n[8]: https://github.com/liudf0716/xkcptun/pulls\n[9]: https://img.shields.io/badge/Issues-welcome-brightgreen.svg?style=plastic\n[10]: https://github.com/liudf0716/xkcptung/issues/new\n[11]: https://img.shields.io/badge/Platform-%20OpenWRT%20%7CLEDE%20%7CCentOS%20-brightgreen.svg?style=plastic\n[12]: https://github.com/gigibox/openwrt-xkcptun\n[13]: https://img.shields.io/badge/KunTeng-Inside-blue.svg?style=plastic\n[14]: http://rom.kunteng.org\n\n# xkcptun \u57fa\u4e8ekcp\u548clibevent2\u5e93\uff0c\u7528c\u8bed\u8a00\u5b9e\u73b0\u7684kcptun\n\nxkcptun\u4e3b\u8981\u5e94\u7528\u4e8eLEDE\uff0copenwrt\u4e2d\uff0c\u5176\u539f\u7406\u5982\u56fe\uff1a\n\n<img src=\"kcptun.png\" alt=\"kcptun\" height=\"300px\"/>\n\n### Compile\n\nxkcptun\u4f9d\u8d56[libevent2](https://github.com/libevent/libevent)\n\n\u5b89\u88c5libevent2\u5e93\u540e (apt-get install libevent-dev)\n\ngit clone https://github.com/liudf0716/xkcptun.git\n\ncd xkcptun\n\nmkdir build && cd build\n\ncmake .. (camke -DBUILD_STATIC_LINK=yes .. //\u9759\u6001\u94fe\u63a5)\n\nmake\n\n\n\u751f\u6210xkcp_client, xkcp_server, xkcp_spy\n\n#### \u53c2\u8003\u6587\u6863\n\n1, [\u5b89\u88c5libjson c\u7684\u95ee\u9898](https://github.com/liudf0716/xkcptun/wiki/%E5%AE%89%E8%A3%85libjson-c%E7%9A%84%E9%97%AE%E9%A2%98)\n\n2, [bbr vs kcp  \u4f18\u5316http\u4e0b\u8f7d\u6027\u80fd\u5bf9\u6bd4\u62a5\u544a](https://github.com/liudf0716/xkcptun/wiki/bbr-vs-kcp-%E4%BC%98%E5%8C%96http%E4%B8%8B%E8%BD%BD%E6%80%A7%E8%83%BD%E5%AF%B9%E6%AF%94%E6%8A%A5%E5%91%8A)\n\n3, [\u5982\u4f55\u5728centos\u4e0a\u90e8\u7f72xkcptun server](https://github.com/liudf0716/xkcptun/pull/11)\n\n### OpenWrt\n\u7f16\u8bd1\u53ca\u5b89\u88c5\u8bf7\u53c2\u8003 [openwrt-xkcptun](https://github.com/gigibox/openwrt-xkcptun)\n\n### QuickStart\n\n\u4e3a\u65b9\u4fbf\u7406\u89e3\u548c\u4f7f\u7528\uff0c\u6211\u4eec\u5c06\u4f7f\u7528\u573a\u666f\u653e\u5728\u540c\u4e00\u53f0pc\u4e0a\uff0cpc\u4f7f\u7528ubuntu\u7cfb\u7edf\uff0c\u6211\u4eec\u901a\u8fc7xkcptun\u6765\u8bbf\u95ee\u672c\u673a\u7684http server\n\n\u5047\u8bbepc\u7684 eth0 ip \u4e3a 192.168.199.18\uff0c http server\u7684\u76d1\u542c\u7aef\u53e3\u4e3a80\u7aef\u53e3\uff0cxkcptun\u7684server\u548cclient\u914d\u7f6e\u5206\u522b\u5982\u4e0b\uff1a\n\nserver.json \u5982\u4e0b\uff1a\n```\n{\n  \"localinterface\": \"eth0\",\n  \"localport\": 9089,\n  \"remoteaddr\": \"192.168.199.18\",\n  \"remoteport\": 80,\n  \"key\": \"14789632a\",\n  \"crypt\": \"none\",\n  \"mode\": \"fast3\",\n  \"mtu\": 1350,\n  \"sndwnd\": 1024,\n  \"rcvwnd\": 1024,\n  \"datashard\": 10,\n  \"parityshard\": 3,\n  \"dscp\": 0,\n  \"nocomp\": true,\n  \"acknodelay\": false,\n  \"nodelay\": 0,\n  \"interval\": 20,\n  \"resend\": 2,\n  \"nc\": 1,\n  \"sockbuf\": 4194304,\n  \"keepalive\": 10\n}\n```\n\nclient.json\u5982\u4e0b\uff1a\n```\n{\n  \"localinterface\": \"eth0\",\n  \"localport\": 9088,\n  \"remoteaddr\": \"192.168.199.18\",\n  \"remoteport\": 9089,\n  \"key\": \"14789632a\",\n  \"crypt\": \"none\",\n  \"mode\": \"fast3\",\n  \"mtu\": 1350,\n  \"sndwnd\": 1024,\n  \"rcvwnd\": 1024,\n  \"datashard\": 10,\n  \"parityshard\": 3,\n  \"dscp\": 0,\n  \"nocomp\": true,\n  \"acknodelay\": false,\n  \"nodelay\": 0,\n  \"interval\": 20,\n  \"resend\": 2,\n  \"nc\": 1,\n  \"sockbuf\": 4194304,\n  \"keepalive\": 10\n}\n```\n\n\u5206\u522b\u8fd0\u884c\uff1a\n\nxkcp_server -c server.json -f -d 7\n\nxkcp_client -c client.json -f -d 7\n\n\n[\u6ce8] \u4ee5\u4e0a\u547d\u4ee4\u90fd\u662f\u8fd0\u884c\u5728debug\u548c\u524d\u53f0\u8fd0\u884c\u6a21\u5f0f\uff0c\u6b63\u5f0f\u90e8\u7f72\u7684\u65f6\u5019\u8981\u628a -f \u53bb\u6389\uff0c -d 0 \u5982\uff1a xkcp_server -c server.json -d 0\n\ncurl http://192.168.199.18:9088\n\n\u5176\u6267\u884c\u6548\u679c\u4e0ecurl http://192.168.199.18 \u7b49\u540c\n\n\nxkcp_spy -h 192.168.199.18 -s -t status\n\n\u67e5\u770b\u670d\u52a1\u5668\u7aef\u7684\u60c5\u51b5\n\nxkcp_spy -h 192.168.199.18 -c -t status\n\n\u67e5\u770b\u5ba2\u6237\u7aef\u7684\u60c5\u51b5\n\n### Todo\n\nCompatible with [kcptun](https://github.com/xtaci/kcptun)  <img src=\"https://github.com/xtaci/kcptun/blob/master/logo-small.png\" alt=\"kcptun\" height=\"24px\" /> \n\n\n\n### How to contribute our project(\u7ed9\u672c\u9879\u76ee\u505a\u8d21\u732e)\n\n\n\u6b22\u8fce\u5927\u5bb6\u7ed9\u672c\u9879\u76ee\u63d0\u4f9b\u610f\u89c1\u548c\u8d21\u732e\uff0c\u63d0\u4f9b\u610f\u89c1\u7684\u65b9\u6cd5\u53ef\u4ee5\u5728\u672c\u9879\u76ee\u7684[Issues](https://github.com/liudf0716/xkcptun/issues/new)\u63d0\uff0c\u66f4\u52a0\u6b22\u8fce\u7ed9\u9879\u76ee\u63d0PULL REQUEST\uff0c\u5177\u4f53\u63d0\u4ea4PR\u7684\u65b9\u6cd5\u8bf7\u53c2\u8003[CONTRIBUTING](https://github.com/liudf0716/xkcptun/blob/master/CONTRIBUTING.md)\n\n\n### Contact me \n\nQQ\u7fa4 \uff1a [331230369](https://jq.qq.com/?_wv=1027&k=47QGEhL)\n\n"}, {"repo": "/yangxi0126/javaScript", "language": "JavaScript", "readme_contents": "# javaScript\n\u524d\u7aef\u7279\u6548\u5b58\u6863\n"}, {"repo": "/Cn33liz/p0wnedShell", "language": "C#", "readme_contents": "# p0wnedShell\n\nPowerShell Runspace Post Exploitation Toolkit \n\n![Alt text](/p0wnedShell/p0wnedShell.ico?raw=true \"p0wnedShell\")\n\n### Author: Cn33liz and Skons\n\nVersion: 2.6\nLicense: BSD 3-Clause\n\n### What is it:\n\np0wnedShell is an offensive PowerShell host application written in C# that does not rely on powershell.exe but runs powershell commands and functions within a powershell runspace environment (.NET). It has a lot of offensive PowerShell modules and binaries included to make the process of Post Exploitation easier.\nWhat we tried was to build an \u201call in one\u201d Post Exploitation tool which we could use to bypass all mitigations solutions (or at least some off), and that has all relevant tooling included. \nYou can use it to perform modern attacks within Active Directory environments and create awareness within your Blue team so they can build the right defense strategies.\n\n### How to Compile it:\n\nTo compile p0wnedShell you need to open this project within Microsoft Visual Studio and build it for the x64/x86 platform.\nYou can change the following AutoMasq options before compiling:\n\npublic static bool AutoMasq = true;\n\npublic static string masqBinary = @\"C:\\Windows\\Notepad.exe\";\n\n### How to use it:\n\nWith AutoMasq set to false, you just run the executable so it runs normally.\nWith AutoMasq enabled, you could rename the p0wnedShell executable as the process you're going to masquerade (masqBinary), so it has the appearance of that process (for example notepad.exe).\n\nUsing the optional \"-parent\" commandline argument, you can start p0wnedShell using another Parent Process ID.\nWhen combining the PEB Masq option and different parent process ID (for example svchost), you can give p0wnedShell the appearance of a legitimate service ;) \n\nNote: Running p0wnedShell using another Parent Process ID doesn't work from a Meterpreter session/shell.... yet!\n\n```\nChanging the Parent Process ID can also be used to spawn a p0wnedShell process with system privileges, \nfor example using lsass as the the parent process.\nFor this you need to have UAC elevated administrator permissions.\n\nC:\\p0wnedShell>p0wnedShellx64.exe -parent\n \n [+] Please enter a valid Parent Process name.\n [+] For Example: C:\\p0wnedShell\\p0wnedShellx64.exe -parent svchost\n \nC:\\p0wnedShell>p0wnedShellx64.exe -parent lsass\n```\n\nTo run as x86 binary and bypass Applocker (Credits for this great bypass go to Casey Smith aka subTee):\n\n```\ncd \\Windows\\Microsoft.NET\\Framework\\v4.0.30319 (Or newer .NET version folder)\n\nInstallUtil.exe /logfile= /LogToConsole=false /U C:\\p0wnedShell\\p0wnedShellx86.exe\n```\n\nTo run as x64 binary and bypass Applocker:\n\n```\ncd \\Windows\\Microsoft.NET\\Framework64\\v4.0.30319 (Or newer .NET version folder)\n\nInstallUtil.exe /logfile= /LogToConsole=false /U C:\\p0wnedShell\\p0wnedShellx64.exe\n```\n\n### What's inside the runspace:\n\n#### The following PowerShell tools/functions are included:\n\n* PowerSploit: Invoke-Shellcode\n* PowerSploit: Invoke-ReflectivePEInjection\n* PowerSploit: Invoke-Mimikatz\n* PowerSploit: Invoke-TokenManipulation\n* PowerSploit: PowerUp and PowerView\n* Rasta Mouse: Sherlock\n* HarmJ0y's: Invoke-Psexec and Invoke-Kerberoast\n* Rohan Vazarkar's: Invoke-BloodHound (C# Ingestor)\n* Chris Campbell's: Get-GPPPassword\n* Tim Medin's: GetUserSPNS\n* Besimorhino's: PowerCat\n* Nishang: Copy-VSS and Invoke-Encode\n* Nishang: Invoke-PortScan and Get-PassHashes\n* Kevin Robertson: Invoke-Tater, Invoke-SMBExec and Invoke-WMIExec\n* Kevin Robertson: Invoke-Inveigh and Invoke-InveighRelay\n* FuzzySecurity: Invoke-MS16-032 and Invoke-MS16-135\n\n\nPowershell functions within the Runspace are loaded in memory from\n[Base64 encode and compressed strings](https://github.com/Cn33liz/p0wnedShell/blob/master/Utilities/CompressString.cs).\n\n#### The following Binaries/tools are included:\n\n* Benjamin DELPY's Mimikatz\n* Benjamin DELPY's MS14-068 kekeo Exploit\n* Didier Stevens modification of ReactOS Command Prompt\n* MS14-058 Local SYSTEM Exploit\n* hfiref0x MS15-051 Local SYSTEM Exploit\n\nBinaries are loaded in memory using ReflectivePEInjection (Byte arrays are compressed using Gzip and saved within p0wnedShell as [Base64 encoded strings](https://github.com/Cn33liz/p0wnedShell/blob/master/Utilities/CompressString.cs)).\n\n### Shout-outs:\n\np0wnedshell is heavily based on tools and knowledge from people like harmj0y, the guys from Powersploit, Sean Metcalf, SubTee, Nikhil Mittal, Besimorhino, Benjamin Delpy, Breenmachine, FoxGlove Security, Kevin Robertson, FuzzySecurity, James Forshaw and anyone else i forgot. So shout-outs go to them and of course to our friends in Redmond for giving us access to a very powerfull hacking language.\n\n### Todo:\n\n* Tab completion within the shell using TabExpansion2.\n* More attacks (Kerberos Silver Tickets e.g.).\n* More usefull powershell modules.\n* Fix the console redirection when running p0wnedShell from a Meterpreter shell using a different Parent Process ID.\n\n### Contact:\n\nTo report an issue or request a feature, feel free to contact me at:\nCornelis ```at``` dePlaa.com or [@Cn33lis](https://twitter.com/Cneelis)\n\n"}, {"repo": "/gregtour/duck-lang", "language": "C", "readme_contents": "# Duck Programming Language      ![Build Status](https://travis-ci.org/gregtour/duck-lang.svg?branch=master)\nA simple scripting language based on the idea of duck-typing (or dynamic typing). \n\n>&ldquo;When I see a bird that walks like a duck and swims like a duck and quacks like a duck, I call that bird a duck.&rdquo;\n> &mdash; James Whitcomb Riley\n\n## Language Features\n\nThe duck programming language supports first-class functions, integer and floating-point arithmetic, string manipulation, dynamically-sized arrays, dictionary types, and basic object oriented programming. The syntax is strongly reminiscent of BASIC, Lua, or Python. While indentation is not strictly specified, the language requires specific whitespace in required newlines at the end of certain statements. Duck is currently only implemented in the form of a slow, interpreted frontend, making it useful as a portable scripting language. This frontend has been developed entirely in C.\n\nThe syntax of loops is somewhat different than in BASIC or other languages. For example, a while loop has the following syntax:\n```\nwhile (condition) do\n\t// loop body\n\t// ...\nloop\n```\nwhile a for loop in Duck looks like this\n```\nfor i = 1 to 10 do\n    // iterated instructions\n    // ...\n    // ...\nloop\n```\nNotice the use of the syntax \\`do' and \\`loop.' &nbsp;There are a number of other example programs in the _examples_ directory of the source repository.\n\nThe programming language's grammar is represented below in Backas-Naur form. The duck language has its own parser-generator, generating SLR(1) parse tables, so it is relatively easy to change the syntax of the language. Other optional ways to configure the language include disabling case-sensitivity or changing the format of comments, which are currently implemented as `/* C-style block comments */`, `// full line comments`, `; semicolon until end of line comments`, and `# any macro use`.\n\nIt is easy to port libraries to Duck. Function hooks are implemented as pointers, of the form `int (function_pointer)(int)` where the argument count is passed as the only parameter. Arguments are bound as string identifiers, and are accessed dynamically in the bound-function's body.\n\nExample:\n```c\nvoid BindStandardLibrary()\n{\n    VALUE duckStdLib = LinkNamespace(\"duck\");\n\n    VALUE print = CreateFunction(DuckPrint);\n    AddParameter(print, \"output\");\n    \n    LinkFunction(duckStdLib, \"print\", print);\n    LinkFunction(duckStdLib, \"println\", print);\n\n    VALUE prompt = CreateFunction(DuckPrompt);\n    LinkFunction(duckStdLib, \"prompt\", prompt);\n}\n```\n\nAs an example of what a typical program might look like written in Duck, the following is an example of computing prime numbers.\n\n```\nfunction display_primes(limit)\n\tcount = 0\n\tnumbers = []\n\tfor i = 2 to limit do\n\t\tnumbers[i] = 1\n\tloop\n\tfor i = 2 to limit do\n\t\tif numbers[i] == 1 then\n\t\t\tcount = count + 1\n\t\t\tfor j = 2 to limit/i do\n\t\t\t\tnumbers[i*j] = 0\n\t\t\tloop\n\t\t\tduck.print(i)\n\t\tend\n\tloop\nend\n```\n\n## Context free grammar\n```\n<program> ::= <stmt list>\n<stmt list> ::= <stmt list> <stmt>\n<stmt list> ::= <epsilon>\n<stmt> ::= import <identifier>\n<stmt> ::= call <reference>\n<stmt> ::= <endl>\n<stmt> ::= <expr> <endl>\n<stmt> ::= <assignment> <endl>\n<stmt> ::= <function def> <endl>\n<stmt> ::= <if> <endl>\n<stmt> ::= <if else> <endl>\n<stmt> ::= <for loop> <endl>\n<stmt> ::= <while loop> <endl>\n<stmt> ::= return <expr> <endl>\n<stmt> ::= break <endl>\n<stmt> ::= continue <endl>\n<function def> ::= function <identifier> <parameters> <endl> <stmt list> end\n<parameters> ::= <epsilon>\n<parameters> ::= ( )\n<parameters> ::= (<param decl>)\n<param decl> ::= <identifier>\n<param decl> ::= <param decl>, <identifier>\n<if> ::= if <condition> then <endl> <stmt list> end\n<if else> ::= if <condition> then <endl> <stmt list> else <endl> <stmt list> end\n<for loop> ::= for <identifier> = <arithmetic> to <arithmetic> do <endl> <stmt list> loop\n<while loop> ::= while <condition> do <endl> <stmt list> loop\n<assignment> ::= <l-value> = <assignment>\n<assignment> ::= <l-value> = <condition>\n<l-value> ::= <identifier>\n<l-value> ::= ( <l-value> )\n<l-value> ::= <reference> . <identifier>\n<l-value> ::= <reference> [ <expr> ]\n<expr> ::= <condition>\n<condition> ::= <condition> and <logic>\n<condition> ::= <condition> or <logic>\n<condition> ::= <condition> nor <logic>\n<condition> ::= <condition> xor <logic>\n<condition> ::= <logic>\n<logic> ::= not <comparison>\n<logic> ::= <comparison>\n<comparison> ::= <comparison> == <arithmetic>\n<comparison> ::= <comparison> != <arithmetic>\n<comparison> ::= <comparison> \\< <arithmetic>\n<comparison> ::= <comparison> > <arithmetic>\n<comparison> ::= <comparison> \\<= <arithmetic>\n<comparison> ::= <comparison> >= <arithmetic>\n<comparison> ::= <arithmetic>\n<arithmetic> ::= <arithmetic> + <term>\n<arithmetic> ::= <arithmetic> - <term>\n<arithmetic> ::= <arithmetic> & <term>\n<arithmetic> ::= <arithmetic> | <term>\n<arithmetic> ::= <term>\n<term> ::= <term> * <factor>\n<term> ::= <term> / <factor>\n<term> ::= <factor>\n<factor> ::= -<factor>\n<factor> ::= !<factor>\n<factor> ::= <final>\n<final> ::= ( <expr> )\n<final> ::= <boolean>\n<final> ::= <integer>\n<final> ::= <float>\n<final> ::= <string>\n<final> ::= <object>\n<final> ::= <reference>\n<reference> ::= <l-value>\n<reference> ::= <reference> ( )\n<reference> ::= <reference> ( <arguments> )\n<arguments> ::= <arguments>, <expr>\n<arguments> ::= <expr>\n<object> ::= [ ]\n<object> ::= [ <array init> ]\n<object> ::= [ <dictionary init> ]\n<array init> ::= <array init>, <expr>\n<array init> ::= <expr>\n<dictionary init> ::= <dictionary init>, <identifier> : <expr>\n<dictionary init> ::= <identifier> : <expr>\n<boolean> ::= true\n<boolean> ::= false\n\n```\n\n## Standard Library\nDuck has a standard library supporting both command-line input and output. See: stdduck.h.\nThere are also SDL and OpenGL bindings to support making a graphical window as well as draw calls.\n\nHere is a list of those functions:\n\n#### Library\n##### Duck\n* duck.print(output)\n* duck.println(output)\n* duck.prompt()\n\n##### SDL\n* SDL.MakeWindow(width, height, title, fullscreen)\n* SDL.flip()\n* SDL.event()\n* SDL.clearScreen()\n* SDL.running()\n* SDL.waitkey()\n* SDL.quit()\n\n##### GL\n* SDL.glLoadIdentity()\n* SDL.glTranslatef(x, y, z)\n* SDL.glRotatef(deg, x, y, z)\n* SDL.glScalef(x, y, z)\n* SDL.glBegin(primitive)\n* SDL.glColor3f(r, g, b)\n* SDL.glVertex3f(x, y, z)\n* SDL.glNormal3f(x, y, z)\n* SDL.glEnd()\n\n## Building\nDuck uses CMake 2.8. To build simply run:\n```\n> cmake .\n> make\n```\n\nBuilding gduck with SDL support requires SDL and OpenGL libraries. There are no platform specific libraries.\n\n## Credits\nGreg Tourville\n\nHiroyuki Sano\n\nRobert Cope\n\n\n## Future Work\n\n* Implementing a binary compiler\n* Memory management and garbage collection, to prevent crashes due to running out of memory\n* Optional, strongly/statically typed form of DUCK\n* Multithreaded parallelism &mdash; implicit or explicit through syntax analysis or library functions\n* Benchmark and profiling performance intrinsics\n* Expanding the standard library\n\n"}, {"repo": "/MicrosoftDocs/PowerShell-Docs", "language": "PowerShell", "readme_contents": "# Microsoft Open Source Code of Conduct\n\nThis project has adopted the\n[Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/). For more\ninformation see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or\ncomments.\n\n[live-badge]: https://powershell.visualstudio.com/PowerShell-Docs/_apis/build/status/PowerShell-Docs-CI?branchName=live\n[staging-badge]: https://powershell.visualstudio.com/PowerShell-Docs/_apis/build/status/PowerShell-Docs-CI?branchName=staging\n\n## Build Status\n\n| Live Branch | Staging Branch |\n|:------------|:---------------|\n| [![live-badge][]][live-badge] | [![staging-badge][]][staging-badge]\n\n## PowerShell Documentation\n\nWelcome to the PowerShell-Docs repository, housing the official PowerShell documentation.\n\n## Repository Structure\n\nEach of the following top-level folders in this repo contain a DocSet that is published to\n[Microsoft Docs](https://docs.microsoft.com/powershell).\n\n- [/reference/](https://docs.microsoft.com/powershell/scripting/) is for PowerShell conceptual\n  topics and module reference across versions 5.1, 6.0, and 7.0. This content is also the source of\n  help content retrieved by the `Get-Help` cmdlet.\n  - [docs-conceptual/](https://docs.microsoft.com/powershell) - this folder contains the conceptual\n    documentation and the following docsets:\n    - [developer/](https://docs.microsoft.com/powershell/scripting/developer/) is the PowerShell SDK\n      documentation (migrated from MSDN)\n    - [dsc/](https://docs.microsoft.com/powershell/scripting/dsc/) is for the Desired State\n      Configuration feature\n    - [gallery/](https://docs.microsoft.com/powershell/scripting/gallery) is for the\n      [PowerShell Gallery](https://www.powershellgallery.com/)\n    - [jea/](https://docs.microsoft.com/powershell/scripting/jea/) is for the Just Enough\n      Administration feature\n    - [wmf/](https://docs.microsoft.com/powershell/scripting/wmf/overview) contains release notes\n      for the Windows Management Framework, the package used to distribute new versions of\n      PowerShell to previous versions of Windows.\n\n## Contributing\n\nWe actively merge contributions into this repository via\n[pull request](https://help.github.com/articles/using-pull-requests/) into the *staging* branch.\nPlease note that before you submit a pull request you must\n[sign a Contribution License Agreement](https://cla.microsoft.com/) to ensure that the community is\nfree to use your submissions.\n\nFor more information on contributing, read our [contributor's guide](https://docs.microsoft.com/contribute/powershell/powershell-contribute). The\ncontributor's guide contains detail information about how to contribute documentation, suggested\ntools, and style and formatting requirements. Please use the Issue and Pull Request templates to\nhelp keep documentation consistent across versions.\n\n## Licenses\n\nThere are two license files for this project. The MIT License applies to the code contained in this\nrepo. The Creative Commons license applies to the documentation."}, {"repo": "/sunpinyin/sunpinyin", "language": "C++", "readme_contents": "SunPinyin\n===\n\nSunPinyin is an SLM (Statistical Language Model) based input method\nengine. To model the Chinese language, it uses a backoff bigram and\ntrigram language model.\n\nCurrently, SunPinyin 2.0 is available on IBus, SCIM, and as a\nstandalone XIM Server.\n\n[![Build Status](https://travis-ci.org/sunpinyin/sunpinyin.svg?branch=master)](https://travis-ci.org/sunpinyin/sunpinyin)\n"}, {"repo": "/plv8/plv8", "language": "C++", "readme_contents": "PLV8 - A Procedural Language in Javascript powered by V8\n=================================================\n\nPLV8 is a shared library that provides a PostgreSQL procedural language powered\nby V8 Javascript Engine.  With this program you can write in Javascript your\nfunction that is callable from SQL.\n\n## Installing\n\n    =# CREATE EXTENSION plv8;\n\nThis will install PLV8 into your database if it exists as an extension.\n\n## Testing\n\nTo test, you can execute:\n\n    =# DO $$ plv8.elog(NOTICE, \"hello there!\"); $$ LANGUAGE plv8;\n\nFor full documentation, see [https://plv8.github.io/](https://plv8.github.io/).\n"}, {"repo": "/redxu/sihook", "language": "C", "readme_contents": "\t\t\tSIHOOK\r\n=================================\r\nABOUT:\r\nsihook is a tabs plugin for source insight 3.x.\r\n\r\n\r\nBUILD:\r\nsihook is build with w32-gcc,sihook.cbp is a codeblocks project file.\r\nyou can also make it use Makefile,there's a simple one in the project.\r\n\r\n\r\nINSTALL:\r\ncopy msimg32.dll sihook.dll to source insight dir. \r\n"}, {"repo": "/bytedeco/javacv", "language": "Java", "readme_contents": "JavaCV\r\n======\r\n\r\n[![Gitter](https://badges.gitter.im/bytedeco/javacv.svg)](https://gitter.im/bytedeco/javacv) [![Maven Central](https://maven-badges.herokuapp.com/maven-central/org.bytedeco/javacv-platform/badge.svg)](https://maven-badges.herokuapp.com/maven-central/org.bytedeco/javacv-platform) [![Sonatype Nexus (Snapshots)](https://img.shields.io/nexus/s/https/oss.sonatype.org/org.bytedeco/javacv.svg)](http://bytedeco.org/builds/) [![Build Status](https://travis-ci.org/bytedeco/javacv.svg?branch=master)](https://travis-ci.org/bytedeco/javacv)\r\n\r\n\r\nIntroduction\r\n------------\r\nJavaCV uses wrappers from the [JavaCPP Presets](https://github.com/bytedeco/javacpp-presets) of commonly used libraries by researchers in the field of computer vision ([OpenCV](http://opencv.org/), [FFmpeg](http://ffmpeg.org/), [libdc1394](http://damien.douxchamps.net/ieee1394/libdc1394/), [PGR FlyCapture](https://www.ptgrey.com/flycapture-sdk), [OpenKinect](http://openkinect.org/), [librealsense](https://github.com/IntelRealSense/librealsense), [CL PS3 Eye Driver](https://codelaboratories.com/downloads/), [videoInput](http://muonics.net/school/spring05/videoInput/), [ARToolKitPlus](https://launchpad.net/artoolkitplus), [flandmark](http://cmp.felk.cvut.cz/~uricamic/flandmark/), [Leptonica](http://www.leptonica.org/), and [Tesseract](https://github.com/tesseract-ocr/tesseract)) and provides utility classes to make their functionality easier to use on the Java platform, including Android.\r\n\r\nJavaCV also comes with hardware accelerated full-screen image display (`CanvasFrame` and `GLCanvasFrame`), easy-to-use methods to execute code in parallel on multiple cores (`Parallel`), user-friendly geometric and color calibration of cameras and projectors (`GeometricCalibrator`, `ProCamGeometricCalibrator`, `ProCamColorCalibrator`), detection and matching of feature points (`ObjectFinder`), a set of classes that implement direct image alignment of projector-camera systems (mainly `GNImageAligner`, `ProjectiveTransformer`, `ProjectiveColorTransformer`, `ProCamTransformer`, and `ReflectanceInitializer`), a blob analysis package (`Blobs`), as well as miscellaneous functionality in the `JavaCV` class. Some of these classes also have an OpenCL and OpenGL counterpart, their names ending with `CL` or starting with `GL`, i.e.: `JavaCVCL`, `GLCanvasFrame`, etc.\r\n\r\nTo learn how to use the API, since documentation currently lacks, please refer to the [Sample Usage](#sample-usage) section below as well as the [sample programs](https://github.com/bytedeco/javacv/tree/master/samples/), including two for Android (`FacePreview.java` and `RecordActivity.java`), also found in the `samples` directory. You may also find it useful to refer to the source code of [ProCamCalib](https://github.com/bytedeco/procamcalib) and [ProCamTracker](https://github.com/bytedeco/procamtracker) as well as [examples ported from OpenCV2 Cookbook](https://github.com/bytedeco/javacv-examples/) and the associated [wiki pages](https://github.com/bytedeco/javacv-examples/tree/master/OpenCV_Cookbook).\r\n\r\nPlease keep me informed of any updates or fixes you make to the code so that I may integrate them into the next release. Thank you! And feel free to ask questions on [the mailing list](http://groups.google.com/group/javacv) if you encounter any problems with the software! I am sure it is far from perfect...\r\n\r\n\r\nDownloads\r\n---------\r\nArchives containing JAR files are available as [releases](https://github.com/bytedeco/javacv/releases). The binary archive contains builds for Android, iOS, Linux, Mac OS X, and Windows. The JAR files for specific child modules or platforms can also be obtained individually from the [Maven Central Repository](http://search.maven.org/#search|ga|1|bytedeco).\r\n\r\nTo install manually the JAR files, follow the instructions in the [Manual Installation](#manual-installation) section below.\r\n\r\nWe can also have everything downloaded and installed automatically with:\r\n\r\n * Maven (inside the `pom.xml` file)\r\n```xml\r\n  <dependency>\r\n    <groupId>org.bytedeco</groupId>\r\n    <artifactId>javacv-platform</artifactId>\r\n    <version>1.5.2</version>\r\n  </dependency>\r\n```\r\n\r\n * Gradle (inside the `build.gradle` file)\r\n```groovy\r\n  dependencies {\r\n    compile group: 'org.bytedeco', name: 'javacv-platform', version: '1.5.2'\r\n  }\r\n```\r\n\r\n * Leiningen (inside the `project.clj` file)\r\n```clojure\r\n  :dependencies [\r\n    [org.bytedeco/javacv-platform \"1.5.2\"]\r\n  ]\r\n```\r\n\r\n * sbt (inside the `build.sbt` file)\r\n```scala\r\n  libraryDependencies += \"org.bytedeco\" % \"javacv-platform\" % \"1.5.2\"\r\n```\r\n\r\nThis downloads binaries for all platforms, but to get binaries for only one platform we can set the `javacpp.platform` system property (via the `-D` command line option) to something like `android-arm`, `linux-x86_64`, `macosx-x86_64`, `windows-x86_64`, etc. Please refer to the [README.md file of the JavaCPP Presets](https://github.com/bytedeco/javacpp-presets#downloads) for details. Another option available for Scala users is [sbt-javacv](https://github.com/bytedeco/sbt-javacv).\r\n\r\n\r\nRequired Software\r\n-----------------\r\nTo use JavaCV, you will first need to download and install the following software:\r\n\r\n * An implementation of Java SE 7 or newer:\r\n   * OpenJDK  http://openjdk.java.net/install/  or\r\n   * Oracle JDK  http://www.oracle.com/technetwork/java/javase/downloads/  or\r\n   * IBM JDK  http://www.ibm.com/developerworks/java/jdk/\r\n\r\nFurther, although not always required, some functionality of JavaCV also relies on:\r\n\r\n * CL Eye Platform SDK (Windows only)  http://codelaboratories.com/downloads/\r\n * Android SDK API 21 or newer  http://developer.android.com/sdk/\r\n * JOCL and JOGL from JogAmp  http://jogamp.org/\r\n\r\nFinally, please make sure everything has the same bitness: **32-bit and 64-bit modules do not mix under any circumstances**.\r\n\r\n\r\nManual Installation\r\n-------------------\r\nSimply put all the desired JAR files (`opencv*.jar`, `ffmpeg*.jar`, etc.), in addition to `javacpp.jar` and `javacv.jar`, somewhere in your class path. Here are some more specific instructions for common cases:\r\n\r\nNetBeans (Java SE 7 or newer):\r\n\r\n 1. In the Projects window, right-click the Libraries node of your project, and select \"Add JAR/Folder...\".\r\n 2. Locate the JAR files, select them, and click OK.\r\n\r\nEclipse (Java SE 7 or newer):\r\n\r\n 1. Navigate to Project > Properties > Java Build Path > Libraries and click \"Add External JARs...\".\r\n 2. Locate the JAR files, select them, and click OK.\r\n\r\nIntelliJ IDEA (Android 5.0 or newer):\r\n\r\n 1. Follow the instructions on this page: http://developer.android.com/training/basics/firstapp/\r\n 2. Copy all the JAR files into the `app/libs` subdirectory.\r\n 3. Navigate to File > Project Structure > app > Dependencies, click `+`, and select \"2 File dependency\".\r\n 4. Select all the JAR files from the `libs` subdirectory.\r\n\r\nAfter that, the wrapper classes for OpenCV and FFmpeg, for example, can automatically access all of their C/C++ APIs:\r\n\r\n * [OpenCV documentation](http://docs.opencv.org/master/)\r\n * [FFmpeg documentation](http://ffmpeg.org/doxygen/trunk/)\r\n\r\n\r\nSample Usage\r\n------------\r\nThe class definitions are basically ports to Java of the original header files in C/C++, and I deliberately decided to keep as much of the original syntax as possible. For example, here is a method that tries to load an image file, smooth it, and save it back to disk:\r\n\r\n```java\r\nimport org.bytedeco.opencv.opencv_core.*;\r\nimport org.bytedeco.opencv.opencv_imgproc.*;\r\nimport static org.bytedeco.opencv.global.opencv_core.*;\r\nimport static org.bytedeco.opencv.global.opencv_imgproc.*;\r\nimport static org.bytedeco.opencv.global.opencv_imgcodecs.*;\r\n\r\npublic class Smoother {\r\n    public static void smooth(String filename) {\r\n        Mat image = imread(filename);\r\n        if (image != null) {\r\n            GaussianBlur(image, image, new Size(3, 3), 0);\r\n            imwrite(filename, image);\r\n        }\r\n    }\r\n}\r\n```\r\n\r\nJavaCV also comes with helper classes and methods on top of OpenCV and FFmpeg to facilitate their integration to the Java platform. Here is a small demo program demonstrating the most frequently useful parts:\r\n\r\n```java\r\nimport java.io.File;\r\nimport java.net.URL;\r\nimport org.bytedeco.javacv.*;\r\nimport org.bytedeco.javacpp.*;\r\nimport org.bytedeco.javacpp.indexer.*;\r\nimport org.bytedeco.opencv.opencv_core.*;\r\nimport org.bytedeco.opencv.opencv_imgproc.*;\r\nimport org.bytedeco.opencv.opencv_calib3d.*;\r\nimport org.bytedeco.opencv.opencv_objdetect.*;\r\nimport static org.bytedeco.opencv.global.opencv_core.*;\r\nimport static org.bytedeco.opencv.global.opencv_imgproc.*;\r\nimport static org.bytedeco.opencv.global.opencv_calib3d.*;\r\nimport static org.bytedeco.opencv.global.opencv_objdetect.*;\r\n\r\npublic class Demo {\r\n    public static void main(String[] args) throws Exception {\r\n        String classifierName = null;\r\n        if (args.length > 0) {\r\n            classifierName = args[0];\r\n        } else {\r\n            URL url = new URL(\"https://raw.github.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_alt.xml\");\r\n            File file = Loader.cacheResource(url);\r\n            classifierName = file.getAbsolutePath();\r\n        }\r\n\r\n        // We can \"cast\" Pointer objects by instantiating a new object of the desired class.\r\n        CascadeClassifier classifier = new CascadeClassifier(classifierName);\r\n        if (classifier == null) {\r\n            System.err.println(\"Error loading classifier file \\\"\" + classifierName + \"\\\".\");\r\n            System.exit(1);\r\n        }\r\n\r\n        // The available FrameGrabber classes include OpenCVFrameGrabber (opencv_videoio),\r\n        // DC1394FrameGrabber, FlyCapture2FrameGrabber, OpenKinectFrameGrabber, OpenKinect2FrameGrabber,\r\n        // RealSenseFrameGrabber, RealSense2FrameGrabber, PS3EyeFrameGrabber, VideoInputFrameGrabber, and FFmpegFrameGrabber.\r\n        FrameGrabber grabber = FrameGrabber.createDefault(0);\r\n        grabber.start();\r\n\r\n        // CanvasFrame, FrameGrabber, and FrameRecorder use Frame objects to communicate image data.\r\n        // We need a FrameConverter to interface with other APIs (Android, Java 2D, JavaFX, Tesseract, OpenCV, etc).\r\n        OpenCVFrameConverter.ToMat converter = new OpenCVFrameConverter.ToMat();\r\n\r\n        // FAQ about IplImage and Mat objects from OpenCV:\r\n        // - For custom raw processing of data, createBuffer() returns an NIO direct\r\n        //   buffer wrapped around the memory pointed by imageData, and under Android we can\r\n        //   also use that Buffer with Bitmap.copyPixelsFromBuffer() and copyPixelsToBuffer().\r\n        // - To get a BufferedImage from an IplImage, or vice versa, we can chain calls to\r\n        //   Java2DFrameConverter and OpenCVFrameConverter, one after the other.\r\n        // - Java2DFrameConverter also has static copy() methods that we can use to transfer\r\n        //   data more directly between BufferedImage and IplImage or Mat via Frame objects.\r\n        Mat grabbedImage = converter.convert(grabber.grab());\r\n        int height = grabbedImage.rows();\r\n        int width = grabbedImage.cols();\r\n\r\n        // Objects allocated with `new`, clone(), or a create*() factory method are automatically released\r\n        // by the garbage collector, but may still be explicitly released by calling deallocate().\r\n        // You shall NOT call cvReleaseImage(), cvReleaseMemStorage(), etc. on objects allocated this way.\r\n        Mat grayImage = new Mat(height, width, CV_8UC1);\r\n        Mat rotatedImage = grabbedImage.clone();\r\n\r\n        // The OpenCVFrameRecorder class simply uses the VideoWriter of opencv_videoio,\r\n        // but FFmpegFrameRecorder also exists as a more versatile alternative.\r\n        FrameRecorder recorder = FrameRecorder.createDefault(\"output.avi\", width, height);\r\n        recorder.start();\r\n\r\n        // CanvasFrame is a JFrame containing a Canvas component, which is hardware accelerated.\r\n        // It can also switch into full-screen mode when called with a screenNumber.\r\n        // We should also specify the relative monitor/camera response for proper gamma correction.\r\n        CanvasFrame frame = new CanvasFrame(\"Some Title\", CanvasFrame.getDefaultGamma()/grabber.getGamma());\r\n\r\n        // Let's create some random 3D rotation...\r\n        Mat randomR    = new Mat(3, 3, CV_64FC1),\r\n            randomAxis = new Mat(3, 1, CV_64FC1);\r\n        // We can easily and efficiently access the elements of matrices and images\r\n        // through an Indexer object with the set of get() and put() methods.\r\n        DoubleIndexer Ridx = randomR.createIndexer(),\r\n                   axisIdx = randomAxis.createIndexer();\r\n        axisIdx.put(0, (Math.random() - 0.5) / 4,\r\n                       (Math.random() - 0.5) / 4,\r\n                       (Math.random() - 0.5) / 4);\r\n        Rodrigues(randomAxis, randomR);\r\n        double f = (width + height) / 2.0;  Ridx.put(0, 2, Ridx.get(0, 2) * f);\r\n                                            Ridx.put(1, 2, Ridx.get(1, 2) * f);\r\n        Ridx.put(2, 0, Ridx.get(2, 0) / f); Ridx.put(2, 1, Ridx.get(2, 1) / f);\r\n        System.out.println(Ridx);\r\n\r\n        // We can allocate native arrays using constructors taking an integer as argument.\r\n        Point hatPoints = new Point(3);\r\n\r\n        while (frame.isVisible() && (grabbedImage = converter.convert(grabber.grab())) != null) {\r\n            // Let's try to detect some faces! but we need a grayscale image...\r\n            cvtColor(grabbedImage, grayImage, CV_BGR2GRAY);\r\n            RectVector faces = new RectVector();\r\n            classifier.detectMultiScale(grayImage, faces);\r\n            long total = faces.size();\r\n            for (long i = 0; i < total; i++) {\r\n                Rect r = faces.get(i);\r\n                int x = r.x(), y = r.y(), w = r.width(), h = r.height();\r\n                rectangle(grabbedImage, new Point(x, y), new Point(x + w, y + h), Scalar.RED, 1, CV_AA, 0);\r\n\r\n                // To access or pass as argument the elements of a native array, call position() before.\r\n                hatPoints.position(0).x(x - w / 10     ).y(y - h / 10);\r\n                hatPoints.position(1).x(x + w * 11 / 10).y(y - h / 10);\r\n                hatPoints.position(2).x(x + w / 2      ).y(y - h / 2 );\r\n                fillConvexPoly(grabbedImage, hatPoints.position(0), 3, Scalar.GREEN, CV_AA, 0);\r\n            }\r\n\r\n            // Let's find some contours! but first some thresholding...\r\n            threshold(grayImage, grayImage, 64, 255, CV_THRESH_BINARY);\r\n\r\n            // To check if an output argument is null we may call either isNull() or equals(null).\r\n            MatVector contours = new MatVector();\r\n            findContours(grayImage, contours, CV_RETR_LIST, CV_CHAIN_APPROX_SIMPLE);\r\n            long n = contours.size();\r\n            for (long i = 0; i < n; i++) {\r\n                Mat contour = contours.get(i);\r\n                Mat points = new Mat();\r\n                approxPolyDP(contour, points, arcLength(contour, true) * 0.02, true);\r\n                drawContours(grabbedImage, new MatVector(points), -1, Scalar.BLUE);\r\n            }\r\n\r\n            warpPerspective(grabbedImage, rotatedImage, randomR, rotatedImage.size());\r\n\r\n            Frame rotatedFrame = converter.convert(rotatedImage);\r\n            frame.showImage(rotatedFrame);\r\n            recorder.record(rotatedFrame);\r\n        }\r\n        frame.dispose();\r\n        recorder.stop();\r\n        grabber.stop();\r\n    }\r\n}\r\n```\r\n\r\nFurthermore, after creating a `pom.xml` file with the following content:\r\n```xml\r\n<project>\r\n    <modelVersion>4.0.0</modelVersion>\r\n    <groupId>org.bytedeco.javacv</groupId>\r\n    <artifactId>demo</artifactId>\r\n    <version>1.5.2</version>\r\n    <properties>\r\n        <maven.compiler.source>1.7</maven.compiler.source>\r\n        <maven.compiler.target>1.7</maven.compiler.target>\r\n    </properties>\r\n    <dependencies>\r\n        <dependency>\r\n            <groupId>org.bytedeco</groupId>\r\n            <artifactId>javacv-platform</artifactId>\r\n            <version>1.5.2</version>\r\n        </dependency>\r\n    </dependencies>\r\n    <build>\r\n        <sourceDirectory>.</sourceDirectory>\r\n    </build>\r\n</project>\r\n```\r\n\r\nAnd by placing the source code above in `Demo.java`, or similarly for other classes found in the [`samples`](samples), we can use the following command to have everything first installed automatically and then executed by Maven:\r\n```bash\r\n $ mvn compile exec:java -Dexec.mainClass=Demo\r\n```\r\n\r\n**Note**: In case of errors, please make sure that the `artifactId` in the `pom.xml` file reads `javacv-platform`, not `javacv` only, for example. The artifact `javacv-platform` adds all the necessary binary dependencies.\r\n\r\n\r\nBuild Instructions\r\n------------------\r\nIf the binary files available above are not enough for your needs, you might need to rebuild them from the source code. To this end, the project files were created for:\r\n\r\n * Maven 3.x  http://maven.apache.org/download.html\r\n * JavaCPP 1.5.2  https://github.com/bytedeco/javacpp\r\n * JavaCPP Presets 1.5.2  https://github.com/bytedeco/javacpp-presets\r\n\r\nOnce installed, simply call the usual `mvn install` command for JavaCPP, its Presets, and JavaCV. By default, no other dependencies than a C++ compiler for JavaCPP are required. Please refer to the comments inside the `pom.xml` files for further details.\r\n\r\nInstead of building the native libraries manually, we can run `mvn install` for JavaCV only and rely on the snapshot artifacts from the CI builds:\r\n\r\n * http://bytedeco.org/builds/\r\n\r\n\r\n----\r\nProject lead: Samuel Audet [samuel.audet `at` gmail.com](mailto:samuel.audet&nbsp;at&nbsp;gmail.com)  \r\nDeveloper site: https://github.com/bytedeco/javacv  \r\nDiscussion group: http://groups.google.com/group/javacv\r\n"}, {"repo": "/sony/v8eval", "language": "C++", "readme_contents": "# v8eval\n\n[![PyPI version](https://badge.fury.io/py/v8eval.svg)](http://badge.fury.io/py/v8eval)\n[![Gem Version](https://badge.fury.io/rb/v8eval.svg)](https://badge.fury.io/rb/v8eval)\n[![GoDoc](https://godoc.org/github.com/sony/v8eval/go/v8eval?status.svg)](http://godoc.org/github.com/sony/v8eval/go/v8eval)\n\nMulti-language bindings to JavaScript engine V8.\n\nCurrently v8eval provides Go, Python and Ruby bindings to the latest V8 7.1 and supports Linux and Mac OS X.\nv8eval uses SWIG and can be extended easily for other languages.\n\n## Pre-installation\n\n#### Linux\n\nSee [Dockerfile](https://github.com/sony/v8eval/blob/master/Dockerfile).\n\n#### Mac\n\nSee [.travis.yml](https://github.com/sony/v8eval/blob/master/.travis.yml).\n\n## Installation\n\nThe installation takes several tens of minutes due to V8 build.\n\n#### Go\n\nv8eval requires Go 1.10 or later.\n\n```\ngit clone https://github.com/sony/v8eval.git ${GOPATH}/src/github.com/sony/v8eval\n${GOPATH}/src/github.com/sony/v8eval/go/build.sh install\n```\n\nIn the case of Linux, you need to build your Go program with `build.sh`:\n\n```\n${GOPATH}/src/github.com/sony/v8eval/go/build.sh go build\n```\n\n#### Python\n\n```\npip install v8eval\n```\n\n#### Ruby\n\n```\ngem install v8eval\n```\n\n## Documentation\n\n#### Go\n\nSee [godoc.org](http://godoc.org/github.com/sony/v8eval/go/v8eval).\n\n#### Python\n\nYou can create the Sphinx documentation under python/docs.\n\n```\npython/build.sh docs\n```\n\n#### Ruby\n\nYou can create the YARD documentation under ruby/doc.\n\n```\nruby/build.sh docs\n```\n\n## Examples\n\n#### Go\n\n```go\nimport \"github.com/sony/v8eval/go/v8eval\"\n\nfunc Add(x, y int) int {\n\tvar v8 = v8eval.NewV8()\n\tv8.Eval(\"var add = (x, y) => x + y;\", nil)\n\n\tvar sum int\n\tv8.Call(\"add\", []int{x, y}, &sum)\n\treturn sum\n}\n```\n\n#### Python\n\n```python\nimport v8eval\n\ndef add(x, y):\n    v8 = v8eval.V8()\n    v8.eval('var add = (x, y) => x + y;')\n    return v8.call('add', [x, y])\n```\n\n#### Ruby\n\n```ruby\nrequire 'v8eval'\n\ndef add(x, y)\n  v8 = V8Eval::V8.new\n  v8.eval('var add = (x, y) => x + y;')\n  v8.call('add', [x, y])\nend\n```\n\n## License\n\nThe MIT License (MIT)\n\nSee [LICENSE](https://github.com/sony/v8eval/blob/master/LICENSE) for details.\n"}, {"repo": "/jondgoodwin/cone", "language": "C", "readme_contents": "# Cone Programming Language\nCone is a fast, fit, friendly, and safe systems programming language.\nIt features:\n\n- Do-it-your-way memory management\n- Versatile type system (incl. variant types and slices)\n- Memory, thread & type safe\n- Extensive code reuse features\n- Lean, native runtime\n- Concise, readable syntax\n\nThe Cone compiler is currently under development.\nThe current status and next steps are documented in [PLAN.md][plan].\n\n## Documentation and Other Resources\n\n - [Cone web site](http://cone.jondgoodwin.com)\n - [Web-based playground][playground], offering pre-built examples in a drop-down\n - [Cone Language Reference][coneref] documentation\n - [Programming Linguistics blog](http://pling.jondgoodwin.com)\n \nThe [Cone home repository](https://github.com/jondgoodwin/conehome)\noffers a rudimentary build environment for Cone programs,\nincluding the Congo build tool and additional example Cone programs.\n\n## Language Features\n\nWhen finished, Cone will support these features:\n\n- Readable, modular marriage of 3D content and behavior:\n  - Simple, outline-like declarative syntax for content\n  - Procedural generation and behavior interwoven in content\n  - Snap-together, Internet-hosted, url-located parts\n- Compile-time memory, type, and concurrency safety checks\n- [Gradual memory management][gmm]: safely manage memory your way\n  - Lexical, single-owner strategy for performance\n  - Ref-counted or tracing GC for flexibility\n  - Lifetime-constrained references for performance/simplicity\n  - Custom allocators (pools/arenas) for performance\n- Lightweight concurrency\n  - Co-routines, threads and actors\n  - Lockless and locked permissions for safe data sharing\n- Robust type system\n  - Sum types, structs, arrays, slices, ranges, aliases\n  - struct subtyping via trait, interface, & parent inheritance\n  - Attach methods to any type\n- Modules, macros, templates and meta-programming\n- Extensible pattern matching\n  - Type-defined '~~' match operator\n  - 'match' blocks using custom match methods\n  - Content extraction during matching\n- Functions, Methods and Closures\n  - Multiple return values and implicit return\n  - Computed properties\n- 'do' block for context management\n- Concise, readable code:\n  - 'this'-implied prefix operators for method cascading, etc.\n  - Operator overloading\n  - Control clauses for 'if', 'while', 'each'\n  - Type inference\n  - Parallel assignment\n  - Auto-detected off-side rule\n  - Blocks and 'if' are expressions\n- Unicode-aware (UTF8) text strings and variable names\n- Fast compilation and convenient packaging\n\n## Building (Windows)\n\nA Visual Studio C++ solution can be created using the Cone.vcxproj project file.\nThe generated object and executable files are created relative to the location of the \nsolutions file. The build depends on [LLVM 7][llvm] being installed and available at $(LLVMDIR).\n\n## Building (Linux)\n\nTo build on Linux:\n\n\tsudo apt-get install llvm-7.0-dev\n\tcmake .\n\tmake\n\nNote: To generate WebAssembly, it is necessary to custom-build LLVM, e.g.:\n\n\tmkdir llvm\n\tcd llvm\n\tsvn co http://llvm.org/svn/llvm-project/llvm/trunk llvm-src\n\tcd llvm-src/tools\n\tsvn co http://llvm.org/svn/llvm-project/cfe/trunk clang\n\tsvn co http://llvm.org/svn/llvm-project/lld/trunk lld\n\tcd ../..\n\tmkdir llvm-build\n\tcd llvm-build\n\tCC=clang CXX=clang++ cmake -G \"Unix Makefiles\" -DLLVM_BUILD_LLVM_DYLIB=ON -DCMAKE_INSTALL_PREFIX=/llvm/wasm -DLLVM_EXPERIMENTAL_TARGETS_TO_BUILD=WebAssembly /llvm/llvm-src\n\tmake\n\tmake install\n\n## Building (Mac OS)\n\nTo build on Mac OS:\n\n\tbrew install --with-toolchain llvm\n\tllvm-config --bindir\n\nCMake will auto-detect LLVM, so all you should need to do:\n\n\tcmake .\n\tmake\n\n## License\n\nThe Cone programming language compiler is distributed under the terms of the MIT license. \nSee LICENSE and COPYRIGHT for details.\n\n[3dweb]: http://cone.jondgoodwin.com/web3d.html\n[gmm]: http://jondgoodwin.com/pling/gmm.pdf\n[plan]: https://github.com/jondgoodwin/cone/blob/master/PLAN.md\n[coneref]: http://cone.jondgoodwin.com/coneref/index.html\n[showcase]: http://cone.jondgoodwin.com/coneref/showcase.html\n[playground]: http://cone.jondgoodwin.com/play/index.html\n[examples]: http://github.com/jondgoodwin/cone/tree/master/text\n[acorn]: https://github.com/jondgoodwin/acornvm\n[acornref]: http://web3d.jondgoodwin.com/acorn\n[llvm]: https://llvm.org/\n\n[hello]: http://cone.jondgoodwin.com/play/index.html?gist=f55a8caa2605a11223437167730c53af\n[pi]: http://cone.jondgoodwin.com/play/index.html?gist=4510655502edcde9d50d185cfd7f3c2e\n[perm]: http://cone.jondgoodwin.com/play/index.html?gist=96ecaecb4827c2b9e6aaad35feb2bfd1\n[struct]: http://cone.jondgoodwin.com/play/index.html?gist=cd702c7c1ffc8f97d7762735d04fd9de\n"}, {"repo": "/herrbischoff/awesome-command-line-apps", "language": null, "readme_contents": "<img src=\"https://cdn.rawgit.com/herrbischoff/awesome-command-line-apps/master/assets/logo.svg\" width=\"600\">\n\n> A curated list of useful command line apps, in celebration of the TUI.\n>\n> _\u201cKnowledge brings fear\u201d (Mars University Mission Statement)_\n\n[![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome) [![Build Status](https://travis-ci.org/herrbischoff/awesome-command-line-apps.svg?branch=master)](https://travis-ci.org/herrbischoff/awesome-command-line-apps)\n\nIf you want to contribute, you are highly encouraged to do so. Please read the [contribution guidelines](contributing.md).\n\n\n## Caffeinating\n\nWhen you find something helpful in here, you could buy me a coffee. I spend a lot of time and effort on curating this list. Keeping me properly caffeinated accelerates things. And it would really make my day. Kindness of strangers and all that. If you can't or won't, no hard feelings. It's available completely free for a reason. Still, it would be awesome.\n\n<a href=\"https://www.buymeacoffee.com/Oi5LPJ4lr\" target=\"_blank\"><img src=\"https://bmc-cdn.nyc3.digitaloceanspaces.com/BMC-button-images/custom_images/orange_img.png\" alt=\"Buy Me A Coffee\" style=\"height: auto !important;width: auto !important;\" ></a>\n\n\n## Contents\n\n- [\\*nix/\\*nux](#nixnux)\n    - [Automation](#automation)\n    - [Backup](#backup)\n    - [Benchmarking](#benchmarking)\n    - [Cloud Services](#cloud-services)\n    - [Compression](#compression)\n    - [Content Creation](#content-creation)\n    - [Conversion](#conversion)\n    - [Data Processing](#data-processing)\n    - [Databases](#databases)\n    - [Developer](#developer)\n    - [Dotfile Management](#dotfile-management)\n    - [Download Utilities](#download-utilities)\n    - [Email](#email)\n    - [Encryption](#encryption)\n    - [Filesystem Management](#filesystem-management)\n    - [FTP](#ftp)\n    - [Games](#games)\n    - [IRC](#irc)\n    - [Media](#media)\n    - [Miscellaneous](#miscellaneous)\n    - [Networking](#networking)\n    - [Presentation](#presentation)\n    - [Productivity](#productivity)\n    - [RSS](#rss)\n    - [Searching](#searching)\n    - [Security](#security)\n    - [SSH](#ssh)\n    - [System](#system)\n    - [Terminal](#terminal)\n    - [Text Editors](#text-editors)\n    - [Version Control](#version-control)\n    - [VPN](#vpn)\n    - [World Wide Web](#world-wide-web)\n- [BSD](#bsd)\n- [Linux](#linux)\n- [Mac OS X](#mac-os-x)\n- [Helpers](#helpers)\n\n\n## \\*nix/\\*nux\n\n### Automation\n\n- [Ansible](https://www.ansible.com) - Automate deployment, configuration, and upgrading.\n- [fswatch](https://github.com/emcrisostomo/fswatch) - Cross-platform file change monitor with multiple backends.\n\n### Backup\n\n- [Amanda](http://www.amanda.org) - Open Source Network Backup for Linux, Windows, UNIX and OS X.\n- [Attic](https://attic-backup.org) - Deduplicating backup program written in Python.\n- [Bacula](http://blog.bacula.org) - Manage backups, recovery, and verification of computer data across a network of computers of different kinds.\n- [BorgBackup](https://github.com/borgbackup/borg) - Significantly improved fork of Attic.\n- [duply](http://duply.net) - Easily create GPG encrypted, compressed backups of any data almost anywhere.\n- [mysqldump-secure](https://github.com/cytopia/mysqldump-secure) - Secure mysqldump script with encryption, compression, logging, blacklisting and Nagios monitoring integration.\n\n\n### Benchmarking\n\n- [hyperfine](https://github.com/sharkdp/hyperfine) - Benchmark commands through the command line.\n- [loadtest](https://github.com/alexfernandez/loadtest) - Runs a load test on the selected HTTP URL.\n- [pv](http://www.ivarch.com/programs/pv.shtml) - Terminal-based tool for monitoring the progress of data through a pipeline.\n- [siege](https://www.joedog.org/siege-home/) - http load testing and benchmarking utility.\n\n### Cloud Services\n\n- [awless](https://github.com/wallix/awless) - A mighty command line interface for Amazon Web Services.\n- [awscli](https://aws.amazon.com/cli/) - Official Amazon AWS command-line interface.\n- [cadaver](http://www.webdav.org/cadaver/) - Command-line WebDAV client for Unix.\n\n### Compression\n\n- [archivemount](http://www.cybernoia.de/software/archivemount.html) - FUSE filesystem using libarchive to mount archives.\n- [dtrx](https://github.com/moonpyk/dtrx) - Takes all the hassle out of extracting archives.\n\n### Content Creation\n\n- [GitBook](https://www.npmjs.com/package/gitbook) - Library and cmd utility to generate GitBooks.\n\n### Conversion\n\n- [binchunker](http://he.fi/bchunk/) - Converts a CD image in a \".bin / .cue\" format (sometimes \".raw / .cue\") to a set of .iso and .cdr tracks.\n- [Echo](https://github.com/misterGF/echo) - Convert HTML tables to JSON/CSVs.\n- [Pandoc](http://pandoc.org/) - A universal document converter.\n\n### Databases\n\n- [mycli](http://mycli.net) - Command line interface for MySQL, MariaDB, and Percona with auto-completion and syntax highlighting.\n- [pgcli](http://pgcli.com) - Command line interface for Postgres with auto-completion and syntax highlighting.\n\n### Data Processing\n\n- [datamash](https://www.gnu.org/software/datamash/) - Perform basic numeric, textual and statistical operations on textual data files.\n- [edcount](https://github.com/haroldfreeman/edcount) - Estimate distinct count of values from standard input.\n- [jq](https://stedolan.github.io/jq/) - Lightweight and flexible command-line JSON processor.\n\n### Developer\n\n- [bat](https://github.com/astaxie/bat) - Go implement CLI, cURL-like tool for humans.\n- [bcal](https://github.com/jarun/bcal) - Byte CALculator for storage conversions and calculations.\n- [bitwise](https://github.com/mellowcandle/bitwise) - Terminal based interactive bit manipulator in curses.\n- [caniuse-cmd](https://github.com/sgentle/caniuse-cmd) - All the power of caniuse.com with none of the GUI.\n- [clog](https://github.com/kentcdodds/clog-cli) - A conventional changelog for the rest of us.\n- [Cookiecutter](https://github.com/audreyr/cookiecutter) - Command-line utility that creates projects from cookiecutters (project templates).\n- [Critical](https://github.com/addyosmani/critical) - Extract & Inline Critical-path CSS in HTML pages.\n- [Grunt](http://gruntjs.com) - The JavaScript Task Runner.\n- [gulp](http://gulpjs.com) - Automate and enhance your build workflow.\n- [how2](https://github.com/santinic/how2) - stackoverflow from the terminal.\n- [http-prompt](https://github.com/eliangcs/http-prompt) - Interactive command-line HTTP client featuring autocomplete and syntax highlighting, built on HTTPie and prompt_toolkit.\n- [HTTPie](https://github.com/jkbrzt/httpie) - User-friendly cURL replacement featuring intuitive UI, JSON support, syntax highlighting, wget-like downloads, extensions, etc.\n- [penthouse](https://github.com/pocketjoso/penthouse) - Critical Path CSS Generator.\n- [Publoy](http://abhiomkar.github.io/publoy/) - Command line tool to deploy your static webapps via Dropbox.\n- [Rebound](https://github.com/shobrook/rebound) - Instantly fetch Stack Overflow results when you get a compiler error.\n- [saws](https://github.com/donnemartin/saws) - Supercharged AWS Command Line Interface.\n- [sift](https://sift-tool.org) - Fast and powerful open source alternative to grep.\n- [Yarn](https://yarnpkg.com) - Deterministic, secure alternative to npm.\n\n### Dotfile Management\n\n- [dotdrop](https://github.com/deadc0de6/dotdrop) - Save your dotfiles once, deploy them everywhere.\n- [homeshick](https://github.com/andsens/homeshick) - Git dotfiles synchronizer written in bash.\n\n### Download Utilities\n\n- [aria2](http://aria2.sourceforge.net) - Lightweight multi-protocol & multi-source command-line download utility.\n- [peerflix](https://github.com/mafintosh/peerflix) - Streaming torrent client for node.js.\n\n### Email\n\n- [abook](http://abook.sourceforge.net/) - text-based addressbook program designed to use with mutt mail client.\n- [Alpine](http://alpine.x10host.com/alpine/) - Fast, easy to use email client that is suitable for both the inexperienced email user as well as for the most demanding of power users.\n- [imapsync](https://github.com/imapsync/imapsync) - IMAP synchronisation, sync, copy or migration tool.\n- [isync](http://isync.sourceforge.net/) - Command line application to synchronize Maildir and IMAP4 mailboxes both ways.\n- [Mutt](http://www.mutt.org) - All mail clients suck. This one just sucks less.\n- [Notmuch](https://notmuchmail.org) - Fast, global-search and tag-based email system.\n- [OfflineIMAP](https://github.com/OfflineIMAP/offlineimap) - Two-way sync your e-mail mailboxes as a local Maildir.\n- [piler](http://www.mailpiler.org/wiki/start) - Feature rich open source email archiving solution, and a viable alternative to commercial email archiving products.\n- [Sup](https://github.com/sup-heliotrope/sup) - A curses threads-with-tags style email client.\n- [Terjira](https://github.com/keepcosmos/terjira) - Command line power tool for Jira.\n\n### Encryption\n\n- [EncFS](https://vgough.github.io/encfs/) - Provides an encrypted filesystem in user-space.\n- [GnuPG](https://www.gnupg.org) - Complete and free implementation of the OpenPGP standard as defined by RFC4880 (also known as PGP).\n\n### Filesystem Management\n\n- [FDUPES](https://github.com/adrianlopezroche/fdupes) - Identify or delete duplicate files residing within specified directories.\n- [Midnight Commander](http://www.midnight-commander.org) - Feature rich visual file manager.\n- [Ncdu](https://dev.yorhel.nl/ncdu) - Disk usage analyzer with an ncurses interface.\n- [ranger](http://ranger.nongnu.org/) - Minimalistic visual file manager featuring curses interface with VI key bindings.\n- [vifm](http://vifm.info) - ncurses based file manager with vi like keybindings/modes/options/commands/configuration, which also borrows some useful ideas from mutt.\n- [zfsnap](http://www.zfsnap.org/) - Rolling ZFS snapshots the easy way.\n\n### FTP\n\n- [CurlFtpFS](http://curlftpfs.sourceforge.net/) - Filesystem for accessing FTP hosts based on FUSE and libcurl.\n- [LFTP](http://lftp.tech/) - Sophisticated ftp/http client, and a file transfer program supporting a number of network protocols.\n- [NcFTP](http://www.ncftp.com/ncftp/) - A set of free application programs implementing the File Transfer Protocol (FTP).\n\n### Games\n\n- [Angband](http://rephial.org/) - Angband is a free, single-player dungeon exploration game.\n- [Cataclysm: Dark Days Ahead](http://en.cataclysmdda.com/) - Roguelike set in a post-apocalyptic world.\n- [Curse of War](https://a-nikolaev.github.io/curseofwar/) - Fast-paced real-time action strategy game.\n- [dopewars](http://dopewars.sourceforge.net) - Deal in drugs on the streets of New York, amassing a huge fortune and paying off the loan shark, while avoiding the ever-annoying police.\n- [Frotz](http://frotz.sourceforge.net/) - Interpreter for Infocom games and other Z-machine games.\n- [Nethack](http://nethack.org) - Single player dungeon exploration game that runs on a wide variety of computer systems.\n- [vitetris](http://www.victornils.net/tetris/) - Terminal-based Tetris clone, much like the early Tetris games by Nintendo.\n\n### IRC\n\n- [BitlBee](https://www.bitlbee.org/main.php/news.r.html) - IRC to other chat networks gateway.\n- [Irssi](https://github.com/irssi/irssi) - The client of the future.\n- [WeeChat](https://weechat.org/) - WeeChat is a fast, light and extensible chat client.\n\n### Media\n\n- [abcde](https://abcde.einval.com/wiki/) - A Better CD Encoder.\n- [AtomicParsely](http://atomicparsley.sourceforge.net/) - Lightweight command line program for reading, parsing and setting metadata into MPEG-4 files.\n- [Audiogrep](https://antiboredom.github.io/audiogrep/) - Creates audio supercuts.\n- [Beets](http://beets.io/) - The music geek's media organizer.\n- [cmus](https://cmus.github.io) - Small, fast and powerful console music player for Unix-like operating systems.\n- [FFmpeg](http://ffmpeg.org) - A complete, cross-platform solution to record, convert and stream audio and video.\n- [Gifsicle](http://www.lcdf.org/gifsicle/) - Command-line tool for creating, editing, and getting information about GIF images and animations.\n- [HandBrakeCLI](https://handbrake.fr) - Tool for converting video from nearly any format to a selection of modern, widely supported codecs.\n- [Legofy](https://github.com/JuanPotato/Legofy) - Python program that takes a static image or gif and makes it so that it looks as if it was built out of LEGO.\n- [MediaInfo](http://mediaarea.net/en/MediaInfo) - Convenient unified display of the most relevant technical and tag data for video and audio files.\n- [MKVToolNix](https://mkvtoolnix.download/) - A set of tools to create, alter and inspect Matroska files under Linux, other Unices and Windows.\n- [mopidy](https://www.mopidy.com/) - Self hosted MPD daemon that connects to Spotify and Soundcloud.\n- [moviemon](https://github.com/iCHAIT/moviemon) - Everything about your movies within the command line.\n- [mp3fs](https://khenriks.github.io/mp3fs/) - FUSE-based transcoding filesystem from FLAC to MP3.\n- [mp4v2](https://code.google.com/archive/p/mp4v2) - Library and tools to provide functions to read, create, and modify mp4 files.\n- [mpg123](http://mpg123.org) - Fast console MPEG Audio Player and decoder library.\n- [ncmpcpp](http://rybczak.net/ncmpcpp/) - NCurses based MPD client.\n- [OptiPNG](http://optipng.sourceforge.net) - PNG optimizer that recompresses image files to a smaller size, without losing any information.\n- [Pngcrush](http://pmt.sourceforge.net/pngcrush/) - An optimizer for PNG (Portable Network Graphics) files.\n- [Shellpic](https://github.com/larsjsol/shellpic) - Display images inline in the shell, ASCII-art is so 2013.\n- [subdownloader](https://github.com/beatfreaker/subdownloader) - Downloading subtitles for one or more files is just a command away.\n- [ttystudio](https://github.com/chjj/ttystudio) - A terminal-to-gif recorder minus the headaches.\n- [Video Transcoding Scripts](https://github.com/donmelton/video-transcoding-scripts) - Utilities to transcode, inspect and convert videos.\n- [Videogrep](https://antiboredom.github.io/videogrep/) - Automatic supercuts with python.\n- [youtube-dl](http://rg3.github.io/youtube-dl/) - A small command-line program to download videos from YouTube.com and a few more sites.\n\n### Miscellaneous\n\n- [ansiweather](https://github.com/fcambus/ansiweather) - Weather in your terminal, with ANSI colors and Unicode symbols.\n- [cointop](https://github.com/miguelmota/cointop) - Interactive cryptocurrency tracking.\n- [FIGlet](http://www.figlet.org) - Program for making large letters out of ordinary text.\n- [license](https://nishanths.github.io/license/) - Create LICENSEs from the command-line.\n- [pockyt](https://github.com/arvindch/pockyt) - composable [Pocket](https://getpocket.com) client for the terminal.\n- [wego](https://github.com/schachmat/wego/) - Weather client for the terminal.\n\n### Networking\n\n- [Bandwidth Monitor NG](https://www.gropp.org/?id=projects&sub=bwm-ng) - Small and simple console-based live network and disk io bandwidth monitor.\n- [Blucat](http://blucat.sourceforge.net/blucat/) - netcat for Bluetooth.\n- [gping](https://github.com/orf/gping) - Ping, but with a graph.\n- [iftop](http://www.ex-parrot.com/pdw/iftop/) - Display bandwidth usage on an interface.\n- [localtunnel](https://github.com/localtunnel/localtunnel) - Exposes your localhost to the world for easy testing and sharing.\n- [mtr](http://www.bitwizard.nl/mtr/) - Combines the functionality of the 'traceroute' and 'ping' programs in a single network diagnostic tool.\n- [Netcat](http://netcat.sourceforge.net) - Networking utility which reads and writes data across network connections, using the TCP/IP protocol.\n- [Nethogs](https://github.com/raboof/nethogs) - Linux 'net top' tool.\n- [ngrep](http://ngrep.sourceforge.net) - grep as a network packet analyzer.\n- [nmap](https://nmap.org) - Network discovery and security auditing utility.\n- [vnStat](http://humdi.net/vnstat/) - Console-based network traffic monitor for Linux and BSD that keeps a log of network traffic for the selected interface(s).\n\n### Presentation\n\n- [termui](https://github.com/gizak/termui) - Cross-platform, easy-to-compile, and fully-customizable terminal dashboard.\n- [WOPR](https://github.com/yaronn/wopr) - Simple markup language for creating rich terminal reports, presentations and infographics.\n\n### Productivity\n\n- [doing](http://brettterpstra.com/projects/doing/) - A command line tool for keeping track of what you\u2019re doing and tracking what you\u2019ve done.\n- [idea](https://github.com/IonicaBizau/idea) - Lightweight CLI tool and module for keeping ideas in a safe place quick and easy.\n- [ledger](http://ledger-cli.org) - Powerful, double-entry accounting system that is accessed from the UNIX command-line.\n- [MapSCII](https://github.com/rastapasta/mapscii) - OpenStreetMap client, renders an explorable Braille & ASCII world map.\n- [pdfgrep](https://pdfgrep.org) - Command line utility to search text in PDF files.\n- [pin-cushion](https://github.com/ELLIOTTCABLE/pin-cushion) - Simple, maintained CLI interface to the Pinboard.in API.\n- [Remind](https://www.roaringpenguin.com/products/remind) - Sophisticated calendar and alarm program.\n- [SC-IM](https://github.com/andmarti1424/sc-im) - An ncurses-based spreadsheet application.\n- [Taskwarrior](http://taskwarrior.org) - Free and Open Source Software that manages your TODO list from your command line.\n- [Timetrap](https://github.com/samg/timetrap) - Simple command line timetracker.\n- [Watson](http://tailordev.github.io/Watson/) - Elegant time tracking with a CLI.\n- [woof](http://www.home.unix-ag.org/simon/woof.html) - Simple one-off HTTP file sharing.\n\n### RSS\n\n- [newsbeuter](https://www.newsbeuter.org) - The Mutt of RSS feed readers.\n- [rss2email](http://www.allthingsrss.com/rss2email/) - A free, open-source tool for Windows and UNIX for getting news from RSS feeds in email.\n\n### Searching\n\n- [fd](https://github.com/sharkdp/fd) - fd is a simple, fast and user-friendly alternative to 'find'.\n- [fselect](https://github.com/jhspetersson/fselect) - 'find' replacement with SQL-like syntax.\n- [ripgrep](https://github.com/BurntSushi/ripgrep) - Recursively search directories for a regex pattern extremely fast.\n- [The Silver Searcher](http://geoff.greer.fm/ag/) - A blazingly fast tool for searching code.\n\n### Security\n\n- [Aircrack-ng](http://aircrack-ng.org) - 802.11 WEP and WPA-PSK keys cracking program that can recover keys once enough data packets have been captured.\n- [Let's Encrypt](https://letsencrypt.org) - A free, automated and open Certificate Authority.\n\n### SSH\n\n- [autossh](http://www.harding.motd.ca/autossh/) - Automatically restart SSH sessions and tunnels.\n- [sshfs](https://github.com/libfuse/sshfs) - Locally mount a remote folder via SSH.\n- [storm](http://stormssh.readthedocs.io/en/master/) - A command line tool to manage your ssh connections.\n\n### System\n\n- [ApacheTop](http://freecode.com/projects/apachetop) - Curses-based top-like display for Apache information, including requests per second, bytes per second, most popular URLs, etc.\n- [dstat](http://dag.wiee.rs/home-made/dstat/) - Versatile replacement for vmstat, iostat, netstat and ifstat.\n- [htop](http://hisham.hm/htop/) - An interactive process viewer.\n- [iotop](http://repo.or.cz/iotop.git) - Find out what's stressing and increasing load on your hard disks.\n- [maybe](https://github.com/p-e-w/maybe) - See what a program does before deciding whether you really want it to happen.\n- [netboot.xyz](https://netboot.xyz) - Boot multiple Operating System installers or utilities over the network from a single menu.\n- [screenFetch](https://github.com/KittyKatt/screenFetch) - Fetches system/theme information in terminal for desktop screenshots.\n\n### Terminal\n\n- [asciinema](https://asciinema.org) - Free and open source solution for recording terminal sessions and sharing them on the web.\n- [autojump](https://github.com/wting/autojump) - A cd command that learns - easily navigate directories from the command line.\n- [bgrep](http://debugmo.de/2009/04/bgrep-a-binary-grep/) - Like grep but for binary strings.\n- [byobu](http://byobu.co) - Text-based window manager and terminal multiplexer.\n- [ccat](https://github.com/jingweno/ccat) - Colorizing the cat command.\n- [cheat](https://github.com/chrisallenlane/cheat) - Create and view interactive cheatsheets on the command-line.\n- [desk](https://github.com/jamesob/desk) - Lightweight workspace manager for the shell.\n- [dit](https://github.com/vulpino/dit) - Dotfile manager that hooks into git.\n- [Fisherman](https://github.com/fisherman/fisherman) - A blazing fast, modern plugin manager for fish shell.\n- [fundle](https://github.com/tuvistavie/fundle) - Minimalist package manager for fish shell.\n- [fzf](https://github.com/junegunn/fzf) - A general-purpose command-line fuzzy finder.\n- [Marker](https://github.com/pindexis/marker) - The terminal command palette.\n- [MultiTail](https://www.vanheusden.com/multitail/) - Monitor logfiles and command output in multiple windows in a terminal, colorize, filter and merge.\n- [PathPicker](https://facebook.github.io/PathPicker/) - After parsing the output from a command, PathPicker presents you with a nice UI to select which files you're interested in.\n- [pick](https://github.com/calleerlandsson/pick) - Fuzzy select anything.\n- [SCREEN](http://www.guckes.net/Screen/) - A \"window manager\" for the console and terminals.\n- [tmux](https://tmux.github.io) - A terminal multiplexer.\n- [yank](https://github.com/mptre/yank) - Yank terminal output to clipboard.\n- [z](https://github.com/rupa/z) - Tracks your most used directories, based on 'frecency'.\n\n### Text Editors\n\n- [Diakonos](http://diakonos.pist0s.ca) - A linux editor for the masses.\n- [Emacs](https://www.gnu.org/software/emacs/) - An extensible, customizable text editor.\n- [Kakoune](http://kakoune.org) - Modal editor with multiple selections and orthogonal design.\n- [Neovim](https://neovim.io) - Modern version of the Vim editor with many advanced features.\n- [Vim](http://www.vim.org) - Advanced text editor that seeks to provide the power of the de-facto Unix editor 'Vi', with a more complete feature set.\n- [Vis](https://github.com/martanne/vis) - A highly efficient text editor.\n\n### Version Control\n\n- [Bazaar](http://bazaar.canonical.com/en/) - Easily manage source code on Windows, Ubuntu, GNU/Linux, and Mac OS X.\n- [fossil](https://fossil-scm.org) - Simple, high-reliability, distributed SCM with integrated bug tracking, wiki, forum, and technotes.\n- [Git](https://www.git-scm.com) - Git is a free and open source distributed version control system.\n- [gitfs](https://www.presslabs.com/gitfs/) - Version controlled file system.\n- [grv](https://github.com/rgburke/grv) - ncurses based text-mode Git repository browser.\n- [Mercurial](https://www.mercurial-scm.org) - Free, distributed source control management tool.\n- [tig](https://github.com/jonas/tig) - ncurses based text-mode interface for Git.\n\n### VPN\n\n- [OpenVPN](https://openvpn.net/index.php/open-source.html) - Full-featured open source SSL VPN solution.\n- [racoon](http://ipsec-tools.sourceforge.net) - Internet Key Exchange (IKE) daemon for automatically keying IPsec connections.\n- [strongSwan](https://www.strongswan.org/) - Open Source IPsec for Linux.\n\n### World Wide Web\n\n- [ELinks](http://elinks.or.cz) - Advanced and well-established feature-rich text mode web (HTTP/FTP/..) browser.\n- [GoAccess](https://goaccess.io) - Real-time visual web log analyzer and interactive viewer.\n- [googler](https://github.com/jarun/googler) - Google Search, Google Site Search, Google News from the terminal.\n- [pageres](https://github.com/sindresorhus/pageres) - Capture screenshots of websites in various resolutions.\n\n\n## BSD\n\n- [ezjail](http://erdgeist.org/arts/software/ezjail/) - Jail administration framework.\n- [iocage](https://iocage.io) - Convenient, Lightweight & Easy Container Management for jails.\n- [pkgsrc](http://www.pkgsrc.org) - Portable package build system.\n- [poudriere](https://github.com/freebsd/poudriere) - Port/Package build and test system.\n\n## Linux\n\n- [aptly](https://www.aptly.info/) -  Swiss army knife for Debian repository management.\n- [btrfs](https://btrfs.wiki.kernel.org/index.php/Main_Page) - Copy on write (CoW) filesystem for Linux aimed at implementing advanced features while focusing on fault tolerance, repair and easy administration.\n- [deborphan](http://freecode.com/projects/deborphan) - Finds packages installed on your Debian/GNU system that have no other packages depending on them.\n- [IPTraf](http://iptraf.seul.org) - Console-based network statistics utility for Linux.\n\n\n## Mac OS X\n\n- [Fink](http://www.finkproject.org) - The full world of Unix Open Source software for Darwin.\n- [Homebrew](http://brew.sh) - The missing package manager for OS X.\n- [itunes-remote](https://github.com/mischah/itunes-remote) - Control iTunes via CLI.\n- [MacPorts](https://www.macports.org) - Compile, install and upgrade either command-line, X11 or Aqua based open-source software.\n- [mas](https://github.com/mas-cli/mas) - Mac App Store command line interface.\n- [Night Shift Shell Utility](https://github.com/jenghis/nshift) - Simple shell utility to control the macOS Night Shift feature.\n- [reminders-cli](https://github.com/keith/reminders-cli) - A simple CLI for interacting with Reminders.\n- [tag](https://github.com/jdberry/tag) - Manipulate tags on files and query for files with those tags.\n- [XLD](http://tmkk.undo.jp/xld/index_e.html) - Tool to decode/convert/play various 'lossless' audio files.\n\n\n## Helpers\n\n- [crontab.guru](http://crontab.guru) - Cron schedule expression editor.\n\n\n## License\n\n<a rel=\"license\" href=\"https://creativecommons.org/licenses/by-sa/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://licensebuttons.net/l/by-sa/4.0/88x31.png\" /></a><br />This work is licensed under a <a rel=\"license\" href=\"https://creativecommons.org/licenses/by-sa/4.0/\">Creative Commons Attribution-ShareAlike 4.0 International License</a>.\n"}, {"repo": "/AutoHotkey/AutoHotkey", "language": "C++", "readme_contents": "# AutoHotkey\nAutoHotkey is a powerful and easy to use scripting language for desktop automation on Windows.  \nhttp://autohotkey.com/\n\n----\n\n### AutoHotkey v1.1\nIn late 2012, after consultation with the community, AutoHotkey_L became the official branch.  \nIt's source code can be found here: https://github.com/Lexikos/AutoHotkey_L  \nalong with the documentation here: https://github.com/Lexikos/AutoHotkey_L-Docs  \n"}, {"repo": "/StanzaOrg/lbstanza", "language": "C", "readme_contents": "# L.B. Stanza Programming Language\n\nL.B. Stanza (or Stanza for short) is a new optionally-typed general purpose programming language designed to help programmers tackle the complexity of architecting large programs and significantly increase the productivity of application programmers across the entire software development life cycle.\n\nVisit www.lbstanza.org for details.\n"}, {"repo": "/daw42/glslcookbook", "language": "C", "readme_contents": "\n:tada: **NEW** *The [3rd Edition is now available][cookbookv3]!!!* :tada:\n\nExample code from the [OpenGL Shading Language Cookbook, 2nd Edition][cookbook]\n=========================================================\n\nThe example code from the [OpenGL Shading Language Cookbook, 2nd Edition][cookbook],\nby David Wolff and published by Packt Publishing, 2013 (ISBN: 9781782167020).\n\nRecent changes:\n * Most examples now run on MacOS!\n * CMake build now uses package config files when finding GLM and GLFW.  This should make for a more\n streamlined configuration.  Use [`CMAKE_PREFIX_PATH`][cmake_prefix] to point CMake to your installs.\n * Examples now properly support high-density displays.\n\nRequirements\n-------------\nTo compile these examples, you'll need the following:\n\n* The [GLM Mathematics Library][GLM] version 0.9.6 or later.  Note that versions\n  prior to 0.9.6 may not work properly because of a switch from degrees to\n  radians.  GLM 0.9.5 will work, but you'll need to add `#define GLM_FORCE_RADIANS`\n  prior to including the glm header files.\n* [GLFW][] version 3.0 or later.\n\nCompiling the examples\n----------------------\nThe example code builds with [CMake][].  Note that the\nexamples for Chapter 10 will not function on MacOS due to lack of support for\ncompute shaders on that platform.\n\n1.  Install [GLFW][] by following the instructions on their [web site][GLFW].\n2.  Install the latest version of [GLM][].  Note that for [CMake][] to find GLM\n    correctly, you need to run the install \"build\" (e.g. `make install`) or install GLM from your\n    favorite package manager.  Otherwise, the CMake config files will not be created/available.\n3.  Download this example code from [github][ghcookbook], or clone using git.\n4.  Run cmake.  If cmake has difficulties finding the GLFW or GLM installations,\n    set the variable [`CMAKE_PREFIX_PATH`][cmake_prefix] to help cmake find them.\n5.  Compile by running `make`.\n\nAny problems, [create an issue](https://github.com/daw42/glslcookbook/issues) on [github][ghcookbook].\n\nTips for compiling for Windows with Visual Studio\n---------------------------------------------\n* Use the Visual Studio target in [CMake][]:  `-G \"Visual Studio...\"`, open the\n  Visual Studio solution.  You should see one project per chapter.\n* Each chapter requires a command line argument to choose a recipe.  When\n  running in VS, be sure to set the 'Command Argument' under 'Properties' for\n  the appropriate recipe.\n\nOpenGL Function Loading\n-----------------------\n\nAn OpenGL header file and a function loader for a 4.3 core profile are\nincluded with this project.  They were generated using\n[GLAD][].  This loader should also work on MacOS under a 4.1 core profile, but of course not all functions will load.\n\nThe code has been tested with OpenGL 4.3 on Windows/Linux and OpenGL 4.1 on MacOS.\n\n[GLM]: http://glm.g-truc.net\n[GLFW]:  http://glfw.org\n[ghcookbook]:  http://github.com/daw42/glslcookbook\n[cookbook]: http://www.packtpub.com/opengl-4-shading-language-cookbook-second-edition/book\n[cookbookv3]: https://github.com/PacktPublishing/OpenGL-4-Shading-Language-Cookbook-Third-Edition\n[GLLoadGen]:  https://bitbucket.org/alfonse/glloadgen/wiki/Home\n[CMake]: http://www.cmake.org/\n[GLAD]: https://github.com/Dav1dde/glad\n[cmake_prefix]: https://cmake.org/cmake/help/latest/variable/CMAKE_PREFIX_PATH.html\n"}, {"repo": "/fennecdjay/Gwion", "language": "C", "readme_contents": "# Gwion\n\n[![Build Status](https://travis-ci.org/fennecdjay/Gwion.svg?branch=master)](https://travis-ci.org/fennecdjay/Gwion)\n[![Language grade: C/C++](https://img.shields.io/lgtm/grade/cpp/g/fennecdjay/Gwion.svg?logo=lgtm&logoWidth=18)](https://lgtm.com/projects/g/fennecdjay/Gwion/context:cpp)\n[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/2417/badge)](https://bestpractices.coreinfrastructure.org/projects/2417)\n[![Coveralls branch](https://img.shields.io/coveralls/fennecdjay/Gwion/master.svg)](https://coveralls.io/github/fennecdjay/Gwion?branch=master)\n[![All Contributors](https://img.shields.io/badge/all_contributors-3-orange.svg)](#contributors)\n[![BCH compliance](https://bettercodehub.com/edge/badge/fennecdjay/Gwion?branch=master)](https://bettercodehub.com/)\n\nGwion is a programming language, aimed at making music\n\n**strongly** inspired by [chuck](http://chuck.stanford.edu/), but adding a bunch *high-level* features:  \n\t  templating, first-class functions and more.  \n<!-- TODO: add benchmarks in doc and link to it -->\nIt aims to be simple, small,\n [fast](https://fennecdjay.github.io/Gwion/#Benchmarks/),\n [extendable](https://github.com/fennecdjay/Gwion-plug) and [embeddable](https://github.com/fennecdjay/Gwion/blob/master/src/main.c#L18-L31).\n\n### simple example code (hello_world.gw):\n\n```cpp\n// print hello world\n<<< \"Hello World\" >>>;\n```\nto run this, do\n\n```sh\n./gwion hello_world.gw\n```\nYou want to know more? :smile: Look [here](https://fennecdjay.github.io/Gwion/)\nBoth outdated and WIP :construction_worker: but a nice place to learn and [contribute](https://github.com/fennecdjay/gwion/issues)\n\n## Build\n### Download the source\nYou might just want the minimum to start with, try\n``` sh\ngit clone https://github.com/fennecdjay/Gwion\ncd Gwion\ngit submodule update --init util ast\nmake\n```\n\nYou can get a list of config files to tweak with\n``` sh\nfind . -name \"config.mk\"\n```\n> Besides develloper options, you migth want to check *USE_DOUBLE*, in util/config.mk, which set the floating point size (float or double).\n\n## Reporting bugs / Contributing\n\n:+1: Every helping hand is welcome!!! :+1:  \n\nIf there's anything you see that can make Gwion better, please let us know!\n\n:book: Please see the [contributing](.github/CONTRIBUTING.md) page for more information.\n\n## Acknowledgements.\nThe whole [Chuck](http://chuck.cs.princeton.edu/) team, for inspiration.  \n[Paul Batchelor](https://github.com/PaulBatchelor) and the awesome [soundpipe](https://github.com/PaulBatchelor/Soundpipe) library, that got me started.\n\n## Contributors\n\nThanks goes to these wonderful people ([emoji key](https://github.com/kentcdodds/all-contributors#emoji-key)):\n<!-- ALL-CONTRIBUTORS-LIST:START - Do not remove or modify this section -->\n<!-- prettier-ignore -->\n<table><tr><td align=\"center\"><a href=\"http://paulbatchelor.github.io\"><img src=\"https://avatars3.githubusercontent.com/u/8139389?v=4\" width=\"100px;\" alt=\"Paul Batchelor\"/><br /><sub><b>Paul Batchelor</b></sub></a><br /><a href=\"#question-PaulBatchelor\" title=\"Answering Questions\">\ud83d\udcac</a> <a href=\"https://github.com/fennecdjay/Gwion/issues?q=author%3APaulBatchelor\" title=\"Bug reports\">\ud83d\udc1b</a> <a href=\"https://github.com/fennecdjay/Gwion/commits?author=PaulBatchelor\" title=\"Code\">\ud83d\udcbb</a> <a href=\"#ideas-PaulBatchelor\" title=\"Ideas, Planning, & Feedback\">\ud83e\udd14</a></td><td align=\"center\"><a href=\"https://github.com/originalsouth\"><img src=\"https://avatars1.githubusercontent.com/u/5300799?v=4\" width=\"100px;\" alt=\"Benny\"/><br /><sub><b>Benny</b></sub></a><br /><a href=\"#question-originalsouth\" title=\"Answering Questions\">\ud83d\udcac</a> <a href=\"https://github.com/fennecdjay/Gwion/issues?q=author%3Aoriginalsouth\" title=\"Bug reports\">\ud83d\udc1b</a> <a href=\"https://github.com/fennecdjay/Gwion/commits?author=originalsouth\" title=\"Code\">\ud83d\udcbb</a></td><td align=\"center\"><a href=\"https://github.com/scalarwaves\"><img src=\"https://avatars1.githubusercontent.com/u/4212896?v=4\" width=\"100px;\" alt=\"Andrew Prentice\"/><br /><sub><b>Andrew Prentice</b></sub></a><br /><a href=\"#question-scalarwaves\" title=\"Answering Questions\">\ud83d\udcac</a> <a href=\"https://github.com/fennecdjay/Gwion/issues?q=author%3Ascalarwaves\" title=\"Bug reports\">\ud83d\udc1b</a> <a href=\"https://github.com/fennecdjay/Gwion/commits?author=scalarwaves\" title=\"Code\">\ud83d\udcbb</a> <a href=\"#ideas-scalarwaves\" title=\"Ideas, Planning, & Feedback\">\ud83e\udd14</a></td></tr></table>\n\n<!-- ALL-CONTRIBUTORS-LIST:END -->\nThis project follows the [all-contributors](https://github.com/kentcdodds/all-contributors) specification. Contributions of any kind welcome!\n\n>    NOTE: if you should be on the list of contributors but we forgot you, don't be shy and let us know!\n"}, {"repo": "/mrniko/netty-socketio", "language": "Java", "readme_contents": "Netty-socketio Overview\n===\nThis project is an open-source Java implementation of [Socket.IO](http://socket.io/) server. Based on [Netty](http://netty.io/) server framework.  \n\nCheckout [Demo project](https://github.com/mrniko/netty-socketio-demo)\n\nLicensed under the Apache License 2.0.\n\n\nFeatures\n================================\n* Supports __0.7__...__0.9.16__ (netty-socketio 1.6.6) and __1.0+__ (netty-socketio latest version) version of [Socket.IO-client](https://github.com/LearnBoost/socket.io-client)  \n* Supports xhr-polling transport  \n* Supports websocket transport  \n* Supports namespaces and rooms  \n* Supports ack (acknowledgment of received data)  \n* Supports SSL  \n* Supports client store (Memory, [Redisson](http://redisson.org), [Hazelcast](http://www.hazelcast.com/))  \n* Supports distributed broadcast across netty-socketio nodes ([Redisson](http://redisson.org), [Hazelcast](http://www.hazelcast.com/))  \n* Supports OSGi  \n* Supports Spring  \n* Lock-free and thread-safe implementation  \n* Declarative handler configuration via annotations  \n\n\nPerformance\n================================\n\nCustomer feedback in __2012__:  \nCentOS, 1 CPU, 4GB RAM runned on VM: \nCPU 10%, Memory 15%  \n6000 xhr-long polling sessions or 15000 websockets sessions  \n4000 messages per second  \n\n\nCustomer feedback in __2014__:  \n\"To stress test the solution we run 30 000 simultaneous websocket clients and managed to peak at total of about 140 000 messages per second with less than 1 second average delay.\" (c) Viktor Endersz - Kambi Sports Solutions\n\nProjects using netty-socketio\n================================\nAVOS Cloud: [avoscloud.com](https://avoscloud.com/)  \nBingo Crack: [bingocrack.com](http://bingocrack.com/)  \nKambi Sports Solutions: [kambi.com](http://kambi.com/)  \nARSnova: [arsnova.eu](https://arsnova.eu)  \nZipwhip: [zipwhip.com](https://zipwhip.com/)\n\nRecent Releases\n================================\n#### Please Note: trunk is current development branch.\n\n#### 11-Jan-2019 - version 1.7.17 released  \nFeature - randomSession setting added to Config object (thanks to yuanxiangz)  \nFixed - NPE in WebSocketTransport  \nFixed - NPE & memory leak (thanks to zhaolianwang)  \nFixed - namespace parsing (thanks to Redliver)  \nFixed - Redisson 3.9+ compatibility  \n\n#### 06-Jul-2018 - version 1.7.16 released  \nFixed - non thread-safe ACK handling (thanks to dawnbreaks)  \nFixed - inactive long-polling channels cause memory leak (thanks to dawnbreaks)  \nFixed - websocket CloseFrame processing (thanks to hangsu.cho)  \nFixed - WebSocketTransport NPE  \n\n#### 15-May-2018 - version 1.7.15 released  \n\nFixed - Session ID is not unique anymore  \nFixed - fixed underlying connection not closing on ping timeout  \nFixed - the \"fin_close\" problem  \n\n#### 26-Feb-2018 - version 1.7.14 released  \nFeature - added local socket address for the connection (thanks to @SergeyGrigorev)  \nFeature - `addPingListener` method added (thanks to @lovebing)  \nFeature - add ThreadFactory for HashedWheelTimer (thanks to @hand515)  \nFixed - changed SO_LINGER to be handled as child channel (not server channel) option (thanks to @robymus)  \nFixed - ByteBuf leak if binary attachments are used  \nFixed - restore session from Cookie (thanks to @wuxudong)  \nFixed - NumberFormatException when b64 is bool value (thanks to @vonway)  \nFixed - data encoding for polling transport  \n\n#### 20-Sep-2017 - version 1.7.13 released  \nFeature - Added option to change the SSL KeyFactoryAlgorithm using Configuration (thanks to @robymus)  \nImprovement - Binary ack handling improvements (thanks to Sergey Bushik)  \nFixed - Failed to mark a promise as success because it has succeeded already (thanks to @robymus)\n\n#### 27-Aug-2016 - version 1.7.12 released  \nFeature - `SocketIOServer.removeAllListeners` method added  \nFeature - `BroadcastOperations.sendEvent` method with `excludedClient` param added  \nImprovement - Redisson updated to 2.4.0  \nFixed - memory leak in Namespace object (thanks to @CrazyIvan007)  \n\n\n#### 13-Jul-2016 - version 1.7.11 released  \nFixed - Throw error if transport not supported  \nFixed - Client disconnecting when using Polling - IndexOutOfBoundsException  \n\n#### 4-Mar-2016 - version 1.7.10 released  \nFixed - netty updated to 4.1.0.CR3 version  \nFixed - binary packet parsing (thanks to Winston Li)  \n\n#### 6-Feb-2016 - version 1.7.9 released  \nFeature - Compression support  \nFixed - DotNET client request handling  \nFixed - Packet length format parsing  \nFixed - skipping 'd=' in packet  \nFixed - Polling clients sporadically get prematurely disconnected (thanks to lpage30)  \nFixed - connections stay open forever if server sent `close` packet  \nFixed - compatibility with Redisson latest version  \n\n#### 30-Nov-2015 - version 1.7.8 released  \nImprovement - `WebSocketServerHandshaker.allowExtensions` is `true` now  \nImprovement - SessionID cookie implementation (thanks to @ryandietrich)  \nFixed - clientRooms leak (thanks to @andreaspalm)  \nFixed - ExceptionListener not used for errors in JSON parsing  \nFixed - \"silent channel\" attack    \n\n#### 26-Mar-2015 - version 1.6.7 released  \nImprovement - `useStrictOrdering` param added for websocket packets strict ordering  \nImprovement - `FAIL_ON_EMPTY_BEANS = false` option setted in json decoder  \n\n#### 18-Feb-2015 - version 1.7.7 released  \nImprovement - no need to add jackson lib if you use own JsonSupport impl    \nFixed - SocketIO client 1.3.x support  \nFixed - Charset encoding handling (thanks to  alim-akbashev)  \n\n#### 17-Jan-2015 - version 1.7.6 released  \nImprovement - `SocketIONamespace.getName()` added  \nFixed - WebSocket frames aggregation  \nFixed - WebSocket buffer release  \nFixed - `Unexpected end-of-input in VALUE_STRING` error  \nFixed - Access-Control-Allow-Credentials is TRUE for requests with origin header  \n\n#### 05-Dec-2014 - version 1.7.5 released  \nFeature - `Configuration.sslProtocol` param added  \nFixed - BinaryEvent ack handling  \nFixed - BinaryEvent non b64 encoding/decoding  \nFixed - buffer leak during packet encoding  \n\n#### 15-Nov-2014 - version 1.7.4 released  \nFixed - packet encoding  \nFixed - BinaryEvent encoding/decoding  \nFixed - unchallenged connections handling  \n\n#### 29-Sep-2014 - version 1.6.6 released  \nFeature - `origin` setting added  \nFeature - `crossDomainPolicy` setting added  \nFeature - `SocketIOServer.startAsync` method added  \n\n#### 24-Sep-2014 - version 1.7.3 released  \nFeature - Epoll support  \nImprovement - BinaryEvent support  \nFixed - SocketIOClient disconnect handling  \nFixed - broadcast callback  \nFixed - NPE then no transport defined during auth  \nFixed - ping timeout for polling transport  \nFixed - buffer leak in PacketEncoder  \n\n#### 22-Aug-2014 - version 1.7.2 released  \nFixed - wrong outgoing message encoding using websocket transport  \nFixed - NPE in websocket transport  \nFixed - multiple packet decoding in polling transport  \nFixed - buffer leak  \n\n#### 07-Jul-2014 - version 1.7.1 released  \nFeature - ability to set custom `Access-Control-Allow-Origin` via Configuration.origin  \nFixed - connection via CLI socket.io-client  \n\n#### 28-Jun-2014 - version 1.7.0 released\nFeature - Socket.IO 1.0 protocol support. Thanks to the new protocol decoding/encoding has speedup  \n__Dropped__ - `SocketIOClient.sendMessage`, `SocketIOClient.sendJsonObject` methods and corresponding listeners  \n__Dropped__ - Flashsocket transport support  \n__Dropped__ - protocol version 0.7 ... 0.9.16  \n\n#### 13-May-2014 - version 1.6.5 released\nImprovement - single packet encoding optimized, used mostly in WebSocket transport. Encoding time reduced up to 40% (thanks to Viktor Endersz)  \nImprovement - rooms handling optimized  \nImprovement - ExceptionListener.exceptionCaught method added  \n__Breaking api change__ - Configuration.autoAck replaced with ackMode  \nFeature - trustStore setting added  \nFeature - maxFramePayloadLength setting added  \nFeature - getAllClients and getClient methods added to SocketIONamespace  \nFixed - SocketIOServer.getAllClients returns wrong clients amount  \n\n#### 25-Mar-2014 - version 1.6.4 released\nFixed - message release problem  \nFixed - problem with exception listener configuration redefinition  \n__Breaking api change__ - DataListener.onData now throws Exception  \nImprovement - data parameter added to exception listener  \nImprovement - ability to setup socket configuration  \nImprovement - Configuration.autoAck parameter added  \n\n#### 06-Mar-2014 - version 1.6.3 released\nFixed - AckCallback handling during client disconnect  \nFixed - unauthorized handshake HTTP code changed to 401  \n__Breaking api change__ - Configuration.heartbeatThreadPoolSize setting removed  \nFeature - annotated Spring beans support via _SpringAnnotationScanner_  \nFeature - common exception listener  \nImprovement - _ScheduledExecutorService_ replaced with _HashedWheelTimer_  \n\n#### 08-Feb-2014 - version 1.6.2 released\nFixed - wrong namespace client disconnect handling  \nFixed - exception in onConnect/onDisconnect/isAuthorized methods leads to server hang  \n__Breaking api change__ - SocketIOClient.sendEvent methods signature changed  \nImprovement - multi type events support via _MultiTypeEventListener_ and _OnEvent_ annotation  \nImprovement - multi type events ack support via _MultiTypeAckCallback_  \nImprovement - SocketIOClient.getHandshakeData method added  \nImprovement - Jedis replaced with [Redisson](https://github.com/mrniko/redisson)  \n\n#### 14-Jan-2014 - version 1.6.1 released\nFixed - JDK 1.6+ compatibility  \nFeature - authorization support  \n\n#### 19-Dec-2013 - version 1.6.0 released\nFixed - XHR-pooling transport regression  \nFixed - Websocket transport regression  \nFixed - namespace NPE in PacketHandler  \nFixed - executors shutdown during server stop  \nFeature - client store (Memory, [Redis](http://redis.io/), [Hazelcast](http://www.hazelcast.com/)) support  \nFeature - distributed broadcast across netty-socketio nodes ([Redis](http://redis.io/), [Hazelcast](http://www.hazelcast.com/)) support  \nFeature - OSGi support (thanks to rdevera)  \nImprovement - XHR-pooling optimization  \nImprovement - SocketIOClient.getAllRooms method added\n\n#### 07-Dec-2013 - version 1.5.4 released\nFixed - flash policy \"request leak\" after page reload (thanks to ntrp)  \nFixed - websocket swf loading (thanks to ntrp)  \nFixed - wrong urls causes a potential DDoS  \nFixed - Event.class package visibility changed to avoid direct usage  \nImprovement - Simplified Jackson modules registration\n\n#### 24-Oct-2013 - version 1.5.2 released\nFixed - NPE during shutdown  \nImprovement - isEmpty method added to Namespace\n\n#### 13-Oct-2013 - version 1.5.1 released\nFixed - wrong ack timeout callback invocation  \nFixed - bigdecimal serialization for JSON  \nFixed - infinity loop during packet handling exception  \nFixed - 'client not found' handling  \n\n#### 27-Aug-2013 - version 1.5.0 released\nImprovement - encoding buffers allocation optimization.  \nImprovement - encoding buffers now pooled in memory to reduce GC pressure (netty 4.x feature).  \n\n#### 03-Aug-2013 - version 1.0.1 released\nFixed - error on unknown property during deserialization.  \nFixed - memory leak in long polling transport.  \nImprovement - logging error info with inbound data.\n \n#### 07-Jun-2013 - version 1.0.0 released\nFirst stable release.\n\n\n### Maven \n\nInclude the following to your dependency list:\n\n    <dependency>\n     <groupId>com.corundumstudio.socketio</groupId>\n     <artifactId>netty-socketio</artifactId>\n     <version>1.7.12</version>\n    </dependency>\n    \n### Supported by\n\nYourKit is kindly supporting this open source project with its full-featured Java Profiler.\nYourKit, LLC is the creator of innovative and intelligent tools for profiling\nJava and .NET applications. Take a look at YourKit's leading software products:\n<a href=\"http://www.yourkit.com/java/profiler/index.jsp\">YourKit Java Profiler</a> and\n<a href=\"http://www.yourkit.com/.net/profiler/index.jsp\">YourKit .NET Profiler</a>.\n"}, {"repo": "/webfrogs/xcode_shell", "language": "Perl", "readme_contents": "\nNote\n=====\n\nHighly suggest you use [**fastlane**](https://github.com/fastlane/fastlane) instead of this project.\n\nIf you want to publish ipa to fir, use official project [**fir-cli**](https://github.com/FIRHQ/fir-cli) instead of this project. Script ipa-publish-fir is deprecated.\n\nIntroduce\n======\n----\n\nThis repository contains a series of useful shell scripts which can help you to work effectively when programming for iOS platform.\n####Include:\n* build .ipa package\n* publish .ipa file to fir.im or your own server\n* send email\n\n\n\nNecessary\n===========\n\n-----\n\n* Mac OS X\n* \"Command Line Tools\" of xcode\n* ruby with \"json\" package installed\n\n\n\nDetail\n===========\n\n----\n\n##1.compile and package xcode project or workspace\n\nYou can do this by using \"ipa-build\" shell script.\n\nThis ipa-build script is created to compile the xcode project and package the project to an ipa file.\n\n####Usage: \n\n***building xcode project***\n\n\tipa-build <project directory> [-c <project configuration>] [-o <ipa output directory>] [-t <target name>] [-n]\n\n***building xcode workspace***\n\n\tipa-build  <workspace directory> -w -s <schemeName> [-c <project configuration>] [-n]\n\n####Options:\n\n\t-c NAME\t\tthe configuration of project used to compile.Default is Release\n\t-o PATH\t\toutput path for ipa file(must be a directory)\n\t-t NAME\t\tthe target which should be compiled\n\t-w\t\t\tbuild xcode workspace\t\n\t-s NAME\t\tthe schemal to be used for compiling\n\t-n\t\t\tclean the project before compling\n\n####Example:\n\n***build project***\n\u200b    \nIf you have an iOS project in the path ~/iphone, and the ipa-build script is put in the path ~/xcode-shell.You want to build this project with 'Release' configuration.Just using script like this:\n\n\tcd ~/iphone\n\t~/xcode-shell/ipa-build .\n\nIf you want to assign specific configuration or target, you can add relevant options to the command.\n\n***build workspace***\n\nIf ~/iphone is a xcode workspace and the scheme used for compile named 'test'.The ipa-build script is put in the path ~/xcode-shell.Using script like this:\n\n\tcd ~/iphone\n\t~/xcode-shell/ipa-build . -w -s test\n\nYou can also assign a specific configuration by using -c option.\n\n\n\tNote:If script executed successfully,an ipa file is created in the path: <project path>/build/ipa-build.\n\n##2.compile project used CocoaPods\n\n[CocoaPods](https://github.com/CocoaPods/CocoaPods) is an Objective-C library manager.If you use it in your iOS project.You can also use 'ipa-build' script to build by assign workspace and scheme, or you can use the 'cocoapods-build' to build it more easily.\n\n####Usage:\n\n\tcocoapods-build <cococapods project path> [<build configuration>] \n\n####Example:\n\n\tcd ~/iphone\n\t~/xcode-shell/cocoapods-build . Debug\n\n\n##3.publish project\n\n###ipa-publish\n####Configure\nYou must configure the script before using at the first time. Open it in any text editor and input you own configurations. Such as ftp address, app download url, email sender and email receiver. After that you can run this script to publish app to your own server.\nNote that installing app from your own server should respect the protocol named \"itms-services\". To learn more about \"itms-services\" you can click blog [Wireless AdHoc Distribution](http://gknops.github.io/adHocGenerate/)(English) or blog [ios\u5b9e\u73b0itms-services\u534f\u8bae\u4f01\u4e1a\u5185\u53d1\u5e03\u6216\u8005\u8d8a\u72f1\u53d1\u5e03](http://blog.csdn.net/wyq5119275/article/details/16946009)(\u4e2d\u6587).\n\n####Usage:\n\n\tipa-publish <project root path> [y <should send notification email>]\n\n####Examples:\n\n    ~/xcode-shell/ipa-publish . y   #publish and send email\n    ~/xcode-shell/ipa-publish .     #just publish\n\n\n###ipa-publish-fir\nThis script is similar to \"ipa-publish\". Both of them are using to publish app to somewhere. But this script will publish app to [fir.im](http://fir.im). So it is more easier to use, as you don't need a special server and FTP. You can use it without any configration, unless you want to send email to notify somebody.\n\n####Configure\nIf you want to send email to notify somebody. Open the script, and changed the value of \"email_reciver\". This field may contain one or more than one emails.\n\n\n####Usage:\n\n\tipa-publish-fir [-d directory>] [-e] [-l number] [-m message]\n\n####Options:\n\n\t-d path\t\tthe root directory of project\n\t-e\t\t\tsend email after publishing\n\t-l number\tlimit of git log, which will be used as change log.\n\t-m message\tused as chang log\n\n\n####Examples:\n\n    ~/xcode-shell/ipa-publish-fir -d . -el20 -m \"haha\"\t#Publish and send email. The change log on fir and in email will be \"haha\"+<last 20 logs of git>\n    ~/xcode-shell/ipa-publish-fir -d .     \t\t\t#just publish\n\n\n##4.add @2x suffix to image files\n\nWhen programming for retina device of iOS,the image file you used should add the suffix of @2x. Using the script \"add2x\" can help you do this automaticly.\n\n**add2x**: add suffix of @2x to all the image files(just png and jpg file) .This script work in the current directory.\n\nUsage:    \n1. go to the directory which contains images should be added suffix.    \n2. execute the add2x script.\n\n**note**: There is a bug of this script.If your image file name contains blank spaces, script can not work correctly.\n\n\n\n\n"}, {"repo": "/filcuc/DOtherSide", "language": "C++", "readme_contents": "# DOtherSide\n[![License](https://img.shields.io/badge/license-LGPL-green.svg)](https://github.com/filcuc/DOtherSide/blob/master/LICENSE)\n[![Build Status](https://travis-ci.org/filcuc/DOtherSide.svg?branch=master)](https://travis-ci.org/filcuc/DOtherSide)\n[![Build status](https://ci.appveyor.com/api/projects/status/ufufhtv2h507sd96/branch/master?svg=true)](https://ci.appveyor.com/project/filcuc/dotherside/branch/master)\n[![codecov](https://codecov.io/gh/filcuc/dotherside/branch/master/graph/badge.svg)](https://codecov.io/gh/filcuc/dotherside)\n[![Documentation Status](https://img.shields.io/badge/read-documentation-blue.svg)](https://filcuc.github.io/DOtherSide/)\n\nC language library for creating bindings for the Qt QML language.\n\nDocumentation: https://filcuc.github.io/DOtherSide/index.html\n\nCurrently the DOtherSide library is used by the following bindings:\n* [nimqml](https://github.com/filcuc/nimqml), QML bindings for the Nim programming language\n* [dqml](https://github.com/filcuc/dqml), QML bindings for the D programming language\n* [qml-rust](https://github.com/White-Oak/qml-rust), QML bindings for the Rust programming language\n\n## Supported features\nThe following features are implementable from a binding language\n* Creating custom QObject\n* Creating custom QAbstractListModels\n* Creating custom properties, signals and slots\n* Creating from QML QObject defined in the binded language\n* Creating from Singleton QML QObject defined in the binded language\n\n## Prebuilt binaries\n### Windows\nCurrently we provide the prebuilt binaries for windows through the\ngithub [releases](https://github.com/filcuc/DOtherSide/releases) page\n\n### Linux\nCurrently we provide the prebuilt binaries for the following\nLinux distributions through the [OpenSUSE OBS service](https://build.opensuse.org/package/show/home:filcuc/DOtherSide)\n* ```Archlinux``` : [here](http://software.opensuse.org/download.html?project=home%3Afilcuc&package=DOtherSide)\n\n## Change log\nThe project change log can be read [here](./CHANGELOG.md).\n\n## Supported platforms\nCurrently we support the following platforms/compilers:\n- Linux both 32/64bit with gcc\n- Windows 32/64bit with Visual Studio 2013|2015 Community Edition\n\n## Build requirements\nYou need the following software:\n* Qt 5.4 or higher\n* Linux: gcc 4.8 or later with c++11 support or higher\n* Windows: Visual Studio 2013|2015 Community Edition (Windows) or higher\n\n## Build instructions:\n1. Open a shell terminal inside the cloned repo\n2. mkdir build && cd build\n3. cmake ..\n4. make\n\n## Install Instructions\nOnce you built the package just type\n```\nmake install\n```\nby default cmake will install to the default CMAKE prefix.\nIf you want to customize this location type the following command\nduring the build steps when invoking cmake\n```\ncmake -DCMAKE_INSTALL_PREFIX:PATH=/path/to/install/prefix path/to/CMakeLists.txt\n```\n"}, {"repo": "/forhappy/c-recipes", "language": "C++", "readme_contents": "c-recipes\n=========\n\nc/c++ language useful recipes"}, {"repo": "/feelpp/feelpp", "language": "C++", "readme_contents": ":feelpp: Feel++\n:cpp: C++\n= {feelpp}: Finite Element Embedded Library in {cpp}\nFeel++ Consortium <https://github.com/feelpp[@feelpp]>\n:toc: macro\n:toclevels: 2\n:uri-rel-file-base: link:\n:uri-rel-tree-base: link:\nifdef::env-site[]\n:uri-rel-file-base: {uri-repo}/blob/develop/\n:uri-rel-tree-base: {uri-repo}/tree/develop/\nendif::[]\nifndef::env-github[:icons: font]\nifdef::env-github[]\n:status:\n:outfilesuffix: .adoc\n:caution-caption: :fire:\n:important-caption: :exclamation:\n:note-caption: :paperclip:\n:tip-caption: :bulb:\n:warning-caption: :warning:\nendif::[]\nifdef::env-github,env-browser[:outfilesuffix: .adoc]\n// URIs:\n:uri-org: https://github.com/feelpp\n:uri-repo: {uri-org}/feelpp\n:uri-www: http://www.feelpp.org\n:uri-project: http://book.feelpp.org\n:uri-docs: {uri-project}/\n:uri-news: {uri-www}/news\n:uri-manpage: {uri-project}/man/asciidoctor\n:uri-help-base: https://help.github.com/articles\n:uri-contribute: {uri-rel-file-base}CONTRIBUTING.adoc\n:uri-license: {uri-rel-file-base}LICENSE.adoc\n:uri-issues: {uri-repo}/issues\n:uri-contributors: {uri-repo}/graphs/contributors\n:uri-fork-help: {uri-help-base}/fork-a-repo\n:uri-branch-help: {uri-fork-help}#create-branches\n:uri-pr-help: {uri-help-base}/using-pull-requests\n:uri-gist: https://gist.github.com\n:uri-freesoftware: https://www.gnu.org/philosophy/free-sw.html\n\n\ntoc::[]\n\nimage:https://github-basic-badges.herokuapp.com/release/feelpp/feelpp.svg[link=https://github.com/feelpp/feelpp/releases/latest]\nimage:https://badge.buildkite.com/192023cd78277ebeb80f48580ea813c586ec6dcd0365531b33.svg?branch=develop[\"Build Status\", link=\"https://buildkite.com/feelpp/feelpp\"]\nimage:https://api.codacy.com/project/badge/Grade/ee741577e2454024a18d44603be62a6d[link=\"https://www.codacy.com/app/prudhomm/feelpp?utm_source=github.com&amp;utm_medium=referral&amp;utm_content=feelpp/feelpp&amp;utm_campaign=Badge_Grade\"]\n\nlink:http://www.feelpp.org[{feelpp}] is a {cpp} library for continuous or discontinuous Galerkin methods including finite element method(FEM), spectral element methods(SEM), reduced basis methods, discontinuous galerkin methods (DG and HDG) in 1D 2D and 3D and in parallel.\n\n== {feelpp} Documentation\n\n.link:http://book.feelpp.org[{feelpp} Book web site]\nimage::https://media.githubusercontent.com/media/feelpp/book.feelpp.org/master/images/cover_small.jpg[{feelpp} Book,link=http://book.feelpp.org]\n\n== Gitter Discussion Forum\n\nWe encourage you to ask questions and discuss any aspects of the project on the link:http://gitter.im/feelpp/feelpp[{feelpp}\n  Gitter forum].\nNew contributors are always welcome!\n\nimage:https://badges.gitter.im/Join%20Chat.svg[\"Join the chat at\", https://gitter.im/feelpp/feelpp\",link=\"https://gitter.im/feelpp/feelpp\"]\n\n\n== Continuous Integration\n\n{feelpp} maintains various branches.\nAt the core, the development model is greatly inspired by existing models out there.\nThe central repo holds two main branches with an infinite lifetime: `master` and `develop`\n\n`master`::\nMain branch where the source code of HEAD always reflects a _production-ready_ state.\n\n`develop`::\nMain branch where the source code of HEAD always reflects a state with the latest delivered development changes for the next release.\nSome would call this the \u201cintegration branch\u201d. This is where any automatic nightly builds are built from.\n\n`feature/*`::\nFeature branches (or sometimes called topic branches) are used to develop new features for the upcoming or a distant future release.\nWhen starting development of a feature, the target release in which this feature will be incorporated may well be unknown at that point.\nThe essence of a feature branch is that it exists as long as the feature is in development, but will eventually be merged back into develop (to definitely add the new feature to the upcoming release) or discarded (in case of a disappointing experiment).\n\n|===\n| Platform & Compiler | `master` | `develop`\n\n| Buildkite Ubuntu 16.04 clang6\n|  image:https://badge.buildkite.com/192023cd78277ebeb80f48580ea813c586ec6dcd0365531b33.svg?branch=master[\"Build Status\", link=\"https://buildkite.com/feelpp/feelpp\"]\n| image:https://badge.buildkite.com/192023cd78277ebeb80f48580ea813c586ec6dcd0365531b33.svg?branch=develop[\"Build Status\", link=\"https://buildkite.com/feelpp/feelpp\"]\n\n| Buildkite Ubuntu 16.04 clang5\n| image:https://badge.buildkite.com/56a8f50b0cd6a7ebf60abb852eb5f78f578f36623b37701809.svg?branch=master[link=\"https://buildkite.com/feelpp/feelpp-clang5\"]\n| image:https://badge.buildkite.com/56a8f50b0cd6a7ebf60abb852eb5f78f578f36623b37701809.svg?branch=develop[link=\"https://buildkite.com/feelpp/feelpp-clang5\"]\n\n| Buildkite Ubuntu 16.04 clang4\n| image:https://badge.buildkite.com/70be862a4a14334363d173068c7b0c7caf63adc8e1555bd813.svg?branch=master[link=\"https://buildkite.com/feelpp/feelpp-clang4\"]\n| image:https://badge.buildkite.com/70be862a4a14334363d173068c7b0c7caf63adc8e1555bd813.svg?branch=develop[link=\"https://buildkite.com/feelpp/feelpp-clang4\"]\n\n| Buildkite MacOsX Homebrew\n| image:https://badge.buildkite.com/8957ffa3255c088997196cfe0743e43e3c4fca200d39755f4b.svg?branch=master[link=https://buildkite.com/feelpp/feelpp-homebrew]\n| image:https://badge.buildkite.com/8957ffa3255c088997196cfe0743e43e3c4fca200d39755f4b.svg?branch=develop[link=https://buildkite.com/feelpp/feelpp-homebrew]\n\n|===\n\n== What is {feelpp}?\n\nlink:http://www.feelpp.org[{feelpp}] is a {cpp} library for continuous or discontinuous Galerkin methods including finite element method(FEM), spectral element methods(SEM), reduced basis methods, discontinuous galerkin methods (DG and HDG) in 1D 2D and 3D and in parallel.\nThe objectives of this framework is quite ambitious; ambitions which could be express in various ways such as :\n\n * the creation of a versatile mathematical kernel solving easily problems using different techniques thus allowing testing and comparing methods, e.g. cG versus dG,\n * the creation of a small and manageable library which shall nevertheless encompass a wide range of numerical methods and techniques,\n * build mathematical software that follows closely the mathematical abstractions associated with partial differential equations (PDE),\n * the creation of a library entirely in C++ allowing to create complex and typically multi-physics applications such as fluid-structure interaction or mass transport in haemodynamic.\n\n\nSome basic installation procedure are available in the link:INSTALL.md[INSTALL] file, the detailled process is available link:http://www.feelpp.org/docs/develop/BuildingP.html[here].\n\n== Releases\n\nHere are the latest releases of {feelpp}\n\n* {feelpp} link:https://github.com/feelpp/feelpp/releases/tag/v0.104.0-beta.2[v0.104.0-beta.2] image:https://zenodo.org/badge/DOI/10.5281/zenodo.1239039.svg[\"DOI\",link=\"https://doi.org/10.5281/zenodo.1239039\"]\n\n\n* {feelpp} link:https://github.com/feelpp/feelpp/releases/tag/v0.104.0-beta.1[v0.104.0-beta.1] image:https://zenodo.org/badge/DOI/10.5281/zenodo.1227144.svg[\"DOI\",link=\"https://doi.org/10.5281/zenodo.1227144\"]\n\n * {feelpp} link:https://github.com/feelpp/feelpp/releases/tag/v0.103.2[v0.103.2] image:https://zenodo.org/badge/DOI/10.5281/zenodo.581705.svg[\"DOI\",link=\"https://doi.org/10.5281/zenodo.581705\"]\n\n * {feelpp} link:https://github.com/feelpp/feelpp/releases/tag/v0.102.0[v0.102.0]\n image:https://zenodo.org/badge/doi/10.5281/zenodo.495740.svg[\"DOI\",link=\"https://doi.org/10.5281/zenodo.495740\"]\n\n * {feelpp} link:https://github.com/feelpp/feelpp/releases/tag/v0.100.0[v0.100.0]\n image:https://zenodo.org/badge/doi/10.5281/zenodo.45132.svg[\"DOI\",link=\"https://doi.org/10.5281/zenodo.45132\"]\n\n * {feelpp} link:https://github.com/feelpp/feelpp/releases/tag/v0.99.0-final.1[v0.99.0] image:https://zenodo.org/badge/doi/10.5281/zenodo.11624.svg[\"DOI\",link=\"https://doi.org/10.5281/zenodo.11624\"]\n\n== Features\n\n * 1D 2D and 3D (including high order) geometries and also lower topological dimension 1D(curve) in 2D and 3D or 2D(surface) in 3D\n * continuous and discontinuous arbitrary order Galerkin Methods in 1D, 2D and 3D including finite and spectral element methods\n * domain specific embedded language in C++ for variational formulations\n * interfaced with link:http://www.mcs.anl.gov/petsc/[PETSc] for linear and non-linear solvers\n * seamless parallel computations using PETSc\n * interfaced with link:http://www.grycap.upv.es/slepc/[SLEPc] for large-scale sparse standard and generalized eigenvalue  solvers\n * supports link:http://www.geuz.org/gmsh[Gmsh] for mesh generation\n * supports link:http://www.geuz.org/gmsh[Gmsh] for post-processing (including on high order geometries)\n * supports link:http://www.paraview.org[Paraview] and CEI/Ensight for post-processing and the following file formats: ensight gold, gmsh, xdmf.\n\n\n== Contributing\n\nIn the spirit of {uri-freesoftware}[free software], _everyone_ is encouraged to help improve this project.\nIf you discover errors or omissions in the source code, documentation, or website content, please don't hesitate to submit an issue or open a pull request with a fix.\n New contributors are always welcome!\n\nHere are some ways *you* can contribute:\n\n* by using develop versions\n* by {uri-issues}[reporting bugs]\n* by {uri-issues}[suggesting new features]\n * by writing or editing documentation\n * by writing specifications\n * by writing code -- _No patch is too small._\n ** fix typos\n ** add comments\n ** write examples!\n ** write tests!\n * by refactoring code\n * by fixing {uri-issues}[issues]\n * by reviewing Pull Requests\n\nThe {uri-contribute}[Contributing] guide provides information on how to create, style, and submit issues, feature requests, code, and documentation to the {feelpp} Project.\n\n== Getting Help\n\nThe {feelpp} project is developed to help you easily do _(i)_ modelisation simulation and optimisation and _(ii)_ high performance computing.\nBut we can't do it without your feedback!\nWe encourage you to ask questions and discuss any aspects of the project on the discussion list, on Twitter or in the chat room.\n\nTwitter:: #feelpp hashtag or @feelpp mention\nChat (Gitter):: image:https://badges.gitter.im/Join%20In.svg[Gitter, link=https://gitter.im/feelpp/feelpp]\n\nifdef::env-github[]\nFurther information and documentation about {feelpp} can be found on the project's website.\n\n{uri-project}/[Home] | {uri-news}[News] | {uri-docs}[Docs]\nendif::[]\n\nThe {feelpp} organization on GitHub hosts the project's source code, issue tracker, and sub-projects.\n\nSource repository (git):: {uri-repo}\nIssue tracker:: {uri-issues}\n{feelpp} organization on GitHub:: {uri-org}\n\n== Copyright and Licensing\n\nCopyright (C) 2011-2017 {feelpp} Consortium.\nFree use of this software is granted under the terms of the GPL License.\n\nSee the {uri-license}[LICENSE] file for details.\n\n== Authors\n\n{feelpp} is led by https://github.com/prudhomm[Christophe Prud'homme] and has received contributions from {uri-contributors}[many other individuals].\nThe project was initiated in 2006 by https://github.com/prudhomm[Christophe Prud'homme] and based initially on link:https://cmcsforge.epfl.ch/projects/lifev/[lifeV] and completely re-written since then.\n\n== Examples\n\n=== Laplacian in 2D using P3 Lagrange basis functions\n\nHere is a full example to solve\n$$-\\Delta u = f \\mbox{ in } \\Omega,\\quad u=g \\mbox{ on } \\partial \\Omega$$\n\n[source,cpp]\n----\n#include <feel/feel.hpp>\n\nint main(int argc, char**argv )\n{\n    using namespace Feel;\n    Environment env( _argc=argc, _argv=argv,\n                     _desc=feel_options(),\n                     _about=about(_name=\"qs_laplacian\",\n                                  _author=\"Feel++ Consortium\",\n                                  _email=\"feelpp-devel@feelpp.org\"));\n\n    auto mesh = unitSquare();\n    auto Vh = Pch<1>( mesh );\n    auto u = Vh->element();\n    auto v = Vh->element();\n\n    auto l = form1( _test=Vh );\n    l = integrate(_range=elements(mesh),\n                  _expr=id(v));\n\n    auto a = form2( _trial=Vh, _test=Vh );\n    a = integrate(_range=elements(mesh),\n                  _expr=gradt(u)*trans(grad(v)) );\n    a+=on(_range=boundaryfaces(mesh), _rhs=l, _element=u,\n          _expr=constant(0.) );\n    a.solve(_rhs=l,_solution=u);\n\n    auto e = exporter( _mesh=mesh, _name=\"qs_laplacian\" );\n    e->add( \"u\", u );\n    e->save();\n    return 0;\n}\n----\n\n\n=== Bratu equation in 2D\n\nHere is a full non-linear example - the Bratu equation - to solve\n$$-\\Delta u + e^u = 0 \\mbox{ in } \\Omega,\\quad u=0 \\mbox{ on } \\partial \\Omega$$.\n\n[source,cpp]\n----\n#include <feel/feel.hpp>\n\ninline\nFeel::po::options_description\nmakeOptions()\n{\n    Feel::po::options_description bratuoptions( \"Bratu problem options\" );\n    bratuoptions.add_options()\n    ( \"lambda\", Feel::po::value<double>()->default_value( 1 ),\n                \"exp() coefficient value for the Bratu problem\" )\n    ( \"penalbc\", Feel::po::value<double>()->default_value( 30 ),\n                 \"penalisation parameter for the weak boundary conditions\" )\n    ( \"hsize\", Feel::po::value<double>()->default_value( 0.1 ),\n               \"first h value to start convergence\" )\n    ( \"export-matlab\", \"export matrix and vectors in matlab\" )\n    ;\n    return bratuoptions.add( Feel::feel_options() );\n}\n\n/**\n * Bratu Problem\n *\n * solve \\f$ -\\Delta u + \\lambda \\exp(u) = 0, \\quad u_\\Gamma = 0\\f$ on \\f$\\Omega\\f$\n */\nint\nmain( int argc, char** argv )\n{\n\n    using namespace Feel;\n    Environment env( _argc=argc, _argv=argv,\n                     _desc=makeOptions(),\n                     _about=about(_name=\"bratu\",\n                                  _author=\"Christophe Prud'homme\",\n                                  _email=\"christophe.prudhomme@feelpp.org\"));\n    auto mesh = unitSquare();\n    auto Vh = Pch<3>( mesh );\n    auto u = Vh->element();\n    auto v = Vh->element();\n    double penalbc = option(_name=\"penalbc\").as<double>();\n    double lambda = option(_name=\"lambda\").as<double>();\n\n    auto Jacobian = [=](const vector_ptrtype& X, sparse_matrix_ptrtype& J)\n        {\n            auto a = form2( _test=Vh, _trial=Vh, _matrix=J );\n            a = integrate( elements( mesh ), gradt( u )*trans( grad( v ) ) );\n            a += integrate( elements( mesh ), lambda*( exp( idv( u ) ) )*idt( u )*id( v ) );\n            a += integrate( boundaryfaces( mesh ),\n               ( - trans( id( v ) )*( gradt( u )*N() ) - trans( idt( u ) )*( grad( v )*N()  + penalbc*trans( idt( u ) )*id( v )/hFace() ) );\n        };\n    auto Residual = [=](const vector_ptrtype& X, vector_ptrtype& R)\n        {\n            auto u = Vh->element();\n            u = *X;\n            auto r = form1( _test=Vh, _vector=R );\n            r = integrate( elements( mesh ), gradv( u )*trans( grad( v ) ) );\n            r +=  integrate( elements( mesh ),  lambda*exp( idv( u ) )*id( v ) );\n            r +=  integrate( boundaryfaces( mesh ),\n               ( - trans( id( v ) )*( gradv( u )*N() ) - trans( idv( u ) )*( grad( v )*N() ) + penalbc*trans( idv( u ) )*id( v )/hFace() ) );\n        };\n    u.zero();\n    backend()->nlSolver()->residual = Residual;\n    backend()->nlSolver()->jacobian = Jacobian;\n    backend()->nlSolve( _solution=u );\n\n    auto e = exporter( _mesh=mesh );\n    e->add( \"u\", u );\n    e->save();\n}\n----\n\n\n\n"}, {"repo": "/timbod7/adl", "language": "C++", "readme_contents": "ADL (Algebraic Data Language)\n================================\n\n*Consistent data everywhere!*\n\nA framework for building cross language data models. It consists of a DSL for describing data types,\ncode generators for several target languages, and runtimes for these languages.\n\n* [introduction][] - an overview of the ADL system\n* [language][] - a description of the ADL language\n* [compiler][] - the command line compiler\n* [serialization][] - how ADL types are serialized\n* Language support:\n    * [haskell][]\n    * [java][]\n    * [typescript][]\n    * [c++][cpp]\n    * [rust][]\n* [install][] - installation instructions\n\n[introduction]:docs/introduction.md\n[language]:docs/language.md\n[compiler]:docs/compiler.md\n[serialization]:docs/serialization.md\n[install]:docs/install.md\n[haskell]:docs/backend-haskell.md\n[typescript]:docs/backend-typescript.md\n[java]:docs/backend-java.md\n[cpp]:docs/backend-cpp.md\n[rust]:docs/backend-rust.md\n"}, {"repo": "/ohmyzsh/ohmyzsh", "language": "Shell", "readme_contents": "<p align=\"center\">\n  <img src=\"https://s3.amazonaws.com/ohmyzsh/oh-my-zsh-logo.png\" alt=\"Oh My Zsh\">\n</p>\n\n[![Discord server](https://img.shields.io/discord/642496866407284746)](https://discord.gg/bpXWhnN)\n[![Follow @ohmyzsh](https://img.shields.io/twitter/follow/ohmyzsh?label=Follow+@ohmyzsh&style=flat)](https://twitter.com/intent/follow?screen_name=ohmyzsh)\n\nOh My Zsh is an open source, community-driven framework for managing your [zsh](https://www.zsh.org/) configuration.\n\nSounds boring. Let's try again.\n\n__Oh My Zsh will not make you a 10x developer...but you may feel like one.__\n\nOnce installed, your terminal shell will become the talk of the town _or your money back!_ With each keystroke in your command prompt, you'll take advantage of the hundreds of powerful plugins and beautiful themes. Strangers will come up to you in caf\u00e9s and ask you, _\"that is amazing! are you some sort of genius?\"_\n\nFinally, you'll begin to get the sort of attention that you have always felt you deserved. ...or maybe you'll use the time that you're saving to start flossing more often. \ud83d\ude2c\n\nTo learn more, visit [ohmyz.sh](https://ohmyz.sh) and follow [@ohmyzsh](https://twitter.com/ohmyzsh) on Twitter.\n\n## Getting Started\n\n### Prerequisites\n\n* A Unix-like operating system: macOS, Linux, BSD. On Windows: WSL is preferred, but cygwin or msys also mostly work.\n* [Zsh](https://www.zsh.org) should be installed (v4.3.9 or more recent). If not pre-installed (run `zsh --version` to confirm), check the following instructions here: [Installing ZSH](https://github.com/ohmyzsh/ohmyzsh/wiki/Installing-ZSH)\n* `curl` or `wget` should be installed\n* `git` should be installed\n\n### Basic Installation\n\nOh My Zsh is installed by running one of the following commands in your terminal. You can install this via the command-line with either `curl` or `wget`.\n\n#### via curl\n\n```shell\nsh -c \"$(curl -fsSL https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\"\n```\n\n#### via wget\n\n```shell\nsh -c \"$(wget -O- https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\"\n```\n\n#### Manual inspection\n\nIt's a good idea to inspect the install script from projects you don't yet know. You can do\nthat by downloading the install script first, looking through it so everything looks normal,\nthen running it:\n\n```shell\ncurl -Lo install.sh https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh\nsh install.sh\n```\n\n## Using Oh My Zsh\n\n### Plugins\n\nOh My Zsh comes with a shitload of plugins to take advantage of. You can take a look in the [plugins](https://github.com/ohmyzsh/ohmyzsh/tree/master/plugins) directory and/or the [wiki](https://github.com/ohmyzsh/ohmyzsh/wiki/Plugins) to see what's currently available.\n\n#### Enabling Plugins\n\nOnce you spot a plugin (or several) that you'd like to use with Oh My Zsh, you'll need to enable them in the `.zshrc` file. You'll find the zshrc file in your `$HOME` directory. Open it with your favorite text editor and you'll see a spot to list all the plugins you want to load.\n\n```shell\nvi ~/.zshrc\n```\n\nFor example, this might begin to look like this:\n\n```shell\nplugins=(\n  git\n  bundler\n  dotenv\n  osx\n  rake\n  rbenv\n  ruby\n)\n```\n\n_Note that the plugins are separated by whitespace. **Do not** use commas between them._\n\n#### Using Plugins\n\nMost plugins (should! we're working on this) include a __README__, which documents how to use them.\n\n### Themes\n\nWe'll admit it. Early in the Oh My Zsh world, we may have gotten a bit too theme happy. We have over one hundred themes now bundled. Most of them have [screenshots](https://github.com/ohmyzsh/ohmyzsh/wiki/Themes) on the wiki. Check them out!\n\n#### Selecting a Theme\n\n_Robby's theme is the default one. It's not the fanciest one. It's not the simplest one. It's just the right one (for him)._\n\nOnce you find a theme that you'd like to use, you will need to edit the `~/.zshrc` file. You'll see an environment variable (all caps) in there that looks like:\n\n```shell\nZSH_THEME=\"robbyrussell\"\n```\n\nTo use a different theme, simply change the value to match the name of your desired theme. For example:\n\n```shell\nZSH_THEME=\"agnoster\" # (this is one of the fancy ones)\n# see https://github.com/ohmyzsh/ohmyzsh/wiki/Themes#agnoster\n```\n\n_Note: many themes require installing the [Powerline Fonts](https://github.com/powerline/fonts) in order to render properly._\n\nOpen up a new terminal window and your prompt should look something like this:\n\n![Agnoster theme](https://cloud.githubusercontent.com/assets/2618447/6316862/70f58fb6-ba03-11e4-82c9-c083bf9a6574.png)\n\nIn case you did not find a suitable theme for your needs, please have a look at the wiki for [more of them](https://github.com/ohmyzsh/ohmyzsh/wiki/External-themes).\n\nIf you're feeling feisty, you can let the computer select one randomly for you each time you open a new terminal window.\n\n\n```shell\nZSH_THEME=\"random\" # (...please let it be pie... please be some pie..)\n```\n\nAnd if you want to pick random theme from a list of your favorite themes:\n\n```shell\nZSH_THEME_RANDOM_CANDIDATES=(\n  \"robbyrussell\"\n  \"agnoster\"\n)\n```\n\n### FAQ\n\nIf you have some more questions or issues, you might find a solution in our [FAQ](https://github.com/ohmyzsh/ohmyzsh/wiki/FAQ).\n\n## Advanced Topics\n\nIf you're the type that likes to get their hands dirty, these sections might resonate.\n\n### Advanced Installation\n\nSome users may want to manually install Oh My Zsh, or change the default path or other settings that\nthe installer accepts (these settings are also documented at the top of the install script).\n\n#### Custom Directory\n\nThe default location is `~/.oh-my-zsh` (hidden in your home directory)\n\nIf you'd like to change the install directory with the `ZSH` environment variable, either by running\n`export ZSH=/your/path` before installing, or by setting it before the end of the install pipeline\nlike this:\n\n```shell\nZSH=\"$HOME/.dotfiles/oh-my-zsh\" sh install.sh\n```\n\n#### Unattended install\n\nIf you're running the Oh My Zsh install script as part of an automated install, you can pass the\nflag `--unattended` to the `install.sh` script. This will have the effect of not trying to change\nthe default shell, and also won't run `zsh` when the installation has finished.\n\n```shell\nsh -c \"$(curl -fsSL https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\" \"\" --unattended\n```\n\n#### Installing from a forked repository\n\nThe install script also accepts these variables to allow installation of a different repository:\n\n- `REPO` (default: `ohmyzsh/ohmyzsh`): this takes the form of `owner/repository`. If you set\n  this variable, the installer will look for a repository at `https://github.com/{owner}/{repository}`.\n\n- `REMOTE` (default: `https://github.com/${REPO}.git`): this is the full URL of the git repository\n  clone. You can use this setting if you want to install from a fork that is not on GitHub (GitLab,\n  Bitbucket...) or if you want to clone with SSH instead of HTTPS (`git@github.com:user/project.git`).\n\n  _NOTE: it's incompatible with setting the `REPO` variable. This setting will take precedence._\n\n- `BRANCH` (default: `master`): you can use this setting if you want to change the default branch to be\n  checked out when cloning the repository. This might be useful for testing a Pull Request, or if you\n  want to use a branch other than `master`.\n\nFor example:\n\n```shell\nREPO=apjanke/oh-my-zsh BRANCH=edge sh install.sh\n```\n\n#### Manual Installation\n\n##### 1. Clone the repository:\n\n```shell\ngit clone https://github.com/ohmyzsh/ohmyzsh.git ~/.oh-my-zsh\n```\n\n##### 2. *Optionally*, backup your existing `~/.zshrc` file:\n\n```shell\ncp ~/.zshrc ~/.zshrc.orig\n```\n\n##### 3. Create a new zsh configuration file\n\nYou can create a new zsh config file by copying the template that we have included for you.\n\n```shell\ncp ~/.oh-my-zsh/templates/zshrc.zsh-template ~/.zshrc\n```\n\n##### 4. Change your default shell\n\n```shell\nchsh -s $(which zsh)\n```\n\nYou must log out from your user session and log back in to see this change.\n\n##### 5. Initialize your new zsh configuration\n\nOnce you open up a new terminal window, it should load zsh with Oh My Zsh's configuration.\n\n### Installation Problems\n\nIf you have any hiccups installing, here are a few common fixes.\n\n* You _might_ need to modify your `PATH` in `~/.zshrc` if you're not able to find some commands after\nswitching to `oh-my-zsh`.\n* If you installed manually or changed the install location, check the `ZSH` environment variable in\n`~/.zshrc`.\n\n### Custom Plugins and Themes\n\nIf you want to override any of the default behaviors, just add a new file (ending in `.zsh`) in the `custom/` directory.\n\nIf you have many functions that go well together, you can put them as a `XYZ.plugin.zsh` file in the `custom/plugins/` directory and then enable this plugin.\n\nIf you would like to override the functionality of a plugin distributed with Oh My Zsh, create a plugin of the same name in the `custom/plugins/` directory and it will be loaded instead of the one in `plugins/`.\n\n## Getting Updates\n\nBy default, you will be prompted to check for upgrades every few weeks. If you would like `oh-my-zsh` to automatically upgrade itself without prompting you, set the following in your `~/.zshrc`:\n\n```shell\nDISABLE_UPDATE_PROMPT=true\n```\n\nTo disable automatic upgrades, set the following in your `~/.zshrc`:\n\n```shell\nDISABLE_AUTO_UPDATE=true\n```\n\n### Manual Updates\n\nIf you'd like to upgrade at any point in time (maybe someone just released a new plugin and you don't want to wait a week?) you just need to run:\n\n```shell\nupgrade_oh_my_zsh\n```\n\nMagic! \ud83c\udf89\n\n## Uninstalling Oh My Zsh\n\nOh My Zsh isn't for everyone. We'll miss you, but we want to make this an easy breakup.\n\nIf you want to uninstall `oh-my-zsh`, just run `uninstall_oh_my_zsh` from the command-line. It will remove itself and revert your previous `bash` or `zsh` configuration.\n\n## How do I contribute to Oh My Zsh?\n\nBefore you participate in our delightful community, please read the [code of conduct](CODE_OF_CONDUCT.md).\n\nI'm far from being a [Zsh](https://www.zsh.org/) expert and suspect there are many ways to improve \u2013 if you have ideas on how to make the configuration easier to maintain (and faster), don't hesitate to fork and send pull requests!\n\nWe also need people to test out pull-requests. So take a look through [the open issues](https://github.com/ohmyzsh/ohmyzsh/issues) and help where you can.\n\nSee [Contributing](CONTRIBUTING.md) for more details.\n\n### Do NOT send us themes\n\nWe have (more than) enough themes for the time being. Please add your theme to the [external themes](https://github.com/ohmyzsh/ohmyzsh/wiki/External-themes) wiki page.\n\n## Contributors\n\nOh My Zsh has a vibrant community of happy users and delightful contributors. Without all the time and help from our contributors, it wouldn't be so awesome.\n\nThank you so much!\n\n## Follow Us\n\nWe're on the social media.\n\n* [@ohmyzsh](https://twitter.com/ohmyzsh) on Twitter. You should follow it.\n* [Oh My Zsh](https://www.facebook.com/Oh-My-Zsh-296616263819290/) on Facebook.\n\n## Merchandise\n\nWe have [stickers, shirts, and coffee mugs available](https://shop.planetargon.com/collections/oh-my-zsh?utm_source=github) for you to show off your love of Oh My Zsh. Again, you will become the talk of the town!\n\n## License\n\nOh My Zsh is released under the [MIT license](LICENSE.txt).\n\n## About Planet Argon\n\n![Planet Argon](https://pa-github-assets.s3.amazonaws.com/PARGON_logo_digital_COL-small.jpg)\n\nOh My Zsh was started by the team at [Planet Argon](https://www.planetargon.com/?utm_source=github), a [Ruby on Rails development agency](https://www.planetargon.com/skills/ruby-on-rails-development?utm_source=github). Check out our [other open source projects](https://www.planetargon.com/open-source?utm_source=github).\n"}, {"repo": "/forio/julia-studio", "language": "C++", "readme_contents": "<a name=\"logo\"/>\n<div align=\"center\">\n<a href=\"http://forio.com/products/julia-studio/\" target=\"_blank\">\n<img src=\"https://github.com/forio/julia-studio/blob/master/src/plugins/juliaeditor/images/js-by-forio.png?raw=true\" alt=\"Julia Logo\" width=\"525\" height=\"128\"></img>\n</a>\n</div>\n\n## Julia Studio\n[Julia Studio](http://forio.com/products/julia-studio/) is a cross-platform IDE for the [Julia language](http://julialang.org/)\nbased on [Qt Creator](http://qt.gitorious.org/qt-creator) and the [Qt framework](http://qt.gitorious.org/qt).\n\n## Supported Platforms\n[Binary packages](http://forio.com/products/julia-studio/download) are available for the following platforms:\n\n   * Mac OSX 10.6 and later\n   * Windows XP SP2 and later\n   * (K)Ubuntu Linux 12.04 and later\n\nJulia Studio binaries for Windows and Mac install the Julia programming language.  Linux users will need to [install Julia](http://julialang.org/downloads/) separately.\n\n![Screenshot of JuliaStudio running on Mac](http://forio.com/img/julia-studio/js-plot.png)\n\n## Compiling Julia Studio\n\n#### Prerequisites\n\n   * [Qt 5.1.0 or later](http://qt-project.org/downloads)\n   * [Julia 0.2 or later](http://julialang.org/downloads/)\n\n#### OSX\n```\ncd $SOURCE_DIRECTORY\nqmake -r\nmake\n```\nNote: Installation (\"make install\") is not needed. It is however possible, using\n```\nmake install INSTALL_ROOT=$INSTALL_DIRECTORY\n```\n\n#### Windows\nSee instructions in [windows-build.md](./windows-build.md)\n\n#### Linux\nSee instructions in [linux-build.md](./linux-build.md)\n\n\n## Third-party Components\nJulia Studio includes the following third-party components,\nwe thank the authors who made this possible:\n\n##### Open Source front-end for C++ (license MIT), enhanced for use in Qt Creator\n\n```\n  Roberto Raggi <roberto.raggi@gmail.com>\n\n  JuliaStudio/src/shared/cplusplus\n\n  Copyright 2005 Roberto Raggi <roberto@kdevelop.org>\n\n  Permission to use, copy, modify, distribute, and sell this software and its\n  documentation for any purpose is hereby granted without fee, provided that\n  the above copyright notice appear in all copies and that both that\n  copyright notice and this permission notice appear in supporting\n  documentation.\n\n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL THE\n  KDEVELOP TEAM BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN\n  AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n  CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n```\n\n##### Botan, a C++ crypto library. Version 1.8.8\n\n```\n  Copyright (C) 1999-2004 The Botan Project. All rights reserved.\n  Copyright (C) 1999-2009 Jack Lloyd\n  2001 Peter J Jones\n  2004-2007 Justin Karneges\n  2005 Matthew Gregan\n  2005-2006 Matt Johnston\n  2006 Luca Piccarreta\n  2007 Yves Jerschow\n  2007-2008 FlexSecure GmbH\n  2007-2008 Technische Universitat Darmstadt\n  2007-2008 Falko Strenzke\n  2007-2008 Martin Doering\n  2007 Manuel Hartl\n  2007 Christoph Ludwig\n  2007 Patrick Sona\n  All rights reserved.\n\n  Redistribution and use in source and binary forms, with or without\n  modification, are permitted provided that the following conditions are met:\n\n  1. Redistributions of source code must retain the above copyright notice,\n  this list of conditions, and the following disclaimer.\n\n  2. Redistributions in binary form must reproduce the above copyright notice,\n  this list of conditions, and the following disclaimer in the documentation\n  and/or other materials provided with the distribution.\n\n  THIS SOFTWARE IS PROVIDED BY THE AUTHOR(S) \"AS IS\" AND ANY EXPRESS OR IMPLIED\n  WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF\n  MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE, ARE DISCLAIMED. IN NO\n  EVENT SHALL THE AUTHOR(S) OR CONTRIBUTOR(S) BE LIABLE FOR ANY DIRECT,\n  INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\n  (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\n  LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND\n  ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\n  SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n  The source code of Botan C++ crypto library can be found in\n  JuliaStudio/src/libs/3rdparty\n```\n\n##### ClassView and ImageViewer plugins\n\n```\n  Copyright (C) 2012 Digia Plc and/or its subsidiary(-ies).\n\n  All rights reserved.\n  Copyright (c) 2010 Denis Mingulov.\n\n  Contact: http://www.qt-project.org/\n\n  This file is part of Julia Studio.\n\n  You may use this file under the terms of the BSD license as follows:\n\n  \"Redistribution and use in source and binary forms, with or without\n  modification, are permitted provided that the following conditions are\n  met:\n    * Redistributions of source code must retain the above copyright\n      notice, this list of conditions and the following disclaimer.\n    * Redistributions in binary form must reproduce the above copyright\n      notice, this list of conditions and the following disclaimer in\n      the documentation and/or other materials provided with the\n      distribution.\n    * Neither the name of Digia Plc and its Subsidiary(-ies) nor\n      the names of its contributors may be used to endorse or promote\n      products derived from this software without specific prior written\n      permission.\n\n  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n  \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\n  LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\n  A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\n  OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n  SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n  LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\"\n```\n\n\n"}, {"repo": "/fabric8io-images/java", "language": "Shell", "readme_contents": "## Fabric8 Java Base Images\n\nThis is a repository for Java Docker base images used in various fabric8 projects.\n\nThe Docker build files for these images are generated by\n[fish-pepper](https://github.com/fabric8io-images/fish-pepper), a sophisticated\ntemplate system for generation Docker builds. `fish-pepper` allows\nthe composition of various building block so that parametrized Docker\nbuilds are easy possible.\n\nIn order to regenerate all Dockerfiles from the provided templates you\nneed only to install `fish-pepper` via npm (assuming that you have\n[node.js](https://nodejs.org/) installed)\n\n```\nnpm -g install fish-pepper\nfish-pepper\n```\n\nThe Java base images come in different flavors:\n\n* Based on [CentOS 7](https://www.centos.org/) or\n  [Alpine Linux](https://www.alpinelinux.org/) (experimental)\n* [OpenJDK 7](http://openjdk.java.net/projects/jdk7/) or\n  [OpenJDK 8](http://openjdk.java.net/projects/jdk8/) or\n  [OpenJDK 11](http://openjdk.java.net/projects/jdk/11/)\n* As JDK (Java Developer Toolkit) or as JRE (Java Runtime Environment)\n\nAll images add the following features:\n\n* [agent-bond](https://github.com/fabric8io/agent-bond) is included\n  which combines [Jolokia](http://www.jolokia.org) and\n  [jmx_exporter](https://github.com/prometheus/jmx_exporter)\n* A startup script [run-java.sh](https://github.com/fabric8io/run-java-sh) is\n  included which transparently starts Java application provided as FAT-jar or\n  traditionally with a bunch of jar dependencies.\n\nHow to use these images and what environment variables can be used are\ndescribed in the associated [README](images/centos/openjdk8/jdk/README.md) files.\n"}, {"repo": "/dachev/node-cld", "language": "C++", "readme_contents": "# node-cld\n[![*NIX Build Status](https://secure.travis-ci.org/dachev/node-cld.png)](https://travis-ci.org/dachev/node-cld)\n[![Windows Build Status](https://ci.appveyor.com/api/projects/status/github/dachev/node-cld?svg=true&retina=true)](https://ci.appveyor.com/project/dachev/node-cld)\n[![Dependencies](https://david-dm.org/dachev/node-cld.png)](https://david-dm.org/dachev/node-cld)\n[![NPM version](https://badge.fury.io/js/cld.svg)](http://badge.fury.io/js/cld)\n\nLanguage detection for Javascript. Based on the CLD2 (Compact Language Detector) library from Google.\n\nHighly optimized for space and speed. Runs about 10x faster than other libraries. Detects over 160 languages. Full test coverage. Runs on Linux, OS X, and Windows.\n\n## Installation\n\n```bash\n$ npm install cld\n```\n\nLinux users, make sure you have g++ >= 4.8. If this is not an option, you should be able to install node-cld 2.4.4 even with an older g++ build.\n\n## Examples\n### Simple\n```js\nrequire('cld').detect('This is a language recognition example', function(err, result) {\n  console.log(result);\n});\n```\n\n### Advanced\n```js\nvar text    = '\u0422\u043e\u0432\u0430 \u0435 \u043f\u0440\u0438\u043c\u0435\u0440 \u0437\u0430 \u0440\u0430\u0437\u043f\u043e\u0437\u043d\u0430\u0432\u0430\u043d\u0435 \u043d\u0430 \u0411\u044a\u043b\u0433\u0430\u0440\u0441\u043a\u0438 \u0435\u0437\u0438\u043a';\nvar options = {\n  isHTML       : false,\n  languageHint : 'BULGARIAN',\n  encodingHint : 'ISO_8859_5',\n  tldHint      : 'bg',\n  httpHint     : 'bg'\n};\n\nrequire('cld').detect(text, options, function(err, result) {\n  console.log(result);\n});\n```\n\n\n## Options\n\n#### isHTML\n\nSet to true if the string contains HTML tags\n\n#### languageHint\n\nPass a LANGUAGES key or value as a hint\n\n#### encodingHint\n\nPass an ENCODINGS value as a hint\n\n#### tldHint\n\nPass top level domain as a hint\n\n#### httpHint\n\nPass an HTTP \"Content-Encoding\" value as a hint\n\n## Warning\nOnce the module has been installed, the underlying C sources will remain in the ```deps/cld``` folder and continue to occupy considerable space. This is because they will be required if you ever need to run `npm rebuild`. If you are under severe constraints you can delete this folder and reclam >100M\n\n## Copyright\nCopyright 2011-2015, Blagovest Dachev.\n\n## License\nApache 2\n"}, {"repo": "/Cr4sh/openreil", "language": "C", "readme_contents": "\nOpenREIL is open source library that implements translator and tools for REIL (Reverse Engineering Intermediate Language).\n\nPlease refer to docs/README.html for more detailed information.\n\n\nDeveloped by Dmytro Oleksiuk (aka Cr4sh), cr4sh0@gmail.com\n"}, {"repo": "/aspnet/JavaScriptServices", "language": "C#", "readme_contents": "# JavaScriptServices [Archived]\n\n**This GitHub project has been archived.** Ongoing development on this project can be found in <https://github.com/aspnet/AspNetCore>.\n\nThis project is part of ASP.NET Core. You can find samples, documentation and getting started instructions for ASP.NET Core at the [AspNetCore](https://github.com/aspnet/AspNetCore) repo.\n\n## What is this?\n\n`JavaScriptServices` is a set of client-side technologies for ASP.NET Core. It provides infrastructure that you'll find useful if you:\n\n-  Use Angular / React / Vue / Aurelia / Knockout / etc.\n-  Build your client-side resources using Webpack.\n-  Execute JavaScript on the server at runtime.\n\nRead [Building Single Page Applications on ASP.NET Core with JavaScriptServices](https://blogs.msdn.microsoft.com/webdev/2017/02/14/building-single-page-applications-on-asp-net-core-with-javascriptservices/) for more details.\n\nThis repo contains:\n\n * A set of NuGet/NPM packages that implement functionality for:\n   * Invoking arbitrary NPM packages at runtime from .NET code ([docs](/src/Microsoft.AspNetCore.NodeServices#simple-usage-example))\n   * Server-side prerendering of SPA components ([docs](/src/Microsoft.AspNetCore.SpaServices#server-side-prerendering))\n   * Webpack dev middleware ([docs](/src/Microsoft.AspNetCore.SpaServices#webpack-dev-middleware))\n   * Hot module replacement (HMR) ([docs](/src/Microsoft.AspNetCore.SpaServices#webpack-hot-module-replacement))\n   * Server-side and client-side routing integration ([docs](/src/Microsoft.AspNetCore.SpaServices#routing-helper-mapspafallbackroute))\n   * Server-side and client-side validation integration\n   * \"Lazy loading\" for Knockout apps\n * Samples and docs\n\nIt's cross-platform (Windows, Linux, or macOS) and works with .NET Core 2.0 or later.\n\n## Creating new applications\n\nPrerequisites:\n\n* [.NET Core 2.0](https://www.microsoft.com/net/core) (or later) SDK\n* [Node.js](https://nodejs.org/) version 6 (or later)\n\nWith these prerequisites, you can immediately create new ASP.NET Core applications that use Angular, React, or React+Redux without having to install anything extra.\n\n### Option 1: Creating Angular/React/Redux applications from the command line (cross-platform)\n\nIn an empty directory, run (for example) `dotnet new angular`. Other supported SPA frameworks include React and React+Redux. You can see the list of available SPA templates by running `dotnet new spa`.\n\nOnce the generator has run and restored all the dependencies, you can start up your new ASP.NET Core SPA:\n\n    npm install\n    dotnet run\n\n### Option 2: Creating Angular/React/Redux applications using Visual Studio 2017 Update 3 or later (Windows only)\n\nUsing the `File`->`New Project` dialog, select *ASP.NET Core Web Application*. You will then be offered the option to create an application with Angular, React, or React+Redux. When the application is created, you can build and run it in the normal way.\n\n### More info and other SPA frameworks\n\nFor a more detailed (albeit somewhat outdated) walkthrough, see [getting started with the `aspnetcore-spa` generator](http://blog.stevensanderson.com/2016/05/02/angular2-react-knockout-apps-on-aspnet-core/).\n\nIf you want to build an ASP.NET Core application with Aurelia, Knockout, or Vue, you can use the `Microsoft.AspNetCore.SpaTemplates` package. On the command line, run `dotnet new --install Microsoft.AspNetCore.SpaTemplates`. Then you will be able to run `dotnet new aurelia` (or `dotnet new vue`, etc.) to create your new application.\n\n## Adding to existing applications\n\nIf you have an existing ASP.NET Core application, or if you just want to use the underlying JavaScriptServices packages directly, you can install these packages using NuGet and NPM:\n\n * `Microsoft.AspNetCore.NodeServices`\n   * This provides a fast and robust way for .NET code to run JavaScript on the server inside a Node.js environment. You can use this to consume arbitrary functionality from NPM packages at runtime in your ASP.NET Core app.\n   * Most applications developers don't need to use this directly, but you can do so if you want to implement your own functionality that involves calling Node.js code from .NET at runtime.\n   * Find [documentation and usage examples here](/src/Microsoft.AspNetCore.NodeServices#microsoftaspnetcorenodeservices).\n * `Microsoft.AspNetCore.SpaServices`\n   * This provides infrastructure that's generally useful when building Single Page Applications (SPAs) with technologies such as Angular or React (for example, server-side prerendering and webpack middleware). Internally, it uses the `NodeServices` package to implement its features.\n   * Find [documentation and usage examples here](/src/Microsoft.AspNetCore.SpaServices#microsoftaspnetcorespaservices)\n\nThere were previously other packages called  `Microsoft.AspNetCore.AngularServices` and `Microsoft.AspNetCore.ReactServices` but these are not currently needed - all applicable functionality is in `Microsoft.AspNetCore.SpaServices`, because it's sufficiently general.\n\nIf you want to build a helper library for some other SPA framework, you can do so by taking a dependency on `Microsoft.AspNetCore.SpaServices` and wrapping its functionality in whatever way is most useful for your SPA framework.\n\n## Samples\n\nThe [`samples` directory](/samples) contains examples of:\n\n- Using the JavaScript services family of packages with Angular and React.\n- A standalone `NodeServices` usage for runtime code transpilation and image processing.\n\n**To run the samples:**\n\n * Clone this repo\n * At the repo's root directory (the one containing `src`, `samples`, etc.), run `dotnet restore`\n * Change directory to the sample you want to run (for example, `cd samples/angular/MusicStore`)\n * Restore Node dependencies by running `npm install`\n   * If you're trying to run the Angular \"Music Store\" sample, then also run `gulp` (which you need to have installed globally). None of the other samples require this.\n * Run the application (`dotnet run`)\n * Browse to [http://localhost:5000](http://localhost:5000)\n"}, {"repo": "/taozhijiang/chinese_nlp", "language": "C++", "readme_contents": "#\u4e00\u4e9b\u6c49\u8bed\u8a00\u5904\u7406\u7684\u4e1c\u897f   \n\n## segment \u6c49\u8bed\u8a00\u5206\u8bcd   \n- \u539f\u7406\uff1aHHM   \n- \u4f9d\u8d56\uff1anumpy scipy hhmlearn    \n- \u53c2\u8003\uff1a   \n  - [Itenyh\u7248-\u7528HMM\u505a\u4e2d\u6587\u5206\u8bcd\u56db\uff1aA Pure-HMM \u5206\u8bcd\u5668](http://www.52nlp.cn/itenyh%E7%89%88-%E7%94%A8hmm%E5%81%9A%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D%E5%9B%9B%EF%BC%9Aa-pure-hmm-%E5%88%86%E8%AF%8D%E5%99%A8)   \n  - [\u81ea\u5df1\u5199\u4e2d\u6587\u5206\u8bcd\u4e4b\uff08\u4e8c\uff09_\u7528HMM\u6a21\u578b\u5b9e\u73b0\u5206\u8bcd](http://sbp810050504.blog.51cto.com/2799422/1251640)   \n- TODO\uff1a   \n  - \u6ca1\u6709\u9488\u5bf9\u82f1\u6587\u5355\u8bcd\u3001\u6807\u70b9\u7b49\u5904\u7406\uff0c\u4e5f\u6ca1\u6709\u7a97\u53e3\u5316\u64cd\u4f5c    \n\n\t\n## \u4e3b\u9898\u5206\u7c7b   \n- \u539f\u7406\uff1aLDA & Labled LDA   \n- \u4f9d\u8d56\uff1agensim   \n- \u53c2\u8003:\n  - http://blog.itpub.net/16582684/viewspace-1253901/\n  - https://radimrehurek.com/gensim/models/ldamodel.html\n  - https://shuyo.wordpress.com/\n- TODO:\n  - \u611f\u89c9\u6548\u679c\u4e0d\u662f\u5f88\u597d\u554a\n\n## LSI/LDA\u4fe1\u606f\u68c0\u7d22\n- \u539f\u7406\uff1aSVD\u5947\u5f02\u503c\u5206\u89e3\n- \u4f9d\u8d56\uff1agensim\n- TODO:\n - \u539f\u7406\u6bd4\u8f83\u7b80\u5355\uff0c\u53ea\u6709SVD\uff0c\u68c0\u7d22\u7ed3\u679c\u8fd8\u662f\u53ef\u4ee5\u7684\uff0c\u4f46\u662f\u9700\u8981\u8c03\u6574topic\u7684\u53c2\u6570\uff0c\u5de5\u7a0b\u4e0a\u4ee5200-500\u4e3a\u4f73\u3002\n\n## \u60c5\u611f\u5206\u6790\n- \u539f\u7406: \u57fa\u4e8e\u7edf\u8ba1\u7684\u65b9\u5f0f   \n- \u4f9d\u8d56\uff1antlk sklearn   \n- \u8bed\u6599\uff1a\u67d0\u4e1c\u7684\u5546\u54c1\u8bc4\u8bba\uff0c\u597d\u8bc4-\u5dee\u8bc4   \n- \u53c2\u8003\uff1a   \n  - [Python \u6587\u672c\u6316\u6398\uff1a\u4f7f\u7528scikit-learn \u673a\u5668\u5b66\u4e60\u5305\u8fdb\u884c\u6587\u672c\u5206\u7c7b ](http://rzcoding.blog.163.com/)\n\n## \u8d1d\u53f6\u65af\u5206\u7c7b   \n- \u7528C/C++\u91cd\u65b0\u5b9e\u73b0\u540e\uff0c\u53d1\u73b0\u5185\u5b58\u5360\u7528\u7387\u548c\u8fd0\u7b97\u901f\u5ea6\u6bd4Python\u8981\u5757\u5f88\u591a\u3002   \n- \u901a\u8fc7Sogou\u7684\u8bad\u7ec3\u8bed\u6599\u53d1\u73b0\uff0c10\u4e2a\u5206\u7c7b\u4e0b\uff0c10000\u7279\u5f81\u8bcd\u7684\u5206\u7c7b\u51c6\u786e\u7387\u572875%\u5de6\u53f3\uff0c\u800c\u5728\u4eac\u4e1c\u6293\u53d6\u7684\u597d\u8bc4/\u5dee\u8bc4\u8bed\u6599\u8bad\u7ec3\u540e\uff0c\u6d4b\u8bd5\u5206\u7c7b\u7cbe\u5ea6\u8fbe\u523091%\u5de6\u53f3\u3002   \n\n## \u6700\u5927\u71b5\u5206\u7c7b\u5668   \n- \u539f\u7406\uff1a\u81ea\u884cGoogle   \n- \u53c2\u8003\uff1a   \n  - http://www.fuqingchuan.com/2015/03/776.html   \n  - http://www.nltk.org/_modules/nltk/classify/maxent.html   \n  - http://www.umiacs.umd.edu/~hal/megam/index.html   \n- NOTE\uff1a   \n  - \u57fa\u672c\u662f\u6309\u7167nltk\u7684GIS\u7b97\u6cd5\u7ffb\u8bd1\u8fc7\u6765\u7684\uff0c\u6ca1\u6709\u5b9e\u73b0IIS\uff0c\u6240\u4ee5\u8bad\u7ec3\u7684\u901f\u5ea6\u975e\u5e38\u7684\u6162\u3002\n- MEGAM   \n  - \u6dfb\u52a0\u4e86MEGAM\u90e8\u5206\uff0c\u5e95\u5c42\u8c03\u7528\u7684megam\u662f\u57fa\u4e8eL-BFGS\u5b9e\u73b0\u7684\uff0c\u6240\u4ee5\u901f\u5ea6\u8fd8\u662f\u633a\u5feb\u7684\uff0c\u6709\u5b9e\u7528\u4ef7\u503c\u4e86\u3002\u53e6\u5916\u5e95\u5c42\u8c03\u7528\u7684megam\u662f\n\u4e8c\u8fdb\u5236\u7a0b\u5e8f\uff0832\u4f4d\uff09\u7684\uff0c\u6240\u4ee5\u4f60\u7684\u7cfb\u7edf\u8981\u652f\u630132\u4f4d\u7684\u8fd0\u884c\u5e93\uff08dnf install glibc.i686\uff09\n\n## \u57fa\u4e8eCRF\u7684\uff08NER\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\uff09   \n- \u53c2\u8003\uff1a[CRFSuite Manual](http://www.chokkan.org/software/crfsuite/manual.html)   \n- TODO\uff1a   \n   - \u4eba\u5bb6\u5df2\u7ecf\u7406\u8bba\u5206\u6790\u4e86CRF\u7684\u6548\u679c\u4f1a\u6bd4\u8d1d\u53f6\u65af\u548c\u9a6c\u5c14\u79d1\u592b\u6a21\u578b\u8981\u597d\uff0c\u800c\u4e14CRF\u5f53\u524d\u6700\u4e3b\u8981\u7684\u5e94\u7528\u5c31\u662fNLP\u7684\u5206\u8bcd\u3001\u5e8f\u5217\u6807\u6ce8\u548c\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u4e86\u3002\u4e2a\u4eba\u6d4b\u8bd5\u89c9\u5f97\uff0c\u7b97\u6cd5\u7684\u6536\u655b\u7684\u901f\u5ea6\u5f88\u6162\uff0c\u6240\u4ee5\u6a21\u578b\u53ea\u8fed\u4ee3\u8bad\u7ec3\u4e86\u4e94\u767e\u6b21\u3002\u6b64\u5916\uff0c\u73b0\u5728\u7684\u7b97\u6cd5\u90fd\u5341\u5206\u7684\u6210\u719f\u4e86\uff0c\u800c\u771f\u6b63\u7684\u58c1\u5792\u5728\u4e8e\u6570\u636e\uff0c\u56fd\u5185\u7684\u5f00\u53d1\u6bd4\u8f83\u7684\u4fdd\u5b88\uff0c\u516c\u5f00\u7684\u6807\u6ce8\u8bed\u6599\u5c11\u4e4b\u53c8\u5c11\u3002\u4eba\u6c11\u65e5\u62a5\u7684\u6807\u6ce8\u8bed\u6599\u516c\u5f00\u7684\u90e8\u5206\u4e0d\u591a\uff0c\u800c\u4e14\u6587\u5b57\u6bd4\u8f83\u7684\u4e66\u9762\u548c\u5b88\u65e7\uff0c\u6548\u679c\u4e00\u822c\u3002   \n   - \u4f8b\u5b50   \n   > \u8fd8\u5f97\u4ece20\u5e74\u524d\u4e2dB-ORG \u5171I-ORG \u53ec\u5f00\u5341\u4e8c\u5927\u524d\u5915\u8bf4\u8d77\u30021982\u5e746\u670827\u65e5\u81f329\u65e5\u7684\u4e2dB-ORG \u5171I-ORG \u5341\u4e00\u5c4a\u516d\u4e2d\u5168\u4f1a\u671f\u95f4\uff0c\u5370\u53d1\u4e86\u9648B-PER \u4e91I-PER \u64b0\u5199\u7684\u300a\u63d0\u62d4\u57f9\u517b\u4e2d\u9752\u5e74\u5e72\u90e8\u662f\u5f53\u52a1\u4e4b\u6025\u300b\u4e00\u6587\u548c\u4ed6\u4e3b\u6301\u8d77\u8349\u7684\u300a\u5173\u4e8e\u8001\u5e72\u90e8\u79bb\u4f11\u9000\u4f11\u95ee\u9898\u5ea7\u8c08\u4f1a\u7eaa\u8981\u300b\u3002\u4f1a\u540e\uff0c\u90e8\u5206\u4e0e\u4f1a\u4eba\u5458\u7559\u4e0b\u6765\u53c2\u52a0\u5404\u7701\u5e02\u81eaB-ORG \u6cbbI-ORG \u533aI-ORG \u515aI-ORG \u59d4I-ORG \u4e66\u8bb0\u5ea7\u8c08\u4f1a\u30027\u67082\u65e5\uff0c\u9648B-PER \u4e91I-PER \u5728\u5ea7\u8c08\u4f1a\u4e0a\u8bb2\u8bdd\uff0c\u5f3a\u8c03\u5e72\u90e8\u961f\u4f0d\u9752\u9ec4\u4e0d\u63a5\u7684\u5ba2\u89c2\u5b58\u5728\uff0c\u4e0d\u65e0\u62c5\u5fe7\u5730\u8bf4\uff1a\u63d0\u4e94\u5341\u5c81\u5de6\u53f3\u7684\u4eba\u53ef\u80fd\u4e89\u8bba\u5c11\u4e9b\uff0c\u63d040\u5c81\u5de6\u53f3\u7684\u4eba\uff0c\u4e89\u8bba\u3001\u6000\u7591\u4f1a\u5f88\u591a\u3002\u63d040\u5c81\u4ee5\u4e0b\u7684\u4eba\uff0c\u6000\u7591\u3001\u4e89\u8bba\u4f1a\u66f4\u591a\u3002\u65e2\u7136\u5982\u6b64\uff0c\u4e3a\u4ec0\u4e48\u201c\u7eaa\u8981\u201d\u8fd8\u662f\u201c\u7279\u522b\u5199\u63d0\u56db\u5341\u5c81\u4ee5\u4e0b\u7684\u4eba\u8fd9\u4e00\u53e5\uff1f\u201d\u4ed6\u81ea\u95ee\u81ea\u7b54\uff1a\u4e00\u662f\u5e74\u5bcc\u529b\u5f3a\u3002\u4e8c\u662f\u6709\u610f\u8bc6\u5730\u57f9\u517b\u3002\u7ecf\u8fc73\u5e74\u30015\u5e74\u300110\u5e74\uff0c\u6709\u610f\u8bc6\u5730\u57f9\u517b\uff0c\u9009\u51fa\u597d\u7684\u4eba\u3002\u4e09\u662f40\u5c81\u4ee5\u4e0b\u7684\u4eba\u4e2d\u95f4\u6709\u4eba\u624d\u3002\u56db\u662f\u53ea\u670940\u5c81\u4ee5\u4e0b\u7684\u4eba\uff0c\u624d\u4e86\u89e3\u201c\u6587\u9769\u201d\u521d\u671f\u9752\u5e74\u4eba\u5f53\u65f6\u7684\u60f3\u6cd5\u548c\u8868\n\n## \u57fa\u4e8e\u540c\u4e49\u8bcd\u8bcd\u6797\u7684\u6d88\u6b67\u5b9e\u73b0\uff1a   \n- \u539f\u7406\uff1a\u57fa\u4e8e\u540c\u4e49\u8bcd\u8bcd\u6797\u7684\u8bed\u6599\u5e93\u53cd\u67e5\uff0c\u8bbe\u5b9a\u5404\u4e2a\u610f\u9879\u7684\u8bc4\u5206\u3002   \n- \u7ed3\u679c\uff1a\u4e0d\u77e5\u9053\u662f\u8fd9\u79cd\u65b9\u5f0f\u7684\u539f\u56e0\uff0c\u8fd8\u662f\u8bc4\u5206\u51fd\u6570\u4f18\u5316\u7684\u4e0d\u5408\u7406\uff0c\u5728\u6807\u6ce8\u7684\u8bed\u6599\u4e0b\uff0c\u51c6\u786e\u5ea6\u5927\u698244%\u5de6\u53f3\u3002   \n\n# \u6df1\u5ea6\u5b66\u4e60\u90e8\u5206   \n## \u4f9d\u8d56\u548c\u4f7f\u7528\u7684\u6df1\u5ea6\u5b66\u4e60\u5e93   \n  - theano (CUDA optional)   \n  - keras   \n  - genism   \n\n\n## \u6df1\u5ea6\u5b66\u4e60\u5206\u8bcd\n- \u53c2\u8003\uff1ahttp://xccds1977.blogspot.com/2015/11/blog-post_25.html   \n- \u8bed\u6599\u5e93\uff1a[\u5317\u5927\u548c\u5fae\u8f6f\u7814\u7a76\u9662\u7684\u5206\u8bcd\u8bed\u6599](http://www.sighan.org/bakeoff2005/)   \n- TODO:   \n  - \u5bf9\u4e8e\u82f1\u6587\u5355\u8bcd\u548c\u6570\u5b57\u7684\u5904\u7406   \n  - \u52a0\u5927\u795e\u7ecf\u7f51\u7edc\u7684\u795e\u7ecf\u8282\u70b9\u6570\u76ee   \n- \u5206\u8bcd\u6548\u679c(LSTM 100-100 4\u7c7b\u6807\u6ce8 15\u6b21\u8fed\u4ee3):   \n> \u4e2d\u4e1c \u548c\u5e73 \u7684 \u5efa\u8bbe\u8005 \u3001 \u4e2d\u4e1c \u53d1\u5c55 \u7684 \u63a8\u52a8 \u8005 \u3001 \u4e2d\u4e1c \u5de5\u4e1a\u5316 \u7684 \u52a9 \u63a8 \u8005 \u3001 \u4e2d\u4e1c \u7a33\u5b9a \u7684 \u652f\u6301\u8005 \u3001 \u4e2d\u4e1c \u6c11\u5fc3 \u4ea4\u878d \u7684 \u5408\u4f5c \u4f19\u4f34 \u2014\u2014 \u4e60\u8fd1 \u5e73 \u4e3b\u5e2d \u5728 \u6f14\u8bb2 \u4e2d \u4e3a \u4e2d\u56fd-\u4e2d\u4e1c\u5173\u7cfb \u53d1\u5c55 \u6307\u660e \u7684 \u65b9\u5411 \uff0c \u5207\u5408 \u5730\u533a \u5b9e\u9645 \u60c5\u51b5 \uff0c \u7167\u987e \u5730\u533a \u56fd\u5bb6 \u5173\u5207 \uff0c \u4e3a \u6446 \u5728 \u56fd\u9645 \u793e\u4f1a \u9762\u524d \u7684 \u201c \u4e2d\u4e1c \u4e4b \u95ee \u201d \u7ed9 \u51fa \u4e86 \u4e2d\u56fd \u7684 \u7b54\u6848 \u3002 \n> 2014\u5e746 \u6708 \uff0c \u4e60\u8fd1 \u5e73\u5728 \u4e2d \u963f \u5408\u4f5c \u8bba\u575b \u5317\u4eac \u90e8\u957f \u7ea7 \u4f1a\u8bae \u4e0a \u63d0\u51fa \uff0c \u4e2d \u963f \u5171\u5efa \u201c \u4e00\u5e26 \u4e00\u8def \u201d \uff0c \u6784\u5efa \u4ee5 \u80fd\u6e90 \u5408\u4f5c \u4e3a \u4e3b\u8f74 \uff0c \u4ee5 \u57fa\u7840 \u8bbe\u65bd \u5efa\u8bbe \u3001 \u8d38\u6613 \u548c \u6295\u8d44 \u4fbf\u5229 \u5316 \u4e3a \u4e24\u7ffc \uff0c \u4ee5 \u6838\u80fd \u3001 \u822a\u5929 \u536b\u661f \u3001 \u65b0 \u80fd\u6e90 \u4e09 \u5927 \u9ad8 \u65b0 \u9886\u57df \u4e3a \u65b0 \u7684 \u7a81\u7834\u53e3 \u7684 \u201c 1 + 2 + 3 \u201d \u5408\u4f5c \u683c\u5c40 \u3002 \n> \u5728 \u6b64\u6b21 \u843d\u9a6c \u7684 16 \u4eba \u91cc\u9762 \uff0c \u7ea7\u522b \u6700\u9ad8 \u7684 \u662f \u8fde \u57ce\u53bf\u59d4 \u539f \u4e66\u8bb0 \u6c5f\u56fd\u6cb3 \u3002 \u5c65\u5386 \u663e\u793a \uff0c \u6c5f \u56fd\u6cb3 196 3\u5e74 \u51fa\u751f \uff0c \u9f99\u5ca9\u5e02 \u6c38\u5b9a\u53bf \u9ad8\u5934\u4e61 \u4eba \u3002 \u88ab \u8c03\u67e5 \u65f6 \uff0c \u4ed6 \u5df2 \u5728 \u798f\u5efa\u7701 \u80fd\u6e90\u96c6\u56e2\u6709\u9650\u8d23\u4efb \u516c\u53f8 \u8463\u4e8b \u3001 \u7eaa\u59d4 \u4e66\u8bb0 \u7684 \u4f4d\u5b50 \u4e0a \u5e72 \u4e86 \u4e24\u5e74 \u3002 \n> \u673a\u667a\u5802 \u662f \u65b0 \u6d6a \u624b\u673a \u63a8\u51fa \u7684 \u65b0 \u680f\u76ee \uff0c \u98ce\u8da3 \u5e7d\u9ed8 \u662f \u6211\u4eec \u7684 \u57fa\u8c03 \uff0c \u76f4\u767d \u7b80\u5355 \u5730 \u666e\u53ca \u624b\u673a \u6280\u672f \u77e5\u8bc6 \u662f \u6211\u4eec \u7684 \u76ee\u7684 \u3002 \u6211\u4eec \u8c08 \u624b\u673a \uff0c \u4e5f \u8c08 \u624b \u673a \u5708 \u7684 \u6709 \u8da3\u4e8b \uff0c \u6bcf\u6708 \u5b9a\u671f \u66f4\u65b0 \uff0c \u641e \u673a \u7231\u597d\u8005 \u4eec \u5343\u4e07 \u4e0d \u80fd \u9519\u8fc7 \u3002 \n\n\n## RNN-LSTM\u81ea\u52a8\u6587\u672c\u751f\u6210   \n- \u53c2\u8003\uff1a   \n  - [RNN Character Model - 2 Layer](https://github.com/ebenolson/pydata2015/blob/master/4%20-%20Recurrent%20Networks/RNN%20Character%20Model%20-%202%20Layer.ipynb)   \n  - [char-rnn](https://github.com/karpathy/char-rnn)   \n  - [lstm_text_generation](https://github.com/fchollet/keras/blob/master/examples/lstm_text_generation.py)   \n"}, {"repo": "/Neilpang/acme.sh", "language": "Shell", "readme_contents": "# An ACME Shell script: acme.sh [![Build Status](https://travis-ci.org/Neilpang/acme.sh.svg?branch=master)](https://travis-ci.org/Neilpang/acme.sh)\n\n<a href=\"https://opencollective.com/acmesh\" alt=\"Financial Contributors on Open Collective\"><img src=\"https://opencollective.com/acmesh/all/badge.svg?label=financial+contributors\" /></a> [![Join the chat at https://gitter.im/acme-sh/Lobby](https://badges.gitter.im/acme-sh/Lobby.svg)](https://gitter.im/acme-sh/Lobby?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge)\n- An ACME protocol client written purely in Shell (Unix shell) language.\n- Full ACME protocol implementation.\n- Support ACME v1 and ACME v2\n- Support ACME v2 wildcard certs\n- Simple, powerful and very easy to use. You only need 3 minutes to learn it.\n- Bash, dash and sh compatible.\n- Simplest shell script for Let's Encrypt free certificate client.\n- Purely written in Shell with no dependencies on python or the official Let's Encrypt client.\n- Just one script to issue, renew and install your certificates automatically.\n- DOES NOT require `root/sudoer` access.\n- Docker friendly\n- IPv6 support\n- Cron job notifications for renewal or error etc.\n\nIt's probably the `easiest & smartest` shell script to automatically issue & renew the free certificates from Let's Encrypt.\n\nWiki: https://github.com/Neilpang/acme.sh/wiki\n\nFor Docker Fans: [acme.sh :two_hearts: Docker ](https://github.com/Neilpang/acme.sh/wiki/Run-acme.sh-in-docker)\n\nTwitter: [@neilpangxa](https://twitter.com/neilpangxa)\n\n\n# [\u4e2d\u6587\u8bf4\u660e](https://github.com/Neilpang/acme.sh/wiki/%E8%AF%B4%E6%98%8E)\n\n# Who:\n- [FreeBSD.org](https://blog.crashed.org/letsencrypt-in-freebsd-org/)\n- [ruby-china.org](https://ruby-china.org/topics/31983)\n- [Proxmox](https://pve.proxmox.com/wiki/HTTPS_Certificate_Configuration_(Version_4.x_and_newer))\n- [pfsense](https://github.com/pfsense/FreeBSD-ports/pull/89)\n- [webfaction](https://community.webfaction.com/questions/19988/using-letsencrypt)\n- [Loadbalancer.org](https://www.loadbalancer.org/blog/loadbalancer-org-with-lets-encrypt-quick-and-dirty)\n- [discourse.org](https://meta.discourse.org/t/setting-up-lets-encrypt/40709)\n- [Centminmod](https://centminmod.com/letsencrypt-acmetool-https.html)\n- [splynx](https://forum.splynx.com/t/free-ssl-cert-for-splynx-lets-encrypt/297)\n- [archlinux](https://www.archlinux.org/packages/community/any/acme.sh)\n- [opnsense.org](https://github.com/opnsense/plugins/tree/master/security/acme-client/src/opnsense/scripts/OPNsense/AcmeClient)\n- [CentOS Web Panel](http://centos-webpanel.com/)\n- [lnmp.org](https://lnmp.org/)\n- [more...](https://github.com/Neilpang/acme.sh/wiki/Blogs-and-tutorials)\n\n# Tested OS\n\n| NO | Status| Platform|\n|----|-------|---------|\n|1|[![](https://neilpang.github.io/acmetest/status/ubuntu-latest.svg)](https://github.com/Neilpang/letest#here-are-the-latest-status)| Ubuntu\n|2|[![](https://neilpang.github.io/acmetest/status/debian-latest.svg)](https://github.com/Neilpang/letest#here-are-the-latest-status)| Debian\n|3|[![](https://neilpang.github.io/acmetest/status/centos-latest.svg)](https://github.com/Neilpang/letest#here-are-the-latest-status)|CentOS\n|4|[![](https://neilpang.github.io/acmetest/status/windows-cygwin.svg)](https://github.com/Neilpang/letest#here-are-the-latest-status)|Windows (cygwin with curl, openssl and crontab included)\n|5|[![](https://neilpang.github.io/acmetest/status/freebsd.svg)](https://github.com/Neilpang/letest#here-are-the-latest-status)|FreeBSD\n|6|[![](https://neilpang.github.io/acmetest/status/pfsense.svg)](https://github.com/Neilpang/letest#here-are-the-latest-status)|pfsense\n|7|[![](https://neilpang.github.io/acmetest/status/opensuse-latest.svg)](https://github.com/Neilpang/letest#here-are-the-latest-status)|openSUSE\n|8|[![](https://neilpang.github.io/acmetest/status/alpine-latest.svg)](https://github.com/Neilpang/letest#here-are-the-latest-status)|Alpine Linux (with curl)\n|9|[![](https://neilpang.github.io/acmetest/status/base-archlinux.svg)](https://github.com/Neilpang/letest#here-are-the-latest-status)|Archlinux\n|10|[![](https://neilpang.github.io/acmetest/status/fedora-latest.svg)](https://github.com/Neilpang/letest#here-are-the-latest-status)|fedora\n|11|[![](https://neilpang.github.io/acmetest/status/kalilinux-kali-linux-docker.svg)](https://github.com/Neilpang/letest#here-are-the-latest-status)|Kali Linux\n|12|[![](https://neilpang.github.io/acmetest/status/oraclelinux-latest.svg)](https://github.com/Neilpang/letest#here-are-the-latest-status)|Oracle Linux\n|13|[![](https://neilpang.github.io/acmetest/status/proxmox.svg)](https://github.com/Neilpang/letest#here-are-the-latest-status)| Proxmox https://pve.proxmox.com/wiki/HTTPSCertificateConfiguration#Let.27s_Encrypt_using_acme.sh\n|14|-----| Cloud Linux  https://github.com/Neilpang/le/issues/111\n|15|[![](https://neilpang.github.io/acmetest/status/openbsd.svg)](https://github.com/Neilpang/letest#here-are-the-latest-status)|OpenBSD\n|16|[![](https://neilpang.github.io/acmetest/status/mageia.svg)](https://github.com/Neilpang/letest#here-are-the-latest-status)|Mageia\n|17|-----| OpenWRT: Tested and working. See [wiki page](https://github.com/Neilpang/acme.sh/wiki/How-to-run-on-OpenWRT)\n|18|[![](https://neilpang.github.io/acmetest/status/solaris.svg)](https://github.com/Neilpang/letest#here-are-the-latest-status)|SunOS/Solaris\n|19|[![](https://neilpang.github.io/acmetest/status/gentoo-stage3-amd64.svg)](https://github.com/Neilpang/letest#here-are-the-latest-status)|Gentoo Linux\n|20|[![Build Status](https://travis-ci.org/Neilpang/acme.sh.svg?branch=master)](https://travis-ci.org/Neilpang/acme.sh)|Mac OSX\n\nFor all build statuses, check our [weekly build project](https://github.com/Neilpang/acmetest):\n\nhttps://github.com/Neilpang/acmetest\n\n# Supported CA\n\n- Letsencrypt.org CA(default)\n- [BuyPass.com CA](https://github.com/Neilpang/acme.sh/wiki/BuyPass.com-CA)\n- [Pebble strict Mode](https://github.com/letsencrypt/pebble)\n\n# Supported modes\n\n- Webroot mode\n- Standalone mode\n- Standalone tls-alpn mode\n- Apache mode\n- Nginx mode\n- DNS mode\n- [DNS alias mode](https://github.com/Neilpang/acme.sh/wiki/DNS-alias-mode)\n- [Stateless mode](https://github.com/Neilpang/acme.sh/wiki/Stateless-Mode)\n\n\n# 1. How to install\n\n### 1. Install online\n\nCheck this project: https://github.com/Neilpang/get.acme.sh\n\n```bash\ncurl https://get.acme.sh | sh\n```\n\nOr:\n\n```bash\nwget -O -  https://get.acme.sh | sh\n```\n\n\n### 2. Or, Install from git\n\nClone this project and launch installation:\n\n```bash\ngit clone https://github.com/Neilpang/acme.sh.git\ncd ./acme.sh\n./acme.sh --install\n```\n\nYou `don't have to be root` then, although `it is recommended`.\n\nAdvanced Installation: https://github.com/Neilpang/acme.sh/wiki/How-to-install\n\nThe installer will perform 3 actions:\n\n1. Create and copy `acme.sh` to your home dir (`$HOME`): `~/.acme.sh/`.\nAll certs will be placed in this folder too.\n2. Create alias for: `acme.sh=~/.acme.sh/acme.sh`.\n3. Create daily cron job to check and renew the certs if needed.\n\nCron entry example:\n\n```bash\n0 0 * * * \"/home/user/.acme.sh\"/acme.sh --cron --home \"/home/user/.acme.sh\" > /dev/null\n```\n\nAfter the installation, you must close the current terminal and reopen it to make the alias take effect.\n\nOk, you are ready to issue certs now.\n\nShow help message:\n\n```sh\nroot@v1:~# acme.sh -h\n```\n\n# 2. Just issue a cert\n\n**Example 1:** Single domain.\n\n```bash\nacme.sh --issue -d example.com -w /home/wwwroot/example.com\n```\n\nor:\n\n```bash\nacme.sh --issue -d example.com -w /home/username/public_html\n```\n\nor:\n\n```bash\nacme.sh --issue -d example.com -w /var/www/html\n```\n\n**Example 2:** Multiple domains in the same cert.\n\n```bash\nacme.sh --issue -d example.com -d www.example.com -d cp.example.com -w /home/wwwroot/example.com\n```\n\nThe parameter `/home/wwwroot/example.com` or `/home/username/public_html` or `/var/www/html` is the web root folder where you host your website files. You **MUST** have `write access` to this folder.\n\nSecond argument **\"example.com\"** is the main domain you want to issue the cert for.\nYou must have at least one domain there.\n\nYou must point and bind all the domains to the same webroot dir: `/home/wwwroot/example.com`.\n\nThe certs will be placed in `~/.acme.sh/example.com/`\n\nThe certs will be renewed automatically every **60** days.\n\nMore examples: https://github.com/Neilpang/acme.sh/wiki/How-to-issue-a-cert\n\n\n# 3. Install the cert to Apache/Nginx etc.\n\nAfter the cert is generated, you probably want to install/copy the cert to your Apache/Nginx or other servers.\nYou **MUST** use this command to copy the certs to the target files, **DO NOT** use the certs files in **~/.acme.sh/** folder, they are for internal use only, the folder structure may change in the future.\n\n**Apache** example:\n```bash\nacme.sh --install-cert -d example.com \\\n--cert-file      /path/to/certfile/in/apache/cert.pem  \\\n--key-file       /path/to/keyfile/in/apache/key.pem  \\\n--fullchain-file /path/to/fullchain/certfile/apache/fullchain.pem \\\n--reloadcmd     \"service apache2 force-reload\"\n```\n\n**Nginx** example:\n```bash\nacme.sh --install-cert -d example.com \\\n--key-file       /path/to/keyfile/in/nginx/key.pem  \\\n--fullchain-file /path/to/fullchain/nginx/cert.pem \\\n--reloadcmd     \"service nginx force-reload\"\n```\n\nOnly the domain is required, all the other parameters are optional.\n\nThe ownership and permission info of existing files are preserved. You can pre-create the files to define the ownership and permission.\n\nInstall/copy the cert/key to the production Apache or Nginx path.\n\nThe cert will be renewed every **60** days by default (which is configurable). Once the cert is renewed, the Apache/Nginx service will be reloaded automatically by the command: `service apache2 force-reload` or `service nginx force-reload`.\n\n\n**Please take care:  The reloadcmd is very important. The cert can be automatically renewed, but, without a correct 'reloadcmd' the cert may not be flushed to your server(like nginx or apache), then your website will not be able to show renewed cert in 60 days.**\n\n# 4. Use Standalone server to issue cert\n\n**(requires you to be root/sudoer or have permission to listen on port 80 (TCP))**\n\nPort `80` (TCP) **MUST** be free to listen on, otherwise you will be prompted to free it and try again.\n\n```bash\nacme.sh --issue --standalone -d example.com -d www.example.com -d cp.example.com\n```\n\nMore examples: https://github.com/Neilpang/acme.sh/wiki/How-to-issue-a-cert\n\n# 5. Use Standalone ssl server to issue cert\n\n**(requires you to be root/sudoer or have permission to listen on port 443 (TCP))**\n\nPort `443` (TCP) **MUST** be free to listen on, otherwise you will be prompted to free it and try again.\n\n```bash\nacme.sh --issue --alpn -d example.com -d www.example.com -d cp.example.com\n```\n\nMore examples: https://github.com/Neilpang/acme.sh/wiki/How-to-issue-a-cert\n\n\n# 6. Use Apache mode\n\n**(requires you to be root/sudoer, since it is required to interact with Apache server)**\n\nIf you are running a web server, Apache or Nginx, it is recommended to use the `Webroot mode`.\n\nParticularly, if you are running an Apache server, you can use Apache mode instead. This mode doesn't write any files to your web root folder.\n\nJust set string \"apache\" as the second argument and it will force use of apache plugin automatically.\n\n```sh\nacme.sh --issue --apache -d example.com -d www.example.com -d cp.example.com\n```\n\n**This apache mode is only to issue the cert, it will not change your apache config files.\nYou will need to configure your website config files to use the cert by yourself.\nWe don't want to mess your apache server, don't worry.**\n\nMore examples: https://github.com/Neilpang/acme.sh/wiki/How-to-issue-a-cert\n\n# 7. Use Nginx mode\n\n**(requires you to be root/sudoer, since it is required to interact with Nginx server)**\n\nIf you are running a web server, Apache or Nginx, it is recommended to use the `Webroot mode`.\n\nParticularly, if you are running an nginx server, you can use nginx mode instead. This mode doesn't write any files to your web root folder.\n\nJust set string \"nginx\" as the second argument.\n\nIt will configure nginx server automatically to verify the domain and then restore the nginx config to the original version.\n\nSo, the config is not changed.\n\n```sh\nacme.sh --issue --nginx -d example.com -d www.example.com -d cp.example.com\n```\n\n**This nginx mode is only to issue the cert, it will not change your nginx config files.\nYou will need to configure your website config files to use the cert by yourself.\nWe don't want to mess your nginx server, don't worry.**\n\nMore examples: https://github.com/Neilpang/acme.sh/wiki/How-to-issue-a-cert\n\n# 8. Automatic DNS API integration\n\nIf your DNS provider supports API access, we can use that API to automatically issue the certs.\n\nYou don't have to do anything manually!\n\n### Currently acme.sh supports most of the dns providers:\n\nhttps://github.com/Neilpang/acme.sh/wiki/dnsapi\n\n# 9. Use DNS manual mode:\n\nSee: https://github.com/Neilpang/acme.sh/wiki/dns-manual-mode first.\n\nIf your dns provider doesn't support any api access, you can add the txt record by your hand.\n\n```bash\nacme.sh --issue --dns -d example.com -d www.example.com -d cp.example.com\n```\n\nYou should get an output like below:\n\n```sh\nAdd the following txt record:\nDomain:_acme-challenge.example.com\nTxt value:9ihDbjYfTExAYeDs4DBUeuTo18KBzwvTEjUnSwd32-c\n\nAdd the following txt record:\nDomain:_acme-challenge.www.example.com\nTxt value:9ihDbjxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n\nPlease add those txt records to the domains. Waiting for the dns to take effect.\n```\n\nThen just rerun with `renew` argument:\n\n```bash\nacme.sh --renew -d example.com\n```\n\nOk, it's done.\n\n**Take care, this is dns manual mode, it can not be renewed automatically. you will have to add a new txt record to your domain by your hand when you renew your cert.**\n\n**Please use dns api mode instead.**\n\n# 10. Issue ECC certificates\n\n`Let's Encrypt` can now issue **ECDSA** certificates.\n\nAnd we support them too!\n\nJust set the `keylength` parameter with a prefix `ec-`.\n\nFor example:\n\n### Single domain ECC certificate\n\n```bash\nacme.sh --issue -w /home/wwwroot/example.com -d example.com --keylength ec-256\n```\n\n### SAN multi domain ECC certificate\n\n```bash\nacme.sh --issue -w /home/wwwroot/example.com -d example.com -d www.example.com --keylength ec-256\n```\n\nPlease look at the `keylength` parameter above.\n\nValid values are:\n\n1. **ec-256 (prime256v1, \"ECDSA P-256\")**\n2. **ec-384 (secp384r1,  \"ECDSA P-384\")**\n3. **ec-521 (secp521r1,  \"ECDSA P-521\", which is not supported by Let's Encrypt yet.)**\n\n\n\n# 11. Issue Wildcard certificates\n\nIt's simple, just give a wildcard domain as the `-d` parameter.\n\n```sh\nacme.sh  --issue -d example.com  -d '*.example.com'  --dns dns_cf\n```\n\n\n\n# 12. How to renew the certs\n\nNo, you don't need to renew the certs manually. All the certs will be renewed automatically every **60** days.\n\nHowever, you can also force to renew a cert:\n\n```sh\nacme.sh --renew -d example.com --force\n```\n\nor, for ECC cert:\n\n```sh\nacme.sh --renew -d example.com --force --ecc\n```\n\n\n# 13. How to stop cert renewal\n\nTo stop renewal of a cert, you can execute the following to remove the cert from the renewal list:\n\n```sh\nacme.sh --remove -d example.com [--ecc]\n```\n\nThe cert/key file is not removed from the disk.\n\nYou can remove the respective directory (e.g. `~/.acme.sh/example.com`) by yourself.\n\n\n# 14. How to upgrade `acme.sh`\n\nacme.sh is in constant development, so it's strongly recommended to use the latest code.\n\nYou can update acme.sh to the latest code:\n\n```sh\nacme.sh --upgrade\n```\n\nYou can also enable auto upgrade:\n\n```sh\nacme.sh --upgrade --auto-upgrade\n```\n\nThen **acme.sh** will be kept up to date automatically.\n\nDisable auto upgrade:\n\n```sh\nacme.sh --upgrade --auto-upgrade 0\n```\n\n\n# 15. Issue a cert from an existing CSR\n\nhttps://github.com/Neilpang/acme.sh/wiki/Issue-a-cert-from-existing-CSR\n\n\n# 16. Send notifications in cronjob\n\nhttps://github.com/Neilpang/acme.sh/wiki/notify\n\n\n# 17. Under the Hood\n\nSpeak ACME language using shell, directly to \"Let's Encrypt\".\n\nTODO:\n\n\n# 18. Acknowledgments\n\n1. Acme-tiny: https://github.com/diafygi/acme-tiny\n2. ACME protocol: https://github.com/ietf-wg-acme/acme\n\n\n## Contributors\n\n### Code Contributors\n\nThis project exists thanks to all the people who contribute. [[Contribute](CONTRIBUTING.md)].\n<a href=\"https://github.com/Neilpang/acme.sh/graphs/contributors\"><img src=\"https://opencollective.com/acmesh/contributors.svg?width=890&button=false\" /></a>\n\n### Financial Contributors\n\nBecome a financial contributor and help us sustain our community. [[Contribute](https://opencollective.com/acmesh/contribute)]\n\n#### Individuals\n\n<a href=\"https://opencollective.com/acmesh\"><img src=\"https://opencollective.com/acmesh/individuals.svg?width=890\"></a>\n\n#### Organizations\n\nSupport this project with your organization. Your logo will show up here with a link to your website. [[Contribute](https://opencollective.com/acmesh/contribute)]\n\n<a href=\"https://opencollective.com/acmesh/organization/0/website\"><img src=\"https://opencollective.com/acmesh/organization/0/avatar.svg\"></a>\n<a href=\"https://opencollective.com/acmesh/organization/1/website\"><img src=\"https://opencollective.com/acmesh/organization/1/avatar.svg\"></a>\n<a href=\"https://opencollective.com/acmesh/organization/2/website\"><img src=\"https://opencollective.com/acmesh/organization/2/avatar.svg\"></a>\n<a href=\"https://opencollective.com/acmesh/organization/3/website\"><img src=\"https://opencollective.com/acmesh/organization/3/avatar.svg\"></a>\n<a href=\"https://opencollective.com/acmesh/organization/4/website\"><img src=\"https://opencollective.com/acmesh/organization/4/avatar.svg\"></a>\n<a href=\"https://opencollective.com/acmesh/organization/5/website\"><img src=\"https://opencollective.com/acmesh/organization/5/avatar.svg\"></a>\n<a href=\"https://opencollective.com/acmesh/organization/6/website\"><img src=\"https://opencollective.com/acmesh/organization/6/avatar.svg\"></a>\n<a href=\"https://opencollective.com/acmesh/organization/7/website\"><img src=\"https://opencollective.com/acmesh/organization/7/avatar.svg\"></a>\n<a href=\"https://opencollective.com/acmesh/organization/8/website\"><img src=\"https://opencollective.com/acmesh/organization/8/avatar.svg\"></a>\n<a href=\"https://opencollective.com/acmesh/organization/9/website\"><img src=\"https://opencollective.com/acmesh/organization/9/avatar.svg\"></a>\n\n# 19. License & Others\n\nLicense is GPLv3\n\nPlease Star and Fork me.\n\n[Issues](https://github.com/Neilpang/acme.sh/issues) and [pull requests](https://github.com/Neilpang/acme.sh/pulls) are welcome.\n\n\n# 20. Donate\nYour donation makes **acme.sh** better:\n\n1. PayPal/Alipay(\u652f\u4ed8\u5b9d)/Wechat(\u5fae\u4fe1): [https://donate.acme.sh/](https://donate.acme.sh/)\n\n[Donate List](https://github.com/Neilpang/acme.sh/wiki/Donate-list)\n"}, {"repo": "/marcuswestin/WebViewJavascriptBridge", "language": "Objective-C", "readme_contents": "WebViewJavascriptBridge\n=======================\n\n[![Circle CI](https://img.shields.io/circleci/project/github/marcuswestin/WebViewJavascriptBridge.svg)](https://circleci.com/gh/marcuswestin/WebViewJavascriptBridge)\n\nAn iOS/OSX bridge for sending messages between Obj-C and JavaScript in WKWebViews, UIWebViews & WebViews.\n\nMigration Guide\n---------------\n\nWhen upgrading from v5.0.x to 6.0.x you will have to update the `setupWebViewJavascriptBridge` javascript snippet. See https://github.com/marcuswestin/WebViewJavascriptBridge#usage part 4).\n\nWho uses WebViewJavascriptBridge?\n---------------------------------\nWebViewJavascriptBridge is used by a range of companies and projects. This is a small and incomplete sample list:\n\n- [Facebook Messenger](https://www.facebook.com/mobile/messenger)\n- [Facebook Paper](https://facebook.com/paper)\n- [Yardsale](http://www.getyardsale.com/)\n- [EverTrue](http://www.evertrue.com/)\n- [Game Insight](http://www.game-insight.com/)\n- [Sush.io](http://www.sush.io)\n- [Imbed](http://imbed.github.io/)\n- [CareZone](https://carezone.com)\n- [Hemlig](http://www.hemlig.co)\n- [Altralogica](http://www.altralogica.it)\n- [\u9f0e\u76db\u4e2d\u534e](https://itunes.apple.com/us/app/ding-sheng-zhong-hua/id537273940?mt=8)\n- [FRIL](https://fril.jp)\n- [\u7559\u767d\u00b7WHITE](http://liubaiapp.com)\n- [BrowZine](http://thirdiron.com/browzine/)\n- ... & many more!\n\nInstallation (iOS & OSX)\n------------------------\n\n### Installation with CocoaPods\nAdd this to your [podfile](https://guides.cocoapods.org/using/getting-started.html) and run `pod install` to install:\n\n```ruby\npod 'WebViewJavascriptBridge', '~> 6.0'\n```\n\n### Manual installation\n\nDrag the `WebViewJavascriptBridge` folder into your project.\n\nIn the dialog that appears, uncheck \"Copy items into destination group's folder\" and select \"Create groups for any folders\".\n\nExamples\n--------\n\nSee the `Example Apps/` folder. Open either the iOS or OSX project and hit run to see it in action.\n\nTo use a WebViewJavascriptBridge in your own project:\n\nUsage\n-----\n\n1) Import the header file and declare an ivar property:\n\n```objc\n#import \"WebViewJavascriptBridge.h\"\n```\n\n...\n\n```objc\n@property WebViewJavascriptBridge* bridge;\n```\n\n2) Instantiate WebViewJavascriptBridge with a WKWebView, UIWebView (iOS) or WebView (OSX):\n\n```objc\nself.bridge = [WebViewJavascriptBridge bridgeForWebView:webView];\n```\n\n3) Register a handler in ObjC, and call a JS handler:\n\n```objc\n[self.bridge registerHandler:@\"ObjC Echo\" handler:^(id data, WVJBResponseCallback responseCallback) {\n\tNSLog(@\"ObjC Echo called with: %@\", data);\n\tresponseCallback(data);\n}];\n[self.bridge callHandler:@\"JS Echo\" data:nil responseCallback:^(id responseData) {\n\tNSLog(@\"ObjC received response: %@\", responseData);\n}];\n```\n\n4) Copy and paste `setupWebViewJavascriptBridge` into your JS:\n\t\n```javascript\nfunction setupWebViewJavascriptBridge(callback) {\n\tif (window.WebViewJavascriptBridge) { return callback(WebViewJavascriptBridge); }\n\tif (window.WVJBCallbacks) { return window.WVJBCallbacks.push(callback); }\n\twindow.WVJBCallbacks = [callback];\n\tvar WVJBIframe = document.createElement('iframe');\n\tWVJBIframe.style.display = 'none';\n\tWVJBIframe.src = 'https://__bridge_loaded__';\n\tdocument.documentElement.appendChild(WVJBIframe);\n\tsetTimeout(function() { document.documentElement.removeChild(WVJBIframe) }, 0)\n}\n```\n\n5) Finally, call `setupWebViewJavascriptBridge` and then use the bridge to register handlers and call ObjC handlers:\n\n```javascript\nsetupWebViewJavascriptBridge(function(bridge) {\n\t\n\t/* Initialize your app here */\n\n\tbridge.registerHandler('JS Echo', function(data, responseCallback) {\n\t\tconsole.log(\"JS Echo called with:\", data)\n\t\tresponseCallback(data)\n\t})\n\tbridge.callHandler('ObjC Echo', {'key':'value'}, function responseCallback(responseData) {\n\t\tconsole.log(\"JS received response:\", responseData)\n\t})\n})\n```\n\nAutomatic reference counting (ARC)\n----------------------------------\nThis library relies on ARC, so if you use ARC in you project, all works fine.\nBut if your project have no ARC support, be sure to do next steps:\n\n1) In your Xcode project open project settings -> 'Build Phases'\n\n2) Expand 'Compile Sources' header and find all *.m files which are belongs to this library. Make attention on the 'Compiler Flags' in front of each source file in this list\n\n3) For each file add '-fobjc-arc' flag\n\nNow all WVJB files will be compiled with ARC support.\n\nContributors & Forks\n--------------------\nContributors: https://github.com/marcuswestin/WebViewJavascriptBridge/graphs/contributors\n\nForks: https://github.com/marcuswestin/WebViewJavascriptBridge/network/members\n\nAPI Reference\n-------------\n\n### ObjC API\n\n##### `[WebViewJavascriptBridge bridgeForWebView:(WKWebVIew/UIWebView/WebView*)webview`\n\nCreate a javascript bridge for the given web view.\n\nExample:\n\n```objc\t\n[WebViewJavascriptBridge bridgeForWebView:webView];\n```\n\n##### `[bridge registerHandler:(NSString*)handlerName handler:(WVJBHandler)handler]`\n\nRegister a handler called `handlerName`. The javascript can then call this handler with `WebViewJavascriptBridge.callHandler(\"handlerName\")`.\n\nExample:\n\n```objc\n[self.bridge registerHandler:@\"getScreenHeight\" handler:^(id data, WVJBResponseCallback responseCallback) {\n\tresponseCallback([NSNumber numberWithInt:[UIScreen mainScreen].bounds.size.height]);\n}];\n[self.bridge registerHandler:@\"log\" handler:^(id data, WVJBResponseCallback responseCallback) {\n\tNSLog(@\"Log: %@\", data);\n}];\n\n```\n\n##### `[bridge callHandler:(NSString*)handlerName data:(id)data]`\n##### `[bridge callHandler:(NSString*)handlerName data:(id)data responseCallback:(WVJBResponseCallback)callback]`\n\nCall the javascript handler called `handlerName`. If a `responseCallback` block is given the javascript handler can respond.\n\nExample:\n\n```objc\n[self.bridge callHandler:@\"showAlert\" data:@\"Hi from ObjC to JS!\"];\n[self.bridge callHandler:@\"getCurrentPageUrl\" data:nil responseCallback:^(id responseData) {\n\tNSLog(@\"Current UIWebView page URL is: %@\", responseData);\n}];\n```\n\n#### `[bridge setWebViewDelegate:(id)webViewDelegate]`\n\nOptionally, set a `WKNavigationDelegate/UIWebViewDelegate` if you need to respond to the [web view's lifecycle events](https://developer.apple.com/reference/uikit/uiwebviewdelegate).\n\n##### `[bridge disableJavscriptAlertBoxSafetyTimeout]`\n\nUNSAFE. Speed up bridge message passing by disabling the setTimeout safety check. It is only safe to disable this safety check if you do not call any of the javascript popup box functions (alert, confirm, and prompt). If you call any of these functions from the bridged javascript code, the app will hang.\n\nExample:\n\n\t[self.bridge disableJavscriptAlertBoxSafetyTimeout];\n\n\n\n### Javascript API\n\n##### `bridge.registerHandler(\"handlerName\", function(responseData) { ... })`\n\nRegister a handler called `handlerName`. The ObjC can then call this handler with `[bridge callHandler:\"handlerName\" data:@\"Foo\"]` and `[bridge callHandler:\"handlerName\" data:@\"Foo\" responseCallback:^(id responseData) { ... }]`\n\nExample:\n\n```javascript\nbridge.registerHandler(\"showAlert\", function(data) { alert(data) })\nbridge.registerHandler(\"getCurrentPageUrl\", function(data, responseCallback) {\n\tresponseCallback(document.location.toString())\n})\n```\n\n\n##### `bridge.callHandler(\"handlerName\", data)`\n##### `bridge.callHandler(\"handlerName\", data, function responseCallback(responseData) { ... })`\n\nCall an ObjC handler called `handlerName`. If a `responseCallback` function is given the ObjC handler can respond.\n\nExample:\n\n```javascript\nbridge.callHandler(\"Log\", \"Foo\")\nbridge.callHandler(\"getScreenHeight\", null, function(response) {\n\talert('Screen height:' + response)\n})\n```\n\n\n##### `bridge.disableJavscriptAlertBoxSafetyTimeout()`\n\nCalling `bridge.disableJavscriptAlertBoxSafetyTimeout()` has the same effect as calling `[bridge disableJavscriptAlertBoxSafetyTimeout];` in ObjC.\n\nExample:\n\n```javascript\nbridge.disableJavscriptAlertBoxSafetyTimeout()\n```\n"}, {"repo": "/gitlabhq/gitlab-shell", "language": "Go", "readme_contents": "# GitLab Shell\n\n## GitLab Shell handles git SSH sessions for GitLab\n\nGitLab Shell handles git SSH sessions for GitLab and modifies the list of authorized keys.\nGitLab Shell is not a Unix shell nor a replacement for Bash or Zsh.\n\nWhen you access the GitLab server over SSH then GitLab Shell will:\n\n1. Limits you to predefined git commands (git push, git pull).\n1. Call the GitLab Rails API to check if you are authorized, and what Gitaly server your repository is on\n1. Copy data back and forth between the SSH client and the Gitaly server\n\nIf you access a GitLab server over HTTP(S) you end up in [gitlab-workhorse](https://gitlab.com/gitlab-org/gitlab-workhorse).\n\nAn overview of the four cases described above:\n\n1. git pull over SSH -> gitlab-shell -> API call to gitlab-rails (Authorization) -> accept or decline -> establish Gitaly session\n1. git push over SSH -> gitlab-shell (git command is not executed yet) -> establish Gitaly session -> (in Gitaly) gitlab-shell pre-receive hook -> API call to gitlab-rails (authorization) -> accept or decline push\n\n## Git hooks\n\nThe gitlab-shell repository used to also contain the\nGit hooks that allow GitLab to validate Git pushes (e.g. \"is this user\nallowed to push to this protected branch\"). These hooks also trigger\nevents in GitLab (e.g. to start a CI pipeline after a push).\n\nWe are in the process of moving these hooks to Gitaly, because Git hooks\nrequire direct disk access to Git repositories, and that is only\npossible on Gitaly servers. It makes no sense to have to install\ngitlab-shell on Gitaly servers.\n\nAs of GitLab 11.10  [the actual Git hooks are in the Gitaly\nrepository](https://gitlab.com/gitlab-org/gitaly/tree/v1.22.0/ruby/vendor/gitlab-shell/hooks),\nbut gitlab-shell must still be installed on Gitaly servers because the\nhooks rely on configuration data (e.g.\u00a0the GitLab internal API URL) that\nis not yet available in Gitaly itself. Also see the [transition\nplan](https://gitlab.com/gitlab-org/gitaly/issues/1226#note_126519133).\n\n## Code status\n\n[![pipeline status](https://gitlab.com/gitlab-org/gitlab-shell/badges/master/pipeline.svg)](https://gitlab.com/gitlab-org/gitlab-shell/commits/master)\n[![coverage report](https://gitlab.com/gitlab-org/gitlab-shell/badges/master/coverage.svg)](https://gitlab.com/gitlab-org/gitlab-shell/commits/master)\n[![Code Climate](https://codeclimate.com/github/gitlabhq/gitlab-shell.svg)](https://codeclimate.com/github/gitlabhq/gitlab-shell)\n\n## Requirements\n\nGitLab Shell is written in Go, and needs a Go compiler to build. It still requires\nRuby to build and test, but not to run.\n\nDownload and install the current version of Go from https://golang.org/dl/\n\n## Setup\n\n    make setup\n\n## Check\n\nChecks if GitLab API access and redis via internal API can be reached:\n\n    make check\n\n## Testing\n\nRun tests:\n\n    bundle install\n    make test\n\nRun gofmt and rubocop:\n\n    bundle install\n    make verify\n\nRun both test and verify (the default Makefile target):\n\n    bundle install\n    make validate\n\n## Git LFS remark\n\nStarting with GitLab 8.12, GitLab supports Git LFS authentication through SSH.\n\n## Releasing a new version\n\nGitLab Shell is versioned by git tags, and the version used by the Rails\napplication is stored in\n[`GITLAB_SHELL_VERSION`](https://gitlab.com/gitlab-org/gitlab-ce/blob/master/GITLAB_SHELL_VERSION).\n\nFor each version, there is a raw version and a tag version:\n\n- The **raw version** is the version number. For instance, `15.2.8`.\n- The **tag version** is the raw version prefixed with `v`. For instance, `v15.2.8`.\n\nTo release a new version of GitLab Shell and have that version available to the\nRails application:\n\n1. Update the [`CHANGELOG`](CHANGELOG) with the **tag version** and the\n   [`VERSION`](VERSION) file with the **raw version**.\n2. Add a new git tag with the **tag version**.\n3. Update `GITLAB_SHELL_VERSION` in the Rails application to the **raw\n   version**. (Note: this can be done as a separate MR to that, or in and MR\n   that will make use of the latest GitLab Shell changes.)\n\n## Contributing\n\nSee [CONTRIBUTING.md](./CONTRIBUTING.md).\n\n## License\n\nSee [LICENSE](./LICENSE).\n"}, {"repo": "/stleary/JSON-java", "language": "Java", "readme_contents": "JSON in Java [package org.json]\n===============================\n\n[![Maven Central](https://img.shields.io/maven-central/v/org.json/json.svg)](https://mvnrepository.com/artifact/org.json/json)\n\n**[Click here if you just want the latest release jar file.](https://repo1.maven.org/maven2/org/json/json/20190722/json-20190722.jar)**\n\nJSON is a light-weight, language independent, data interchange format.\nSee http://www.JSON.org/\n\nThe files in this package implement JSON encoders/decoders in Java.\nIt also includes the capability to convert between JSON and XML, HTTP\nheaders, Cookies, and CDL.\n\nThis is a reference implementation. There is a large number of JSON packages\nin Java. Perhaps someday the Java community will standardize on one. Until\nthen, choose carefully.\n\nThe license includes this restriction: \"The software shall be used for good,\nnot evil.\" If your conscience cannot live with that, then choose a different\npackage.\n\nThe package compiles on Java 1.6-1.8.\n\n\n**JSONObject.java**: The `JSONObject` can parse text from a `String` or a `JSONTokener`\nto produce a map-like object. The object provides methods for manipulating its\ncontents, and for producing a JSON compliant object serialization.\n\n**JSONArray.java**: The `JSONArray` can parse text from a String or a `JSONTokener`\nto produce a vector-like object. The object provides methods for manipulating\nits contents, and for producing a JSON compliant array serialization.\n\n**JSONTokener.java**: The `JSONTokener` breaks a text into a sequence of individual\ntokens. It can be constructed from a `String`, `Reader`, or `InputStream`.\n\n**JSONException.java**: The `JSONException` is the standard exception type thrown\nby this package.\n\n**JSONPointer.java**: Implementation of\n[JSON Pointer (RFC 6901)](https://tools.ietf.org/html/rfc6901). Supports\nJSON Pointers both in the form of string representation and URI fragment\nrepresentation.\n\n**JSONPropertyIgnore.java**: Annotation class that can be used on Java Bean getter methods.\nWhen used on a bean method that would normally be serialized into a `JSONObject`, it\noverrides the getter-to-key-name logic and forces the property to be excluded from the\nresulting `JSONObject`.\n\n**JSONPropertyName.java**: Annotation class that can be used on Java Bean getter methods.\nWhen used on a bean method that would normally be serialized into a `JSONObject`, it\noverrides the getter-to-key-name logic and uses the value of the annotation. The Bean\nprocessor will look through the class hierarchy. This means you can use the annotation on\na base class or interface and the value of the annotation will be used even if the getter\nis overridden in a child class.   \n\n**JSONString.java**: The `JSONString` interface requires a `toJSONString` method,\nallowing an object to provide its own serialization.\n\n**JSONStringer.java**: The `JSONStringer` provides a convenient facility for\nbuilding JSON strings.\n\n**JSONWriter.java**: The `JSONWriter` provides a convenient facility for building\nJSON text through a writer.\n\n\n**CDL.java**: `CDL` provides support for converting between JSON and comma\ndelimited lists.\n\n**Cookie.java**: `Cookie` provides support for converting between JSON and cookies.\n\n**CookieList.java**: `CookieList` provides support for converting between JSON and\ncookie lists.\n\n**HTTP.java**: `HTTP` provides support for converting between JSON and HTTP headers.\n\n**HTTPTokener.java**: `HTTPTokener` extends `JSONTokener` for parsing HTTP headers.\n\n**XML.java**: `XML` provides support for converting between JSON and XML.\n\n**JSONML.java**: `JSONML` provides support for converting between JSONML and XML.\n\n**XMLTokener.java**: `XMLTokener` extends `JSONTokener` for parsing XML text.\n\nUnit tests are maintained in a separate project. Contributing developers can test\nJSON-java pull requests with the code in this project:\nhttps://github.com/stleary/JSON-Java-unit-test\n\nNumeric types in this package comply with\n[ECMA-404: The JSON Data Interchange Format](http://www.ecma-international.org/publications/files/ECMA-ST/ECMA-404.pdf) and\n[RFC 8259: The JavaScript Object Notation (JSON) Data Interchange Format](https://tools.ietf.org/html/rfc8259#section-6).\nThis package fully supports `Integer`, `Long`, and `Double` Java types. Partial support\nfor `BigInteger` and `BigDecimal` values in `JSONObject` and `JSONArray` objects is provided\nin the form of `get()`, `opt()`, and `put()` API methods.\n\nAlthough 1.6 compatibility is currently supported, it is not a project goal and may be\nremoved in some future release.\n\nIn compliance with RFC8259 page 10 section 9, the parser is more lax with what is valid\nJSON than the Generator. For Example, the tab character (U+0009) is allowed when reading\nJSON Text strings, but when output by the Generator, tab is properly converted to \\t in\nthe string. Other instances may occur where reading invalid JSON text does not cause an\nerror to be generated. Malformed JSON Texts such as missing end \" (quote) on strings or\ninvalid number formats (1.2e6.3) will cause errors as such documents can not be read\nreliably.\n\nSome notible exceptions that the JSON Parser in this library accepts are:\n* Unquoted keys `{ key: \"value\" }`\n* Unquoted values `{ \"key\": value }`\n* Unescaped literals like \"tab\" in string values `{ \"key\": \"value   with an unescaped tab\" }`\n* Numbers out of range for `Double` or `Long` are parsed as strings\n\nRelease history:\n\n~~~\n20190722    Recent commits\n\n20180813    POM change to include Automatic-Module-Name (#431)\n\n20180130    Recent commits\n\n20171018    Checkpoint for recent commits.\n\n20170516    Roll up recent commits.\n\n20160810    Revert code that was breaking opt*() methods.\n\n20160807    This release contains a bug in the JSONObject.opt*() and JSONArray.opt*() methods,\nit is not recommended for use.\nJava 1.6 compatability fixed, JSONArray.toList() and JSONObject.toMap(),\nRFC4180 compatibility, JSONPointer, some exception fixes, optional XML type conversion.\nContains the latest code as of 7 Aug, 2016\n\n20160212    Java 1.6 compatibility, OSGi bundle. Contains the latest code as of 12 Feb, 2016.\n\n20151123    JSONObject and JSONArray initialization with generics. Contains the\nlatest code as of 23 Nov, 2015.\n\n20150729    Checkpoint for Maven central repository release. Contains the latest code\nas of 29 July, 2015.\n~~~\n\n\nJSON-java releases can be found by searching the Maven repository for groupId \"org.json\"\nand artifactId \"json\". For example:\nhttps://search.maven.org/search?q=g:org.json%20AND%20a:json&core=gav\n"}, {"repo": "/CObjectSystem/COS", "language": "C", "readme_contents": "#\n#  C Object System\n#  Copyright 2007+ Laurent Deniau <laurent.deniau at gmail dot com>\n#\n\nThe motivation to develop the C Object System (COS) on top of the C language may\nnot be obvious. While many new languages appear each year with new syntax and\nlittle new concepts, I prefer to try to lift C up to the level of other high\nlevel languages. C is portable, efficient, widely available and standardised.\nThis is probably why it is also the reference for other languages when memory\nand speed efficiency matter and why most languages have a Foreign Function\nInterface to C. Still, many virtual machines, interpreters, compilers or\noperating systems are written in C. If one often blame C to be a low level\nlanguage similar to a super assembler, it should be worthwhile to raise C to the\nlevel of the other high level Object Oriented languages and beyond. This is the\naim of COS, itself entirely written in ISO C.\n\nCOS uses the C99 preprocessor to parse its DSL (Domain Specific Language)\nembedded in C files and to generate pure C89 code on-the-fly during the\ntranslation phases of C compilers, using its advanced framework of C99 macros.\nThe design and the DSL of COS are strongly inspired by Objective-C and CLOS\n(Common Lisp Object System), one of the most flexible object model ever\ndeveloped, and to some lesser extend by Cecil, Dylan, Haskell, Python, Slate and\nSmallTalk. Contrary to CLOS, COS enforces strong encapsulation and separation of\nconcerns through its open object model, which allows to use and to extend COS\ncomponents (e.g. classes) defined in shared libraries without having the source\ncode (see papers).\n\nThe core of COS is only 7,000 SLOC and fulfils very well the five principles it\naims: simplicity, flexibility, extensibility, efficiency and portability. It is\navailable on GitHub and described in DLS'09 and OOPSLA'09 papers, and a\npresentation available in the doc directory. It tries to keep minimal the\navailable concepts for the sake of simplicity and flexibility: uniform object\nmodel, open classes, metaclasses, property metaclasses, generics, multimethods,\ndelegation, ownership, properties, exceptions, contracts and closures.\n\nCOS design is tuned to provide efficient portable implementation of these\nconcepts, especially for its two key features: dynamic message dispatch\nsupporting multimethods (i.e. many receivers) as well as generic message\nforwarding (i.e. delegation without limitations). COS message dispatch is\nx1.7-x2.3 slower than indirect function call (called through pointers) and about\nx1.2-x1.5 faster than Objective-C message dispatch. COS message forwarding is as\nfast as message dispatch and about x40-x80 faster than Objective-C message\nforwarding, which has strong limitations on the returned values. On top of these\ntwo efficient concepts, it is easy to implement high order messages, class-\npredicate dispatch, multiple inheritance, dynamic inheritance, dynamic classes,\nadaptive object model, reflection and advanced memory management (some of them\nare described in the papers).\n\nCOS achieves the principles of simplicity, flexibility and extensibility as well\nas existing mainstream scripting languages (e.g. PHP, Python, Ruby, Lua,\nSmallTalk) while keeping the efficiency and the portability in the range of C.\nIt can be used as both a dynamically or a statically typed programming language\n(see fast sorting of heterogeneous Array for an example of mixed use). COS is\nalso designed for parallelisation, and it is compliant with TLS (Thread Local\nStorage), OpenMP and POSIX threads. Its minimal requirement is a C99\npreprocessor and a C89 compiler.\n\nProject information:\n--------------------\n\n  - web site : http://github.com/CObjectSystem\n  - license  : http://www.apache.org/licenses/LICENSE-2.0\n  - contact  : laurent.deniau at gmail dot com\n\nDocumentation:\n--------------\n\npaper and presentation can be found in\npath-to-cos/doc/\n\nor after installation to\n$(PREFIX)/$(DOCDIR)/cos/\n\nor on arXiv.org\n\nWiki on CLOS:\nhttp://en.wikipedia.org/wiki/Common_Lisp_Object_System\n\nWiki on multiple dispatch:\nhttp://en.wikipedia.org/wiki/Multiple_dispatch#C\n\nMakefile examples:\n------------------\n\n# distrib\npath-to-cos/Makefile\n\n# library\npath-to-cos/CosBase/Makefile\n\n# program\npath-to-cos/CosBase/examples/ex??/Makefile\n\n# tests (program with auto-run)\npath-to-cos/CosBase/tests/Makefile\n\nDebugging makefiles:\n--------------------\n\nmake [target] SHOW=yes\n\n# debug flags\nSHOW will show the commands run\n\nCode examples:\n--------------\n\npath-to-cos/CosBase/examples\npath-to-cos/CosBase/tests\n\nSupported platforms:\n--------------------\n\nnote: platforms name are detected using the posix command \"uname -s\"\n\nthe list of supported platforms are in the directory\npath-to-cos/CosBase/include/cos/cfg/\n\nor after installation to\n$(PREFIX)/$(INCDIR)/cos/cfg/\n\nporting on Unixes/Posix compliant platform should be straightforward\nporting on Windows requires some Posix-like environment (e.g. Mingw, Cygwin)\n\nTested platforms:\n-----------------\n\n# Systems & Architectures\nLinux Ubuntu from 8.04 to 12.04 on i386 and x86_64 multicore\nMac OSX from Leopard to El Capitan on x86_64 multicore\nWindows from 7 to 10 on x86_64 multicore using MSys2 (mingw64)\n\n# Compilers\ngcc from 3.2.3 to 4.8.5, 7.2.0, and 8.2.0\n\nOther available platforms (untested):\n-------------------------------------\nSunOS + gcc\nFreeBSD + gcc\n"}, {"repo": "/microsoft/xlang", "language": "C++", "readme_contents": "# xlang\n\nThis repo is the starting point for the xlang project, which enables developers to take existing shared libraries,\nimplemented in one programming language and make that library's APIs available to client code using a different programming language. Thus the name \"xlang\", for cross-language.  \n\nSee these related repos:\n\n|Repository|Status|\n|-|-|\n|[C++/WinRT](https://github.com/microsoft/cppwinrt)|[![Build status](https://dev.azure.com/microsoft/Dart/_apis/build/status/cppwinrt%20internal%20build)](https://dev.azure.com/microsoft/Dart/_build/latest?definitionId=31784)|\n|[C++ winmd parser](https://github.com/microsoft/winmd)|[![Build Status](https://dev.azure.com/microsoft/Dart/_apis/build/status/WinMD%20Nuget?branchName=master)](https://dev.azure.com/microsoft/Dart/_build/latest?definitionId=44715&branchName=master)|\n|[Rust winmd parser](https://github.com/microsoft/winmd-rs)|[![Build Status](https://dev.azure.com/microsoft/Dart/_apis/build/status/microsoft.winmd-rs?branchName=master)](https://dev.azure.com/microsoft/Dart/_build/latest?definitionId=45839&branchName=master)|\n[WinRT test component](https://github.com/microsoft/TestWinRT)|[![Build Status](https://dev.azure.com/microsoft/Dart/_apis/build/status/TestWinRT?branchName=master)](https://dev.azure.com/microsoft/Dart/_build/latest?definitionId=45310&branchName=master)|\n\nAdditionally, the xlang toolset will be available on multiple operating systems.\nThis means that if your shared library is portable to various operating systems,\nthen you can use the xlang tooling to make that shared library available to various client programming language on those various platforms.\n\nMore succinctly, you can take a library written in language A and make it available to language B applications running on platform C. The set of supported languages and platforms will expand as the project progresses.\n\nThe xlang project is in a very, very early stage of development.\nThe project wants and encourages community feedback and contributions. As such, the xlang team is doing *all* xlang project development in the open on GitHub. \n\n## What xlang is NOT\n\n* The xlang project is not a port of the Windows Runtime, COM, DCOM or related technology.\n* The xlang project will not port the Windows Runtime APIs.\n\n## Project details\n\nFor details on project structure and build process, please see the [Project Readme](./src/readme.md).\n\nFor technical design details, please see the [Design Notes](./design_notes).\n\n## License\n\nCode licensed under the [MIT License](LICENSE).\n\n## Contributing\n\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit https://cla.microsoft.com.\n\nWhen you submit a pull request, a CLA-bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n\n"}, {"repo": "/oun111/zas", "language": "C++", "readme_contents": "\n## What is ZAS\n - ZAS\uff08Zhou\u2019s Adaptor of Sql\uff09is being developed based on the `MYSQL Client/Server Protocol`\n - ZAS is a C++ library that used by applications to access MYSQL databases\n - ZAS can translate SQL syntax automatically \n\n\n## Features\n - Cross platforms: 32/64 bit processors supports, linux and windows supports\n - Cross languages: you may use ZAS with c++, java, python\n - Provides OTLV4-compatible interfaces\n - Provides automatically SQL syntax translations that is transparent to upper applications\n - Supports most SQL syntaxs in ORACLE/MYSQL \n - Good performance in SQL syntax analyzing\n - The underlying `MYSQL Client/Server Protocol` is being optimized\n - Conceals complexities of `MYSQL Client/Server Protocol`\n - Good extensibility\n - Being tested over a year and runs steadily\n\n\n## Structure\n\n ![Alt text](https://github.com/oun111/images/blob/master/zas_structure.png)\n\n - Connection String processor: processes the DB connection strings including Oracle TNS and traditional DSN format\n - Protocol Management(the `MYSQLC` libray) provides:\n    1. implementations of the `MYSQL Client/Server Protocol`\n    2. fully support for the `prepare` and `query` mode\n    3. API compatibilities with `libmysqlclient`\n - SQL Syntax Engine: performs SQL syntax analyzing/checking/translations\n - OTLV4 Compatible API: provides a set of c++ classes that compatible with OTLV4 libraries\n\n\n## Process Flow\n\n ![Alt text](https://github.com/oun111/images/blob/master/zas_process_flow.png)\n\n - First of all, the application should call `rlogon() ` to parse connection strings and to do database login \n - Second, the application should call `open()` to initialize the SQL and translate it\n - Third, the application should input enough place holder values to execute the statement\n - Last, fetching the result\n - Further more, one can `reopen` a new SQL or `execute` the old one again\n \n \n## Connection String Handling\n\n ![Alt text](https://github.com/oun111/images/blob/master/zas_conn_str.png)\n\n - When login, the connection string is passed to the `connection string processor` which will test  the inputed string\n    1. if it\u2019s TNS format, the processor will parse the TNS file for login informations\n    2. if it\u2019s DSN format, the processor will parse it directly\n    3. otherwise, throws C++ exception \n\n\n## the SQL Syntax Engine\n\n ![Alt text](https://github.com/oun111/images/blob/master/zas_syntax_engine.png)\n\n - when a SQL is inputed, it would be processed by a hard-coding  parser and be translated to a syntax tree\n - if no errors, the tree will be scaned for syntax errors\n - if everythings\u2019 ok, the tree will be scaned again for `translation points` to being translated to `MYSQL-style` syntax\n - then, all place-holders within the tree will be processed\n - last, the tree will be serialized to string form and passed to output\n\n\n## The MYSQLC library\n\n - The library provides the following functionalities: database login, SQL execution, result fetching, protocol compression, connection maintainance\n - The protocol compression invokes the `deflate` algorithm from zlib \n - The library employs the `ping` protocol to maintain the database connection\n - To execute a SQL statement, the application may use `query mode` with which all place holder values are embeded within the SQL statement string that will be sent to server by a single `com_query` request, here\u2019s the diagram:\n\n ![Alt text](https://github.com/oun111/images/blob/master/zas_query.png)\n\n\n - The application may also execute SQL under `prepare mode`. The SQL execution progress is seperated into 2 requests:\n    1. the primordial SQL statement is sent to server by `com_stmt_prepare` to prepare resources and do checkings at server side\n    2. the place-holder value list are embeded into the `com_stmt_execute` request to initiate the `SQL execution` progress, and the `binary/string/blob` type place-holders values should be sent by `com_send_long_data` requests especially,  Here\u2019s the diagram:\n\n ![Alt text](https://github.com/oun111/images/blob/master/zas_prepare.png)\n\n\n## Compiling and Installing\n\n - Simply do `make clean install` under source root directory\n - The `libzas.a`, `libzas.so`, and `zas wrapper` library will be generated\n - Link the `.a` or `.so` library to your c++ applications\n - Load the wrapper library into your java/python applications\n \n \n## Roadmap\n * `src`: core of zas library\n * `tests`: test cases of zas\n * `win`: vss project files of zas under windows\n * `wrapper`: library classes for java/python that encapsulates APIs onto ZAS \n \n \n## Wrappers\n * both java and python wrappers load a c library named `libcwpr` that encapsulates a set of usage with ZAS APIs. see wrapper/cwpr.c for more details\n * in java wrapper, it calls `libcwpr` methods with JNI interfaces\n * in python wrapper, it dynamically loads the `libcwpr`\n \n \n## HOWTO\n\n ### `In c++, one should access MYSQL with ZAS like this:`\n \n```c++\n /* initialize connection object and login to database with MYSQL driver */\n zas_connect cnn(tnsFilePath,dal_mysql) ;\n /* initialize stream object with SQL-prepare mode */\n zas_stream stream(cnn,true);\n \n /* initialize the ORACLE-style SQL */\n stream.open(0,\"select id,nvl(name),price from test_db.test_tbl \"\n        \"where id>=:f1<unsigned int> and id<:f2<int,in>\");\n \n /* insert place holders and execute the SQL */\n streams<<1;\n streams<<5;\n \n /* fetch results */\n while (!streams[strs].eof()) {\n  int id=0;\n  char name[256] = \"\";\n  float point = 0.0;\n  long size = 0L;\n  \n  streams>>id ;\n  streams>>name ;\n  streams>>point ;\n  streams>>size ;\n  streams.flush();\n  printd(\"%d: name %s, point %f, size %ld\\n\",\n    id, name, point, size);\n}\n```\n\n### `In java, one should set correct 'CLASSPATH' of ZAS java wrapper class and play like this:`\n\n```java\npublic class test_cases {\n\n  public static void main(String[] args) throws Exception {\n\n    /* initialize instance of zas.class and do initializations with it */\n    zas mz = (zas)Class.forName(\"zas\").newInstance();\n\n    /* login to MYSQL */\n    mz.login(\"localhost\",3306,\"root\",\"123\",\"\");\n\n    /* initialize the ORACLE-style SQL */\n    mz.prepare(\"select id,nvl(name),price,size from test_db.test_tbl where id<:f1<int>\");\n\n    /* insert placeholder and execute SQL */\n    mz.insertInt(10);\n\n    /* fetch results */\n    while (!mz.isEof()) {\n      Integer id = 0;\n      String name = \"\" ;\n      Double price = 0.0;\n      Long size = 0L; \n\n      id = mz.fetchInt();\n      name = mz.fetchStr();\n      price = mz.fetchDouble();\n      size = mz.fetchLong();\n      System.out.println(id + \": name: \" + name + \", point: \" + \n        price + \", size: \" + size + \"\\n\");\n    }   \n\n  }\n}\n\n```\n\n### `In python, one should load ZAS python wrapper class and play like this:`\n\n```python\n\n# path of ZAS python wrapper class\nsys.path.append(zasPythonWrapperPath)\n\n# load the wrapper class\nfrom python.zas import *\n\ndef main():\n\n  # do initializations\n  mz = zas()\n\n  # login to database\n  if mz.login(\"localhost\",3306,\"root\",\"123\",\"\")!=0 :\n    print(\"login fail\\n\")\n    exit(-1)\n\n  # initialize the ORACLE-style SQL\n  if mz.prepare('select nvl(id),name,price,size from test_db.test_tbl where id <:f1<int>')!=0 :\n    print(\"prepare fail\\n\")\n    exit(-1)\n\n  # insert placeholder and execute SQL\n  if mz.insert_int(10)!=0 :\n    exit(-1)\n\n  # fetch results\n  while mz.is_eof()==0 :\n    id = mz.fetch_int()\n    name = mz.fetch_str()\n    price = mz.fetch_double()\n    size = mz.fetch_long()\n    print(\"{0}: name: {1}, point: {2}, size: {3}\\n\".format(id,name,price,size))\n\n```\n"}, {"repo": "/jfecher/ante", "language": "C++", "readme_contents": "# Ante\n\n### The compile-time language\n\n[![Build Status](https://gitlab.com/jfecher/ante/badges/typeinference/build.svg)](https://gitlab.com/rndmprsn/ante/commits/typeinference)\n\nAnte is a compiled systems language focusing on providing extreme extensibility through\nthe use of a compile-time API.  Using such an API, compiler extensions can be created\nwithin the program itself, allowing for the addition of a garbage collector, ownership\nsystem, automatic linters, etc, all in a normal library without requiring any changes\nto the compiler itself.\n\nSystems languages can traditionally be a pain to write.  To fix this, Ante provides high-level\nsolutions such as string interpolation, smart pointers, and pattern matching, while maintaining\nthe ability to interact at a lower level if needed.\n\n## Community\n- Join the official subreddit at [/r/ante](https://www.reddit.com/r/ante) for any and all discussion.  Everyone is welcome!\n- Want to learn Ante?  Check out [the website](http://antelang.org/).\n- Looking to contribute?  Check out [the documentation](http://antelang.org/doxygen/html/).\n\n## Features\n* Strong focus on readability\n* Expression-based syntax\n* Robust module system with integrated build system\n* Immutable by default\n* Strongly typed with a detailed algebraic type system and type inferencing\n* Compile-time execution combined with an extensible compiler API\n    - Ability to write compiler plugins within the compiled program itself\n    - Use compiler API to analyze or change type system, IR, macros, etc.\n    - Programmers have just as much power over their program as the compiler does.  As an example,\n    here is an implementation of the goto construct in Ante:\n\n```haskell\n//The 'ante' keyword declares compile-time values\nante\n    labels = global mut empty Map\n\n    goto lbl =\n        label = lookup labels lbl ?\n            None -> Ante.error \"Cannot goto undefined label ${lbl}\"\n\n        Llvm.setInsertPoint (getCallSiteBlock ())\n        Llvm.createBr label\n\n    label name:Str =\n        callingFn = getParentFn (getCallSiteBlock ())\n        lbl = Llvm.BasicBlock(Ante.llvm_ctxt, callingFn)\n        labels#name := lbl\n\n\n//test it out\nlabel \"begin\"\nprint \"hello!\"\ngoto \"begin\"\n```\n\n## Installation\n\n### Requirements\n\n * `yacc`. This is normally provided by GNU Bison - to install Bison, install the `bison` package in your\ndistro's package manager.\n * (Optional) `llvm` version >= 8.0.  There is no need to install llvm manually.  If you do not have it\n installed already, cmake will automatically use the version in ante's git submodule.  If you wish to\n install llvm system wide anyway, then make sure to check which version you have by running `$ lli --version`.\n To install a specific version of llvm, install the `llvm` package on your distro's package manager, eg. for\n Ubuntu: `$ sudo apt-get install llvm-8.0`.  Note that not all versions may be available on all systems\n without building from source.\n\n### Steps\n\n1. Install yacc/bison.\n\n2. Run `$ git clone https://github.com/jfecher/ante.git`\n\n3. Run `$ cd ante && cmake .` This will generate your platform specific\nbuild files.  Usually either a Makefile or Visual Studio solution file.\nYou can also specify which to make manually by passing the appropriate\narguments to cmake.\n\n3. Run `$ cmake --build .`  This may take a while as it is also building llvm.\n\nNOTE: If you are planning to develop ante in vim or a similar editor, make sure\nto add include, llvm/include, and llvm_build/include to your include paths.\n\n### Trying Ante in Docker\n\nAlternatively, you can try Ante using Docker. You can build the image using:\n\n```\ndocker build . -t ante\n```\n\nand then start it with:\n\n```\ndocker run -it ante\n```\n\nAt this point you can install an editor and use the compiler/REPL (in /home/ante/ante) to write some code and run it.\n"}, {"repo": "/bakwc/JamSpell", "language": "C++", "readme_contents": "# JamSpell\n\n[![Build Status][travis-image]][travis] [![Release][release-image]][releases]\n\n[travis-image]: https://travis-ci.org/bakwc/JamSpell.svg?branch=master\n[travis]: https://travis-ci.org/bakwc/JamSpell\n\n[release-image]: https://img.shields.io/badge/release-0.0.11-blue.svg?style=flat\n[releases]: https://github.com/bakwc/JamSpell/releases\n\nJamSpell is a spell checking library with following features:\n\n- **accurate** - it consider words surroundings (context) for better correction\n- **fast** - near 5K words per second\n- **multi-language** - it's written in C++ and available for many languages with swig bindings\n\n## Content\n- [Benchmarks](#benchmarks)\n- [Usage](#usage)\n  - [Python](#python)\n  - [C++](#c)\n  - [Other languages](#other-languages)\n  - [HTTP API](#http-api)\n- [Train](#train)\n\n## Benchmarks\n\n<table>\n  <tr>\n    <td></td>\n    <td>Errors</td>\n    <td>Top 7 Errors</td>\n    <td>Fix Rate</td>\n    <td>Top 7 Fix Rate</td>\n    <td>Broken</td>\n    <td>Speed<br>\n(words/second)</td>\n  </tr>\n  <tr>\n    <td>JamSpell</td>\n    <td>3.25%</td>\n    <td>1.27%</td>\n    <td>79.53%</td>\n    <td>84.10%</td>\n    <td>0.64%</td>\n    <td>4854</td>\n  </tr>\n  <tr>\n    <td>Norvig</td>\n    <td>7.62%</td>\n    <td>5.00%</td>\n    <td>46.58%</td>\n    <td>66.51%</td>\n    <td>0.69%</td>\n    <td>395</td>\n  </tr>\n  <tr>\n    <td>Hunspell</td>\n    <td>13.10%</td>\n    <td>10.33%</td>\n    <td>47.52%</td>\n    <td>68.56%</td>\n    <td>7.14%</td>\n    <td>163</td>\n  </tr>\n  <tr>\n    <td>Dummy</td>\n    <td>13.14%</td>\n    <td>13.14%</td>\n    <td>0.00%</td>\n    <td>0.00%</td>\n    <td>0.00%</td>\n    <td>-</td>\n  </tr>\n</table>\n\nModel was trained on [300K wikipedia sentences + 300K news sentences (english)](http://wortschatz.uni-leipzig.de/en/download/). 95% was used for train, 5% was used for evaluation. [Errors model](https://github.com/bakwc/JamSpell/blob/master/evaluate/typo_model.py) was used to generate errored text from the original one. JamSpell corrector was compared with [Norvig's one](http://norvig.com/spell-correct.html), [Hunspell](http://hunspell.github.io/) and a dummy one (no corrections).\n\nWe used following metrics:\n- **Errors** - percent of words with errors after spell checker processed\n- **Top 7 Errors** - percent of words missing in top7 candidated\n- **Fix Rate** - percent of errored words fixed by spell checker\n- **Top 7 Fix Rate** - percent of errored words fixed by one of top7 candidates\n- **Broken** - percent of non-errored words broken by spell checker\n- **Speed** - number of words per second\n\nTo ensure that our model is not too overfitted for wikipedia+news we checked it on \"The Adventures of Sherlock Holmes\" text:\n\n<table>\n  <tr>\n    <td></td>\n    <td>Errors</td>\n    <td>Top 7 Errors</td>\n    <td>Fix Rate</td>\n    <td>Top 7 Fix Rate</td>\n    <td>Broken</td>\n    <td>Speed\n(words per second)</td>\n  </tr>\n  <tr>\n    <td>JamSpell</td>\n    <td>3.56%</td>\n    <td>1.27%</td>\n    <td>72.03%</td>\n    <td>79.73%</td>\n    <td>0.50%</td>\n    <td>5524</td>\n  </tr>\n  <tr>\n    <td>Norvig</td>\n    <td>7.60%</td>\n    <td>5.30%</td>\n    <td>35.43%</td>\n    <td>56.06%</td>\n    <td>0.45%</td>\n    <td>647</td>\n  </tr>\n  <tr>\n    <td>Hunspell</td>\n    <td>9.36%</td>\n    <td>6.44%</td>\n    <td>39.61%</td>\n    <td>65.77%</td>\n    <td>2.95%</td>\n    <td>284</td>\n  </tr>\n  <tr>\n    <td>Dummy</td>\n    <td>11.16%</td>\n    <td>11.16%</td>\n    <td>0.00%</td>\n    <td>0.00%</td>\n    <td>0.00%</td>\n    <td>-</td>\n  </tr>\n</table>\n\nMore details about reproducing available in \"[Train](#train)\" section.\n\n## Usage\n### Python\n1. Install ```swig3``` (usually it is in your distro package manager)\n\n2. Install ```jamspell```:\n```bash\npip install jamspell\n```\n3. [Download](#download-models) or [train](#train) language model\n\n4. Use it:\n\n```python\nimport jamspell\n\ncorrector = jamspell.TSpellCorrector()\ncorrector.LoadLangModel('en.bin')\n\ncorrector.FixFragment('I am the begt spell cherken!')\n# u'I am the best spell checker!'\n\ncorrector.GetCandidates(['i', 'am', 'the', 'begt', 'spell', 'cherken'], 3)\n# (u'best', u'beat', u'belt', u'bet', u'bent', ... )\n\ncorrector.GetCandidates(['i', 'am', 'the', 'begt', 'spell', 'cherken'], 5)\n# (u'checker', u'chicken', u'checked', u'wherein', u'coherent', ...)\n```\n\n### C++\n1. Add `jamspell` and `contrib` dirs to your project\n\n2. Use it:\n\n```cpp\n#include <jamspell/spell_corrector.hpp>\n\nint main(int argc, const char** argv) {\n\n    NJamSpell::TSpellCorrector corrector;\n    corrector.LoadLangModel(\"model.bin\");\n\n    corrector.FixFragment(L\"I am the begt spell cherken!\");\n    // \"I am the best spell checker!\"\n\n    corrector.GetCandidates({L\"i\", L\"am\", L\"the\", L\"begt\", L\"spell\", L\"cherken\"}, 3);\n    // \"best\", \"beat\", \"belt\", \"bet\", \"bent\", ... )\n\n    corrector.GetCandidates({L\"i\", L\"am\", L\"the\", L\"begt\", L\"spell\", L\"cherken\"}, 3);\n    // \"checker\", \"chicken\", \"checked\", \"wherein\", \"coherent\", ... )\n    return 0;\n}\n```\n\n### Other languages\nYou can generate extensions for other languages using [swig tutorial](http://www.swig.org/tutorial.html). The swig interface file is `jamspell.i`. Pull requests with build scripts are welcome.\n\n## HTTP API\n* Install ```cmake```\n\n* Clone and build jamspell (it includes http server):\n```bash\ngit clone https://github.com/bakwc/JamSpell.git\ncd JamSpell\nmkdir build\ncd build\ncmake ..\nmake\n```\n* [Download](#download-models) or [train](#train) language model\n* Run http server:\n```bash\n./web_server/web_server en.bin localhost 8080\n```\n* **GET** Request example:\n```bash\n$ curl \"http://localhost:8080/fix?text=I am the begt spell cherken\"\nI am the best spell checker\n```\n* **POST** Request example\n```bash\n$ curl -d \"I am the begt spell cherken\" http://localhost:8080/fix\nI am the best spell checker\n```\n* Candidate example\n```bash\ncurl \"http://localhost:8080/candidates?text=I am the begt spell cherken\"\n# or\ncurl -d \"I am the begt spell cherken\" http://localhost:8080/candidates\n```\n```javascript\n{\n    \"results\": [\n        {\n            \"candidates\": [\n                \"best\",\n                \"beat\",\n                \"belt\",\n                \"bet\",\n                \"bent\",\n                \"beet\",\n                \"beit\"\n            ],\n            \"len\": 4,\n            \"pos_from\": 9\n        },\n        {\n            \"candidates\": [\n                \"checker\",\n                \"chicken\",\n                \"checked\",\n                \"wherein\",\n                \"coherent\",\n                \"cheered\",\n                \"cherokee\"\n            ],\n            \"len\": 7,\n            \"pos_from\": 20\n        }\n    ]\n}\n```\nHere `pos_from` - misspelled word first letter position, `len` - misspelled word len\n\n## Train\nTo train custom model you need:\n\n1. Install ```cmake```\n\n2. Clone and build jamspell:\n```bash\ngit clone https://github.com/bakwc/JamSpell.git\ncd JamSpell\nmkdir build\ncd build\ncmake ..\nmake\n```\n\n3. Prepare a utf-8 text file with sentences to train at (eg. [```sherlockholmes.txt```](https://github.com/bakwc/JamSpell/blob/master/test_data/sherlockholmes.txt)) and another file with language alphabet (eg. [```alphabet_en.txt```](https://github.com/bakwc/JamSpell/blob/master/test_data/alphabet_en.txt))\n\n4. Train model:\n```bash\n./main/jamspell train ../test_data/alphabet_en.txt ../test_data/sherlockholmes.txt model_sherlock.bin\n```\n5. To evaluate spellchecker you can use ```evaluate/evaluate.py``` script:\n```bash\npython evaluate/evaluate.py -a alphabet_file.txt -jsp your_model.bin -mx 50000 your_test_data.txt\n```\n6. You can use ```evaluate/generate_dataset.py``` to generate you train/test data. It supports txt files, [Leipzig Corpora Collection](http://wortschatz.uni-leipzig.de/en/download/) format and fb2 books.\n\n## Download models\nHere is a few simple models. They trained on 300K news + 300k wikipedia sentences. We strongly recommend to train your own model, at least on a few million sentences to achieve better quality. See [Train](#train) section above.\n\n - [en.tar.gz](https://github.com/bakwc/JamSpell-models/raw/master/en.tar.gz) (35Mb)\n - [fr.tar.gz](https://github.com/bakwc/JamSpell-models/raw/master/fr.tar.gz) (31Mb)\n - [ru.tar.gz](https://github.com/bakwc/JamSpell-models/raw/master/ru.tar.gz) (38Mb)\n"}, {"repo": "/geckom/ChatScript", "language": "C++", "readme_contents": "# ChatScript\nNatural Language tool/dialog manager\n"}, {"repo": "/zsh-users/zsh-syntax-highlighting", "language": "Shell", "readme_contents": "zsh-syntax-highlighting [![Build Status][build-status-image]][build-status-travis]\n=======================\n\n**[Fish shell][fish]-like syntax highlighting for [Zsh][zsh].**\n\n*Requirements: zsh 4.3.11+.*\n\n[fish]: http://www.fishshell.com/\n[zsh]: http://www.zsh.org/\n\nThis package provides syntax highlighting for the shell zsh.  It enables\nhighlighting of commands whilst they are typed at a zsh prompt into an\ninteractive terminal.  This helps in reviewing commands before running\nthem, particularly in catching syntax errors.\n\nSome examples:\n\nBefore: [![Screenshot #1.1](images/before1-smaller.png)](images/before1.png)\n<br/>\nAfter:&nbsp; [![Screenshot #1.2](images/after1-smaller.png)](images/after1.png)\n\nBefore: [![Screenshot #2.1](images/before2-smaller.png)](images/before2.png)\n<br/>\nAfter:&nbsp; [![Screenshot #2.2](images/after2-smaller.png)](images/after2.png)\n\nBefore: [![Screenshot #3.1](images/before3-smaller.png)](images/before3.png)\n<br/>\nAfter:&nbsp; [![Screenshot #3.2](images/after3-smaller.png)](images/after3.png)\n\n\nHow to install\n--------------\n\nSee [INSTALL.md](INSTALL.md).\n\n\nFAQ\n---\n\n### Why must `zsh-syntax-highlighting.zsh` be sourced at the end of the `.zshrc` file?\n\n`zsh-syntax-highlighting.zsh` wraps ZLE widgets.  It must be sourced after all\ncustom widgets have been created (i.e., after all `zle -N` calls and after\nrunning `compinit`).  Widgets created later will work, but will not update the\nsyntax highlighting.\n\n### Does syntax highlighting work during incremental history search?\n\nHighlighting the command line during an incremental history search (by default bound to\nto <kbd>Ctrl+R</kbd> in zsh's emacs keymap) requires zsh 5.4 or newer.\n\nUnder zsh versions older than 5.4, the zsh-default [underlining][zshzle-Character-Highlighting]\nof the matched portion of the buffer remains available, but zsh-syntax-highlighting's\nadditional highlighting is unavailable.  (Those versions of zsh do not provide\nenough information to allow computing the highlighting correctly.)\n\nSee issues [#288][i288] and [#415][i415] for details.\n\n[zshzle-Character-Highlighting]: http://zsh.sourceforge.net/Doc/Release/Zsh-Line-Editor.html#Character-Highlighting\n[i288]: https://github.com/zsh-users/zsh-syntax-highlighting/pull/288\n[i415]: https://github.com/zsh-users/zsh-syntax-highlighting/pull/415\n\n### How are new releases announced?\n\nThere is currently no \"push\" announcements channel.  However, the following\nalternatives exist:\n\n- GitHub's RSS feed of releases: https://github.com/zsh-users/zsh-syntax-highlighting/releases.atom\n- An anitya entry: https://release-monitoring.org/project/7552/\n\n\nHow to tweak\n------------\n\nSyntax highlighting is done by pluggable highlighter scripts.  See the\n[documentation on highlighters](docs/highlighters.md) for details and\nconfiguration settings.\n\n[build-status-image]: https://travis-ci.org/zsh-users/zsh-syntax-highlighting.svg?branch=master\n[build-status-travis]: https://travis-ci.org/zsh-users/zsh-syntax-highlighting\n"}, {"repo": "/Icinga/icinga2", "language": "C++", "readme_contents": "[![Build Status](https://travis-ci.org/Icinga/icinga2.svg?branch=master)](https://travis-ci.org/Icinga/icinga2)\n[![Github Tag](https://img.shields.io/github/tag/Icinga/icinga2.svg)](https://github.com/Icinga/icinga2)\n\n# Icinga 2\n\n![Icinga Logo](https://icinga.com/wp-content/uploads/2014/06/icinga_logo.png)\n\n#### Table of Contents\n\n1. [About][About]\n2. [Installation][Installation]\n3. [Documentation][Documentation]\n4. [Support][Support]\n5. [License][License]\n6. [Contributing][Contributing]\n\n## About\n\n[Icinga](https://icinga.com/products/) is a monitoring system which checks\nthe availability of your network resources, notifies users of outages, and generates\nperformance data for reporting.\n\nScalable and extensible, Icinga can monitor large, complex environments across\nmultiple locations.\n\nIcinga 2 is the monitoring server and requires [Icinga Web 2](https://icinga.com/products/)\non top in your Icinga Stack. The [configuration](https://icinga.com/products/configuration/)\ncan be easily managed with either the [Icinga Director](https://icinga.com/docs/director/latest/),\nconfig management tools or plain text within the [Icinga DSL](https://icinga.com/docs/icinga2/latest/doc/17-language-reference/).\n\n![Icinga Dashboard](https://icinga.com/wp-content/uploads/2017/12/icingaweb2-2.5.0-dashboard.png)\n\n## Installation\n\n* [Installation](https://icinga.com/docs/icinga2/latest/doc/02-installation/)\n* [Monitoring Basics](https://icinga.com/docs/icinga2/latest/doc/03-monitoring-basics/)\n* [Configuration](https://icinga.com/docs/icinga2/latest/doc/04-configuration/)\n* [Distributed Monitoring](https://icinga.com/docs/icinga2/latest/doc/06-distributed-monitoring/)\n* [Addons, Integrations and Features](https://icinga.com/docs/icinga2/latest/doc/13-addons/)\n* [Troubleshooting](https://icinga.com/docs/icinga2/latest/doc/15-troubleshooting/)\n* [Upgrading](https://icinga.com/docs/icinga2/latest/doc/16-upgrading-icinga-2/)\n\nOnce Icinga Server and Web are running in your distributed environment,\nmake sure to check out the many [Icinga modules](https://icinga.com/docs/)\nfor even better monitoring.\n\n## Documentation\n\nThe documentation is available on [icinga.com/docs](https://icinga.com/docs/icinga2/latest/).\n\n## Support\n\nCheck the [project website](https://icinga.com) for status updates. Join the\n[community channels](https://icinga.com/community/) for questions\nor ask an Icinga partner for [professional support](https://icinga.com/support/).\n\n## License\n\nIcinga 2 and the Icinga 2 documentation are licensed under the terms of the GNU\nGeneral Public License Version 2, you will find a copy of this license in the\nCOPYING file included in the source package.\n\nIn addition, as a special exception, the copyright holders give\npermission to link the code of portions of this program with the\nOpenSSL library under certain conditions as described in each\nindividual source file, and distribute linked combinations including\nthe two.\n\nYou must obey the GNU General Public License in all respects for all\nof the code used other than OpenSSL. If you modify file(s) with this\nexception, you may extend this exception to your version of the\nfile(s), but you are not obligated to do so. If you do not wish to do\nso, delete this exception statement from your version. If you delete\nthis exception statement from all source files in the program, then\nalso delete it here.\n\n## Contributing\n\nThere are many ways to contribute to Icinga -- whether it be sending patches,\ntesting, reporting bugs, or reviewing and updating the documentation. Every\ncontribution is appreciated!\n\nPlease continue reading in the [contributing chapter](CONTRIBUTING.md).\n\nIf you are a packager, please read the [development chapter](https://icinga.com/docs/icinga2/latest/doc/21-development/)\nfor more details.\n\n### Security Issues\n\nFor reporting security issues please visit [this page](https://icinga.com/contact/security/).\n\n<!-- TOC URLs -->\n[About]: #about\n[License]: #license\n[Installation]: #installation\n[Documentation]: #documentation\n[Support]: #support\n[Contributing]: #contributing\n"}, {"repo": "/parity-js/shell", "language": "JavaScript", "readme_contents": "# Parity UI\n\n## \u26a0 Parity Technologies is looking for a new maintainer for this repo. If you are interested, please get in touch at admin@parity.io.\n\n## \u26a0 Parity UI is currently only compatible with Parity Ethereum <v2.0. Read about [possible alternatives here](#parity-ui-alternatives).\n\n### [Download the latest release](https://github.com/parity-js/shell/releases/latest)\n\n[![GPLv3](https://img.shields.io/badge/license-GPL%20v3-green.svg)](https://www.gnu.org/licenses/gpl-3.0.en.html)\n\n### Join the chat!\n\nGet in touch with us on Gitter:\n[![Gitter: Parity](https://img.shields.io/badge/gitter-parity-4AB495.svg)](https://gitter.im/paritytech/parity)\n\nOr join our community on Matrix:\n[![Riot: +Parity](https://img.shields.io/badge/riot-%2Bparity%3Amatrix.parity.io-orange.svg)](https://riot.im/app/#/group/+parity:matrix.parity.io)\n\nBe sure to check out [our wiki](https://wiki.parity.io/Parity-Wallet) for more information.\n\n----\n## About Parity UI\n\nParity UI is a User Interface desktop application for [Parity Ethereum Client](https://github.com/paritytech/parity/blob/master/README.md) >=v1.10. It features a Wallet supporting Ether and ERC-20 Tokens, a Contract development environment, and so much more. Parity UI will download and run [Parity Ethereum Client](https://github.com/paritytech/parity/blob/master/README.md) in the background if it is not found on the system. \nBy default Parity UI will try connect to a Parity Ethereum node using Websocket port 8546. You can use alternative ports, see [CLI Options](#cli-options) below.\n\nYou can download Parity UI [here](https://github.com/parity-js/shell/releases/latest) or follow the instructions below to build from source.\n\n## Parity UI alternatives\n\n### View and send Ether and tokens\n\nAs Parity UI is not working properly with Parity Ethereum >2.0, you can use [MyCrypto Desktop app](https://download.mycrypto.com/) connected to a local full node to interact with your accounts. Follow [these steps](https://support.mycrypto.com/networks/run-your-own-node-with-mycrypto.html) to connect MyCrypto Desktop to a local Parity Ethereum node. Parity UI accounts' JSON keystore files can be found at the following location:\n- Mac OS X: `~/Library/Application\\ Support/io.parity.ethereum/keys/ethereum/`\n- Linux: `$HOME/.local/share/io.parity.ethereum/keys`\n- Windows 7/10: `%HOMEPATH%/AppData/Roaming/Parity/Ethereum/keys`\n\nImport an account to MyCrypto by selecting the corresponding JSON keystore file. You will require your account's password to unlock it (originally setup with Parity UI).\n\n### Smart contract development\n\nYou can use [Remix](https://remix.ethereum.org/) connected to a local Parity Ethereum full node as an alternative to Parity UI for smart contracts development and deployment. Make sure that Remix is allowed to connect to your node by setting up the right [JSON-RPC cors policy](https://ethereum.stackexchange.com/questions/54639/is-it-possible-to-connect-remix-and-parity?rq=1).\n\n## Install from the snap store\n\nIn any of the [supported Linux distros](https://snapcraft.io/docs/core/install):\n\n```bash\nsudo snap install parity-ui\n```\n\nOr, if you want to contribute testing the upcoming release:\n\n```bash\nsudo snap install parity-ui --beta\n```\n\nAnd to test the latest code landed into the master branch:\n\n```bash\nsudo snap install parity-ui --edge\n```\n\n---\n\n## Build from source\n\n```bash\nnpm install\nnpm run electron\n```\n\nYou should see the Electron app popping up.\n\n### Build the binary (Optional)\n\nOne further, albeit optional step is to create an OS-specific binary. This is done with the following command:\n\n```bash\nnpm run release\n```\n\nThis command may take some time. Once finished, you will see binaries for your OS in the `dist/` folder.\n\n## Developing\n\nThe best Developer Experience is achieved by running:\n\n```bash\nparity --ui-no-validation # Warning: INSECURE. Only use it when developing the UI.\nnpm start\n```\n\nA new browser tab will open on `http://localhost:3000` with the UI, and this tab will refresh on any code change. This DX allows fast iterations.\n\nIf you want to test the rendering in an Electron window, run the following command in parallel with the previous command:\n\n```bash\nnpm run electron:dev\n```\n\nThis will spawn an Electron window serving `http://localhost:3000`. Same thing, the Electron window will refresh on any code change.\n\n## CLI Options\nAll other flags passed to Parity UI will be passed down to parity when trying to launch it.\n```bash\nOperating Options:\n    --no-run-parity\n        Parity UI will not attempt to run \n        the locally installed parity.\n\n    --ui-dev\n        Parity UI will load http://localhost:3000. \n        WARNING: Only use this is you plan on developing on Parity UI.\n\n    --ws-interface=[IP]\n        Specify the hostname portion of the WebSockets server \n        Parity UI will connect to. IP should be an \n        interface's IP address. (default: 127.0.0.1)\n\n    --ws-port=[PORT]\n        Specify the port portion of the WebSockets \n        server Parity UI will connect to. (default: 8546)\n```\n"}, {"repo": "/crossoverJie/JCSprout", "language": "Java", "readme_contents": "\n<div align=\"center\">  \n\n<img src=\"https://ws1.sinaimg.cn/large/0069RVTdly1fubocn5pxaj30go082dg1.jpg\" width=\"\"/> \n<br/>\n\n[![Build Status](https://travis-ci.org/crossoverJie/JCSprout.svg?branch=master)](https://travis-ci.org/crossoverJie/JCSprout)\n[![QQ\u7fa4](https://img.shields.io/badge/QQ%E7%BE%A4-787381170-yellowgreen.svg)](https://jq.qq.com/?_wv=1027&k=5HPYvQk)\n\n[qq0groupsvg]: https://img.shields.io/badge/QQ%E7%BE%A4-787381170-yellowgreen.svg\n[qq0group]: https://jq.qq.com/?_wv=1027&k=5HPYvQk\n\n</div><br>\n\n\n> `Java Core Sprout`\uff1a\u5904\u4e8e\u840c\u82bd\u9636\u6bb5\u7684 Java \u6838\u5fc3\u77e5\u8bc6\u5e93\u3002\n\n**\u8bbf\u95ee\u8fd9\u91cc\u83b7\u53d6\u66f4\u597d\u7684\u9605\u8bfb\u4f53\u9a8c**\uff1a[https://crossoverjie.top/JCSprout/](https://crossoverjie.top/JCSprout/)\n\n<br/>\n\n\n| \ud83d\udcca |\u2694\ufe0f | \ud83d\udda5 | \ud83d\ude8f | \ud83c\udfd6  | \ud83c\udf01| \ud83d\udcee | \ud83d\udd0d | \ud83d\ude80 | \ud83c\udf08 |\ud83d\udca1\n| :--------: | :---------: | :---------: | :---------: | :---------: | :---------:| :---------: | :-------: | :-------:| :------:|:------:|\n| [\u96c6\u5408](#\u5e38\u7528\u96c6\u5408) | [\u591a\u7ebf\u7a0b](#java-\u591a\u7ebf\u7a0b)|[JVM](#jvm) | [\u5206\u5e03\u5f0f](#\u5206\u5e03\u5f0f\u76f8\u5173) |[\u6846\u67b6](#\u5e38\u7528\u6846\u67b6\u7b2c\u4e09\u65b9\u7ec4\u4ef6)|[\u67b6\u6784\u8bbe\u8ba1](#\u67b6\u6784\u8bbe\u8ba1)| [\u6570\u636e\u5e93](#db-\u76f8\u5173) |[\u7b97\u6cd5](#\u6570\u636e\u7ed3\u6784\u4e0e\u7b97\u6cd5)|[Netty](#netty-\u76f8\u5173)| [\u9644\u52a0\u6280\u80fd](#\u9644\u52a0\u6280\u80fd)|[\u8054\u7cfb\u4f5c\u8005](#\u8054\u7cfb\u4f5c\u8005) |\n\n\n\n### \u5e38\u7528\u96c6\u5408\n- [ArrayList/Vector](https://github.com/crossoverJie/JCSprout/blob/master/MD/ArrayList.md)\n- [LinkedList](https://github.com/crossoverJie/JCSprout/blob/master/MD/LinkedList.md)\n- [HashMap](https://github.com/crossoverJie/JCSprout/blob/master/MD/HashMap.md)\n- [HashSet](https://github.com/crossoverJie/JCSprout/blob/master/MD/collection/HashSet.md)\n- [LinkedHashMap](https://github.com/crossoverJie/JCSprout/blob/master/MD/collection/LinkedHashMap.md)\n\n### Java \u591a\u7ebf\u7a0b\n- [\u591a\u7ebf\u7a0b\u4e2d\u7684\u5e38\u89c1\u95ee\u9898](https://github.com/crossoverJie/JCSprout/blob/master/MD/Thread-common-problem.md)\n- [synchronized \u5173\u952e\u5b57\u539f\u7406](https://github.com/crossoverJie/JCSprout/blob/master/MD/Synchronize.md)\n- [\u591a\u7ebf\u7a0b\u7684\u4e09\u5927\u6838\u5fc3](https://github.com/crossoverJie/JCSprout/blob/master/MD/Threadcore.md)\n- [\u5bf9\u9501\u7684\u4e00\u4e9b\u8ba4\u77e5](https://github.com/crossoverJie/JCSprout/blob/master/MD/Java-lock.md)\n- [ReentrantLock \u5b9e\u73b0\u539f\u7406 ](https://github.com/crossoverJie/JCSprout/blob/master/MD/ReentrantLock.md)\n- [ConcurrentHashMap \u7684\u5b9e\u73b0\u539f\u7406](https://github.com/crossoverJie/JCSprout/blob/master/MD/ConcurrentHashMap.md)\n- [\u5982\u4f55\u4f18\u96c5\u7684\u4f7f\u7528\u548c\u7406\u89e3\u7ebf\u7a0b\u6c60](https://github.com/crossoverJie/JCSprout/blob/master/MD/ThreadPoolExecutor.md)\n- [\u6df1\u5165\u7406\u89e3\u7ebf\u7a0b\u901a\u4fe1](https://github.com/crossoverJie/JCSprout/blob/master/MD/concurrent/thread-communication.md)\n- [\u4e00\u4e2a\u7ebf\u7a0b\u7f62\u5de5\u7684\u8be1\u5f02\u4e8b\u4ef6](docs/thread/thread-gone.md)\n- [\u7ebf\u7a0b\u6c60\u4e2d\u4f60\u4e0d\u5bb9\u9519\u8fc7\u7684\u4e00\u4e9b\u7ec6\u8282](docs/thread/thread-gone2.md)\n- [\u300e\u5e76\u53d1\u5305\u5165\u5751\u6307\u5317\u300f\u4e4b\u963b\u585e\u961f\u5217](docs/thread/ArrayBlockingQueue.md)\n\n### JVM\n- [Java \u8fd0\u884c\u65f6\u5185\u5b58\u5212\u5206](https://github.com/crossoverJie/JCSprout/blob/master/MD/MemoryAllocation.md)\n-  [\u7c7b\u52a0\u8f7d\u673a\u5236](https://github.com/crossoverJie/JCSprout/blob/master/MD/ClassLoad.md)\n-  [OOM \u5206\u6790](https://github.com/crossoverJie/JCSprout/blob/master/MD/OOM-analysis.md)\n- [\u5783\u573e\u56de\u6536](https://github.com/crossoverJie/JCSprout/blob/master/MD/GarbageCollection.md)\n- [\u5bf9\u8c61\u7684\u521b\u5efa\u4e0e\u5185\u5b58\u5206\u914d](https://github.com/crossoverJie/JCSprout/blob/master/MD/newObject.md)\n- [\u4f60\u5e94\u8be5\u77e5\u9053\u7684 volatile \u5173\u952e\u5b57](https://github.com/crossoverJie/JCSprout/blob/master/MD/concurrent/volatile.md)\n- [\u4e00\u6b21\u5185\u5b58\u6ea2\u51fa\u6392\u67e5\u4f18\u5316\u5b9e\u6218](https://crossoverjie.top/2018/08/29/java-senior/OOM-Disruptor/)\n- [\u4e00\u6b21 HashSet \u6240\u5f15\u8d77\u7684\u5e76\u53d1\u95ee\u9898](docs/jvm/JVM-concurrent-HashSet-problem.md)\n- [\u4e00\u6b21\u751f\u4ea7 CPU 100% \u6392\u67e5\u4f18\u5316\u5b9e\u8df5](docs/jvm/cpu-percent-100.md)\n\n### \u5206\u5e03\u5f0f\u76f8\u5173\n\n- [\u5206\u5e03\u5f0f\u9650\u6d41](http://crossoverjie.top/2018/04/28/sbc/sbc7-Distributed-Limit/)\n- [\u57fa\u4e8e Redis \u7684\u5206\u5e03\u5f0f\u9501](http://crossoverjie.top/2018/03/29/distributed-lock/distributed-lock-redis/)\n- [\u5206\u5e03\u5f0f\u7f13\u5b58\u8bbe\u8ba1](https://github.com/crossoverJie/JCSprout/blob/master/MD/Cache-design.md)\n- [\u5206\u5e03\u5f0f ID \u751f\u6210\u5668](https://github.com/crossoverJie/JCSprout/blob/master/MD/ID-generator.md)\n\n### \u5e38\u7528\u6846\u67b6\\\u7b2c\u4e09\u65b9\u7ec4\u4ef6\n\n- [Spring Bean \u751f\u547d\u5468\u671f](https://github.com/crossoverJie/JCSprout/blob/master/MD/spring/spring-bean-lifecycle.md)\n- [Spring AOP \u7684\u5b9e\u73b0\u539f\u7406](https://github.com/crossoverJie/JCSprout/blob/master/MD/SpringAOP.md) \n- [Guava \u6e90\u7801\u5206\u6790\uff08Cache \u539f\u7406\uff09](https://crossoverjie.top/2018/06/13/guava/guava-cache/)\n- [\u8f7b\u91cf\u7ea7 HTTP \u6846\u67b6](https://github.com/crossoverJie/cicada)\n- [Kafka produce \u6e90\u7801\u5206\u6790](https://github.com/crossoverJie/JCSprout/blob/master/MD/kafka/kafka-product.md)\n- [Kafka \u6d88\u8d39\u5b9e\u8df5](https://github.com/crossoverJie/JCSprout/blob/master/docs/frame/kafka-consumer.md)\n\n\n### \u67b6\u6784\u8bbe\u8ba1\n- [\u79d2\u6740\u7cfb\u7edf\u8bbe\u8ba1](https://github.com/crossoverJie/JCSprout/blob/master/MD/Spike.md)\n- [\u79d2\u6740\u67b6\u6784\u5b9e\u8df5](http://crossoverjie.top/2018/05/07/ssm/SSM18-seconds-kill/)\n- [\u8bbe\u8ba1\u4e00\u4e2a\u767e\u4e07\u7ea7\u7684\u6d88\u606f\u63a8\u9001\u7cfb\u7edf](https://github.com/crossoverJie/JCSprout/blob/master/MD/architecture-design/million-sms-push.md)\n\n### DB \u76f8\u5173\n\n- [MySQL \u7d22\u5f15\u539f\u7406](https://github.com/crossoverJie/JCSprout/blob/master/MD/MySQL-Index.md)\n- [SQL \u4f18\u5316](https://github.com/crossoverJie/JCSprout/blob/master/MD/SQL-optimization.md)\n- [\u6570\u636e\u5e93\u6c34\u5e73\u5782\u76f4\u62c6\u5206](https://github.com/crossoverJie/JCSprout/blob/master/MD/DB-split.md)\n- [\u4e00\u6b21\u5206\u8868\u8e29\u5751\u5b9e\u8df5\u7684\u63a2\u8ba8](docs/db/sharding-db.md)\n\n### \u6570\u636e\u7ed3\u6784\u4e0e\u7b97\u6cd5\n- [\u7ea2\u5305\u7b97\u6cd5](https://github.com/crossoverJie/JCSprout/blob/master/src/main/java/com/crossoverjie/red/RedPacket.java)\n- [\u4e8c\u53c9\u6811\u5c42\u5e8f\u904d\u5386](https://github.com/crossoverJie/JCSprout/blob/master/src/main/java/com/crossoverjie/algorithm/BinaryNode.java#L76-L101)\n- [\u662f\u5426\u4e3a\u5feb\u4e50\u6570\u5b57](https://github.com/crossoverJie/JCSprout/blob/master/src/main/java/com/crossoverjie/algorithm/HappyNum.java#L38-L55)\n- [\u94fe\u8868\u662f\u5426\u6709\u73af](https://github.com/crossoverJie/JCSprout/blob/master/src/main/java/com/crossoverjie/algorithm/LinkLoop.java#L32-L59)\n- [\u4ece\u4e00\u4e2a\u6570\u7ec4\u4e2d\u8fd4\u56de\u4e24\u4e2a\u503c\u76f8\u52a0\u7b49\u4e8e\u76ee\u6807\u503c\u7684\u4e0b\u6807](https://github.com/crossoverJie/JCSprout/blob/master/src/main/java/com/crossoverjie/algorithm/TwoSum.java#L38-L59)\n- [\u4e00\u81f4\u6027 Hash \u7b97\u6cd5\u539f\u7406](https://github.com/crossoverJie/JCSprout/blob/master/MD/Consistent-Hash.md)\n- [\u4e00\u81f4\u6027 Hash \u7b97\u6cd5\u5b9e\u8df5](https://github.com/crossoverJie/JCSprout/blob/master/docs/algorithm/consistent-hash-implement.md)\n- [\u9650\u6d41\u7b97\u6cd5](https://github.com/crossoverJie/JCSprout/blob/master/MD/Limiting.md)\n- [\u4e09\u79cd\u65b9\u5f0f\u53cd\u5411\u6253\u5370\u5355\u5411\u94fe\u8868](https://github.com/crossoverJie/JCSprout/blob/master/src/main/java/com/crossoverjie/algorithm/ReverseNode.java)\n- [\u5408\u5e76\u4e24\u4e2a\u6392\u597d\u5e8f\u7684\u94fe\u8868](https://github.com/crossoverJie/JCSprout/blob/master/src/main/java/com/crossoverjie/algorithm/MergeTwoSortedLists.java)\n- [\u4e24\u4e2a\u6808\u5b9e\u73b0\u961f\u5217](https://github.com/crossoverJie/JCSprout/blob/master/src/main/java/com/crossoverjie/algorithm/TwoStackQueue.java)\n- [\u52a8\u624b\u5b9e\u73b0\u4e00\u4e2a LRU cache](http://crossoverjie.top/2018/04/07/algorithm/LRU-cache/)\n- [\u94fe\u8868\u6392\u5e8f](./src/main/java/com/crossoverjie/algorithm/LinkedListMergeSort.java)\n- [\u6570\u7ec4\u53f3\u79fb k \u6b21](./src/main/java/com/crossoverjie/algorithm/ArrayKShift.java)\n- [\u4ea4\u66ff\u6253\u5370\u5947\u5076\u6570](https://github.com/crossoverJie/JCSprout/blob/master/src/main/java/com/crossoverjie/actual/TwoThread.java)\n- [\u4ebf\u7ea7\u6570\u636e\u4e2d\u5224\u65ad\u6570\u636e\u662f\u5426\u4e0d\u5b58\u5728](https://github.com/crossoverJie/JCSprout/blob/master/docs/algorithm/guava-bloom-filter.md) \n\n### Netty \u76f8\u5173\n- [SpringBoot \u6574\u5408\u957f\u8fde\u63a5\u5fc3\u8df3\u673a\u5236](https://crossoverjie.top/2018/05/24/netty/Netty(1)TCP-Heartbeat/)\n- [\u4ece\u7ebf\u7a0b\u6a21\u578b\u7684\u89d2\u5ea6\u770b Netty \u4e3a\u4ec0\u4e48\u662f\u9ad8\u6027\u80fd\u7684\uff1f](https://crossoverjie.top/2018/07/04/netty/Netty(2)Thread-model/)\n- [\u4e3a\u81ea\u5df1\u642d\u5efa\u4e00\u4e2a\u5206\u5e03\u5f0f IM(\u5373\u65f6\u901a\u8baf) \u7cfb\u7edf](https://github.com/crossoverJie/cim)\n\n### \u9644\u52a0\u6280\u80fd\n\n- [TCP/IP \u534f\u8bae](https://github.com/crossoverJie/JCSprout/blob/master/MD/TCP-IP.md)\n- [\u4e00\u4e2a\u5b66\u6e23\u7684\u963f\u91cc\u4e4b\u8def](https://crossoverjie.top/2018/06/21/personal/Interview-experience/)\n- [\u5982\u4f55\u6210\u4e3a\u4e00\u4f4d\u300c\u4e0d\u90a3\u4e48\u5dee\u300d\u7684\u7a0b\u5e8f\u5458](https://crossoverjie.top/2018/08/12/personal/how-to-be-developer/)\n- [\u5982\u4f55\u9ad8\u6548\u7684\u4f7f\u7528 Git](https://github.com/crossoverJie/JCSprout/blob/master/MD/additional-skills/how-to-use-git-efficiently.md)\n\n\n### \u8054\u7cfb\u4f5c\u8005\n\n> crossoverJie#gmail.com\n\n<img src=\"https://ws2.sinaimg.cn/large/006tKfTcly1fsa01u7ro1j30gs0howfq.jpg\" width=\"300\"/> \n"}, {"repo": "/lazywinadmin/PowerShell", "language": "PowerShell", "readme_contents": "# PowerShell\n\nThis repository is used for all my public scripts.\nLet me know if you have any issues using them, always space for improvement\nFeel free to fork\n\n* [Blog](https://lazywinadmin.com)\n* [Twitter @LazyWinAdmin](https://twitter.com/LazyWinAdmin)\n"}, {"repo": "/clymb3r/PowerShell", "language": "PowerShell", "readme_contents": "The tools in this directory are part of PowerSploit and are being maintained there. They are preserved here for legacy, but any bug fixes should be checked in to PowerSploit.\n\nhttps://github.com/mattifestation/PowerSploit"}, {"repo": "/nickola/web-console", "language": "JavaScript", "readme_contents": "# About\n\nWeb Console is a web-based application that allows to execute shell commands on a server directly from a browser (web-based SSH).\nThe application is very light, does not require any database and can be installed and configured in about 3 minutes.\n\nIf you like Web Console, please consider an opportunity to support it on [Patreon](https://www.patreon.com/nickola).\n\n![Web Console](https://raw.github.com/nickola/web-console/master/screenshots/main.png)\n\n# Installation\n\nInstallation process is really simple:\n\n  - [Download](https://github.com/nickola/web-console/releases/download/v0.9.7/webconsole-0.9.7.zip) latest version of the Web Console.\n  - Unpack archive and open file `webconsole.php` in your favorite text editor.\n  - At the beginning of the file enter your `$USER` and `$PASSWORD` credentials, edit any other settings that you like (see description in the comments).\n  - Upload changed `webconsole.php` file to the web server and open it in the browser.\n\n# About author\n\nWeb Console has been developed by [Nickolay Kovalev](http://nickola.ru).\nIf you have interest job offers, you can see him contacts at his [CV](http://cv.nickola.ru).\nAlso, various third-party components are used.\n\n# Used components\n\n  - jQuery JavaScript Library: https://github.com/jquery/jquery\n  - jQuery Terminal Emulator: https://github.com/jcubic/jquery.terminal\n  - jQuery Mouse Wheel Plugin: https://github.com/brandonaaron/jquery-mousewheel\n  - PHP JSON-RPC 2.0 Server/Client Implementation: https://github.com/sergeyfast/eazy-jsonrpc\n  - Normalize.css: https://github.com/necolas/normalize.css\n\n# URLs\n\n - Website: http://web-console.org\n - GitHub: https://github.com/nickola/web-console\n - Patreon: https://www.patreon.com/nickola\n - Author: http://nickola.ru\n\n# License\n\nWeb Console is licensed under [GNU LGPL Version 3](http://www.gnu.org/licenses/lgpl.html) license.\n"}, {"repo": "/ROCmSoftwarePlatform/rocRAND", "language": "C", "readme_contents": "# rocRAND\n\nThe rocRAND project provides functions that generate pseudo-random and quasi-random numbers.\n\nThe rocRAND library is implemented in the [HIP](https://github.com/ROCm-Developer-Tools/HIP)\nprogramming language and optimised for AMD's latest discrete GPUs. It is designed to run on top\nof AMD's Radeon Open Compute [ROCm](https://rocm.github.io/) runtime, but it also works on\nCUDA enabled GPUs.\n\nAdditionally, the project includes a wrapper library called hipRAND which allows user to easily port\nCUDA applications that use cuRAND library to the [HIP](https://github.com/ROCm-Developer-Tools/HIP)\nlayer. In [ROCm](https://rocm.github.io/) environment hipRAND uses rocRAND, however in CUDA\nenvironment cuRAND is used instead.\n\n## Supported Random Number Generators\n\n* XORWOW\n* MRG32k3a\n* Mersenne Twister for Graphic Processors (MTGP32)\n* Philox (4x32, 10 rounds)\n* Sobol32\n\n## Requirements\n\n* Git\n* cmake (3.0.2 or later)\n* C++ compiler with C++11 support\n* For AMD platforms:\n  * [ROCm](https://rocm.github.io/install.html) (1.7 or later)\n  * [HCC](https://github.com/RadeonOpenCompute/hcc) compiler, which must be\n    set as C++ compiler on ROCm platform.\n* For CUDA platforms:\n  * [HIP](https://github.com/ROCm-Developer-Tools/HIP) (hcc is not required)\n  * Latest CUDA SDK\n\nOptional:\n\n* [GTest](https://github.com/google/googletest) (required only for tests; building tests is enabled by default)\n  * Use `GTEST_ROOT` to specify GTest location (also see [FindGTest](https://cmake.org/cmake/help/latest/module/FindGTest.html))\n  * Note: If GTest is not already installed, it will be automatically downloaded and built\n* [TestU01](http://simul.iro.umontreal.ca/testu01/tu01.html) (required only for crush tests)\n  * Use `TESTU01_ROOT_DIR` to specify TestU01 location\n  * Note: If TestU01 is not already installed, it will be automatically downloaded and built\n* Fortran compiler (required only for Fortran wrapper)\n  * `gfortran` is recommended.\n* Python 2.7+ or 3.5+ (required only for Python wrapper)\n\nIf some dependencies are missing, cmake script automatically downloads, builds and\ninstalls them. Setting `DEPENDENCIES_FORCE_DOWNLOAD` option `ON` forces script to\nnot to use system-installed libraries, and to download all dependencies.\n\n## Build and Install\n\n```\ngit clone https://github.com/ROCmSoftwarePlatform/rocRAND.git\n\n# Go to rocRAND directory, create and go to build directory\ncd rocRAND; mkdir build; cd build\n\n# Configure rocRAND, setup options for your system\n# Build options: BUILD_TEST, BUILD_BENCHMARK (off by default), BUILD_CRUSH_TEST (off by default)\n#\n# ! IMPORTANT !\n# On ROCm platform set C++ compiler to HCC. You can do it by adding 'CXX=<path-to-hcc>' or just\n# `CXX=hcc` before 'cmake', or setting cmake option 'CMAKE_CXX_COMPILER' to path to the HCC compiler.\n#\n[CXX=hcc] cmake -DBUILD_BENCHMARK=ON ../. # or cmake-gui ../.\n\n# Build\n# For ROCM-1.6, if a HCC runtime error is caught, consider setting\n# HCC_AMDGPU_TARGET=<arch> in front of make as a workaround\nmake -j4\n\n# Optionally, run tests if they're enabled\nctest --output-on-failure\n\n# Install\n[sudo] make install\n```\n\nNote: Existing gtest library in the system (especially static gtest libraries built with other compilers)\nmay cause build failure; if errors are encountered with existing gtest library or other dependencies,\n`DEPENDENCIES_FORCE_DOWNLOAD` flag can be passed to cmake, as mentioned before, to help solve the problem.\n\nNote: To disable inline assembly optimisations in rocRAND (for both the host library and\nthe device functions provided in `rocrand_kernel.h`) set cmake option `ENABLE_INLINE_ASM`\nto `OFF`.\n\n## Running Unit Tests\n\n```\n# Go to rocRAND build directory\ncd rocRAND; cd build\n\n# To run all tests\nctest\n\n# To run unit tests\n./test/<unit-test-name>\n```\n\n## Running Benchmarks\n\n```\n# Go to rocRAND build directory\ncd rocRAND; cd build\n\n# To run benchmark for generate functions:\n# engine -> all, xorwow, mrg32k3a, mtgp32, philox, sobol32\n# distribution -> all, uniform-uint, uniform-float, uniform-double, normal-float, normal-double,\n#                 log-normal-float, log-normal-double, poisson\n# Further option can be found using --help\n./benchmark/benchmark_rocrand_generate --engine <engine> --dis <distribution>\n\n# To run benchmark for device kernel functions:\n# engine -> all, xorwow, mrg32k3a, mtgp32, philox, sobol32\n# distribution -> all, uniform-uint, uniform-float, uniform-double, normal-float, normal-double,\n#                 log-normal-float, log-normal-double, poisson, discrete-poisson, discrete-custom\n# further option can be found using --help\n./benchmark/benchmark_rocrand_kernel --engine <engine> --dis <distribution>\n\n# To compare against cuRAND (cuRAND must be supported):\n./benchmark/benchmark_curand_generate --engine <engine> --dis <distribution>\n./benchmark/benchmark_curand_kernel --engine <engine> --dis <distribution>\n```\n\n## Running Statistical Tests\n\n```\n# Go to rocRAND build directory\ncd rocRAND; cd build\n\n# To run \"crush\" test, which verifies that generated pseudorandom\n# numbers are of high quality:\n# engine -> all, xorwow, mrg32k3a, mtgp32, philox\n./test/crush_test_rocrand --engine <engine>\n\n# To run Pearson Chi-squared and Anderson-Darling tests, which verify\n# that distribution of random number agrees with the requested distribution:\n# engine -> all, xorwow, mrg32k3a, mtgp32, philox, sobol32\n# distribution -> all, uniform-float, uniform-double, normal-float, normal-double,\n#                 log-normal-float, log-normal-double, poisson\n./test/stat_test_rocrand_generate --engine <engine> --dis <distribution>\n```\n\n## Documentation\n\n```\n# go to rocRAND doc directory\ncd rocRAND; cd doc\n\n# run doxygen\ndoxygen Doxyfile\n\n# open html/index.html\n\n```\n\n## Wrappers\n\n* C++ wrappers for host API of rocRAND and hipRAND are in files [`rocrand.hpp`](./library/include/rocrand.hpp)\nand [`hiprand.hpp`](./library/include/hiprand.hpp).\n* [Fortran wrappers](./library/src/fortran/).\n* [Python wrappers](./python/): [rocRAND](./python/rocrand) and [hipRAND](./python/hiprand).\n\n## Support\n\nBugs and feature requests can be reported through [the issue tracker](https://github.com/ROCmSoftwarePlatform/rocRAND/issues).\n\n## Contributions and License\n\nContributions of any kind are most welcome! More details are found at [CONTRIBUTING](./CONTRIBUTING.md)\nand [LICENSE](./LICENSE.txt). Please note that [statistical tests](./test/crush) link to TestU01 library\ndistributed under GNU General Public License (GPL) version 3, thus GPL version 3 license applies to\nthat part of the project.\n"}, {"repo": "/metacall/core", "language": "C", "readme_contents": "<div align=\"center\">\n  <a href=\"https://metacall.io\" target=\"_blank\"><img src=\"https://raw.githubusercontent.com/metacall/core/master/deploy/images/logo.png\" alt=\"M E T A C A L L\" style=\"max-width:100%; margin: 0 auto;\" width=\"80\" height=\"80\">\n  <p><b>M E T A C A L L</b></p></a>\n  <p>A library for providing inter-language foreign function interface calls</p>\n</div>\n\n# Abstract\n\n**METACALL** is a library that allows calling functions, methods or procedures between programming languages. With **METACALL** you can transparently execute code from / to any programming language, for example, call Python code from JavaScript code.\n\n`sum.py`\n``` python\ndef sum(a, b):\n  return a + b\n```\n\n`main.js`\n``` javascript\nmetacall_load_from_file('py', [ 'sum.py' ]);\n\nmetacall('sum', 3, 4); // 7\n```\n\n<div align=\"center\">\n  <a href=\"https://medium.com/@metacall/call-functions-methods-or-procedures-between-programming-languages-with-metacall-58cfece35d7\" target=\"_blank\"><img src=\"https://raw.githubusercontent.com/metacall/core/master/deploy/images/overview.png\" alt=\"M E T A C A L L\" style=\"max-width:100%; margin: 0 auto;\" width=\"350\" height=\"auto\">\n</div>\n\n# Table Of Contents\n\n<!-- TOC -->\n\n- [Abstract](#abstract)\n- [Table Of Contents](#table-of-contents)\n    - [1. Motivation](#1-motivation)\n    - [2. Language Support (Backends)](#2-language-support-backends)\n    - [3. Use Cases](#3-use-cases)\n    - [3.1 Known Projects Using MetaCall](#31-known-projects-using-metacall)\n    - [4. Usage](#4-usage)\n    - [4.1 Installation](#41-installation)\n        - [4.2 Environment Variables](#42-environment-variables)\n        - [4.3 Examples](#43-examples)\n    - [5. Architecture](#5-architecture)\n        - [5.1 Overview](#51-overview)\n            - [5.1.1 Design Decisions](#511-design-decisions)\n            - [5.1.2 Modules](#512-modules)\n        - [5.2 Reflect](#52-reflect)\n            - [5.2.1 Type System](#521-type-system)\n            - [5.2.2 Values](#522-values)\n            - [5.2.3 Functions](#523-functions)\n        - [5.3 Plugins](#53-plugins)\n            - [5.3.1 Loaders](#531-loaders)\n                - [5.3.1.1 Python](#5311-python)\n                - [5.3.1.2 NodeJS](#5312-nodejs)\n                - [5.3.1.3 JavaScript](#5313-javascript)\n                - [5.3.1.4 C#](#5314-c)\n                - [5.3.1.5 Ruby](#5315-ruby)\n                - [5.3.1.6 Mock](#5316-mock)\n                - [5.3.1.7 File](#5317-file)\n            - [5.3.2 Serials](#532-serials)\n                - [5.3.2.1 MetaCall](#5321-metacall)\n                - [5.3.2.2 RapidJSON](#5322-rapidjson)\n            - [5.3.3 Detours](#533-detours)\n                - [5.3.3.1 FuncHook](#5331-funchook)\n        - [5.4 Ports](#54-ports)\n        - [5.5 Serialization](#55-serialization)\n        - [5.6 Memory Layout](#56-memory-layout)\n        - [5.7 Fork Model](#57-fork-model)\n        - [5.8 Threading Model](#58-threading-model)\n    - [5. Application Programming Interface (API)](#5-application-programming-interface-api)\n    - [6. Build System](#6-build-system)\n        - [6.1 Build Options](#61-build-options)\n        - [6.2 Coverage](#62-coverage)\n    - [7. Platform Support](#7-platform-support)\n        - [7.1 Docker Support](#71-docker-support)\n        - [7.1.1 Docker Development](#711-docker-development)\n        - [7.1.2 Docker Testing](#712-docker-testing)\n    - [8. License](#8-license)\n\n<!-- /TOC -->\n\n## 1. Motivation\n\nThe **METACALL** project started time ago when I was coding a [Game Engine for an MMORPG](https://bitbucket.org/parrastudios/argentum-online-c). My idea was to provide an interface to allow other programmers extend the Game Engine easily. By that time, I was finishing the university so I decide to do my [Final Thesis](https://bitbucket.org/parrastudios/argentum-online-c/raw/e6e78fef80c6adc541640d68d422721ef735184f/common/doc/Plugin/plugin-framework-paper.pdf) and [Presentation](https://bitbucket.org/parrastudios/argentum-online-c/raw/e6e78fef80c6adc541640d68d422721ef735184f/common/doc/Plugin/plugin-framework-presentation.pdf) based on the plug-in system for my Game Engine. The Plugin Architecture designed for the Game Engine has similarities with **METACALL** although the architecture has been redefined and the code has been rewritten from scratch. After some refination of the system, I came up with **METACALL** and other use cases for the tool. Currently we are using **METACALL** to build a cutting edge FaaS (Function as a Service) **[https://metacall.io](https://metacall.io/)** based on this technique to provide high scalability of the functions among multiple cores and **[Function Mesh](https://medium.com/@metacall/function-mesh-architecture-c0304ba4bad0)** pattern, a new technique I have developed to interconnect transparently functions in a distributed system based on this library.\n\n## 2. Language Support (Backends)\n\nThis section describes all programming languages that **METACALL** supports, if you are interested in from what languages can be used **METACALL** you must go to [ports section](#54-ports).\n\n- Currently supported languages and run-times:\n\n| Language                                                           | Runtime                                                                                      |               Version                | Tag  |\n|--------------------------------------------------------------------|----------------------------------------------------------------------------------------------|:------------------------------------:|:----:|\n| [Python](https://www.python.org/)                                  | [Python C API](https://docs.python.org/3/c-api/intro.html)                                   |          **>= 3.2 <= 3.7**           |  py  |\n| [NodeJS](https://nodejs.org/)                                      | [N API](https://nodejs.org/api/n-api.html)                                                   | **>= 8.11.1<sup>\u2020</sup> <= 10.16.3** | node |\n| [JavaScript](https://developer.mozilla.org/bm/docs/Web/JavaScript) | [V8](https://v8.dev/)                                                                        |             **5.1.117**              |  js  |\n| [C#](https://dotnet.microsoft.com/)                                | [NetCore](https://github.com/dotnet/docs/blob/master/docs/core/tutorials/netcore-hosting.md) |    **>= 1.0.0-preview2 <= 2.2.7**    |  cs  |\n| [Ruby](https://ruby-lang.org/)                                     | [Ruby C API](https://silverhammermba.github.io/emberb/c/)                                    |          **>= 2.1 <= 2.3**           |  rb  |\n| [File](/source/loaders/file_loader)                                | **\u2205**                                                                                        |              **0.1.0**               | file |\n| [Mock](/source/loaders/mock_loader)                                | **\u2205**                                                                                        |              **0.1.0**               | mock |\n\n\u2020. **NodeJS 8.x** does not support async functions.\n\n- Languages and run-times under construction:\n\n| Language                                                           | Runtime                                                                                                | Tag  |\n|--------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------|:----:|\n| [WebAssembly](https://webassembly.org/)                            | [WebAssembly Virtual Machine](https://github.com/WAVM/WAVM)                                            | wasm |\n| [C/C++](http://www.cplusplus.com/)                                 | [Clang](https://clang.llvm.org/) - [LLVM](https://llvm.org/) - [libffi](http://sourceware.org/libffi/) |  c   |\n| [Java](https://www.java.com/)                                      | [JNI](https://docs.oracle.com/javase/8/docs/technotes/guides/jni/)                                     | java |\n| [PHP](https://php.net/)                                            | [Zend](https://www.php.net/manual/en/internals2.ze1.zendapi.php)                                       | php  |\n| [Go](https://golang.org/)                                          | Go Runtime                                                                                             |  go  |\n| [Haskell](https://www.haskell.org/)                                | [Haskell FFI](https://wiki.haskell.org/GHC/Using_the_FFI)                                              |  hs  |\n| [JavaScript](https://developer.mozilla.org/bm/docs/Web/JavaScript) | [SpiderMonkey](https://developer.mozilla.org/en-US/docs/Mozilla/Projects/SpiderMonkey/JSAPI_reference) | jsm  |\n\n## 3. Use Cases\n\n**METACALL** can be used in the following cases:\n\n- Interconnect different technologies in the same project. It allows to have heterogeneous teams of developers working over same project in an isolated way and using different programming languages at the same time.\n\n- Embedding programming languages to existing softwares. Game Engines, 3D Editors like [Blender](https://www.blender.org/), among others can take benefit of **METACALL** and extend the core functionality with higher level programming languages (aka scripting).\n\n- Function as a Service. **METACALL** can be used to implement efficient FaaS architectures. We are using it to implement our own FaaS (Function as a Service) **[https://metacall.io](https://metacall.io/)** based on **[Function Mesh](https://medium.com/@metacall/function-mesh-architecture-c0304ba4bad0)** pattern and high performance function scalability thanks to this library.\n\n- Source code migrations. **METACALL** can wrap large and legacy code-bases, and provide an agnostic way to work with the codebase into a new programming language. Eventually the code can be migrated by parts, without need of creating a new project or stopping the production environment. Incremental changes can be done, solving the migration easily and with less time and effort.\n\n- Porting low level libraries to high level languages transparently. With **METACALL** you can get rid of extension APIs like Python C API or NodeJS N-API. You can call directly low level libraries from your high level languages without making a wrapper in C or C++ for it.\n\nAs you can see, there are plenty of uses. **METACALL** introduces a new model of programming which allows a high interoperability between technologies. If you find any other use case just let us know about it with a Pull Request and we will add it to the list.\n\n## 3.1 Known Projects Using MetaCall\n\n- **[Acid Cam](https://www.facebook.com/AcidCam/)**: A software for video manipulation that distorts videos for generating art by means of OpenCV. [Acid Cam CLI](https://github.com/lostjared/acidcam-cli) uses **METACALL** to allow custom filters written in Python and easily embed Python programming language into its plugin system.\n\n## 4. Usage\n\n## 4.1 Installation\n\nPrior to try any example, you must have **METACALL** installed in your system. To install **METACALL** you have the following options.\n\n- [Download a release](/TODO).\n- [Install via package manager](/TODO).\n- [Build and install it manually](#6-build-system).\n- [Pull it from DockerHub](/TODO).\n\n### 4.2 Environment Variables\n\nThis environment variables are optional, in case that you want to modify default paths of **METACALL**.\n\n|           Name            | Description                                                      |          Default Value           |\n|:-------------------------:|------------------------------------------------------------------|:--------------------------------:|\n| **`DETOUR_LIBRARY_PATH`** | Directory where detour plugins to be loaded are located          |          **`detours`**           |\n| **`SERIAL_LIBRARY_PATH`** | Directory where serial plugins to be loaded are located          |          **`serials`**           |\n| **`CONFIGURATION_PATH`**  | File path where the **METACALL** global configuration is located | **`configurations/global.json`** |\n| **`LOADER_LIBRARY_PATH`** | Directory where loader plugins to be loaded are located          |          **`loaders`**           |\n| **`LOADER_SCRIPT_PATH`**  | Directory where scripts to be loaded are located                 | **`${execution_path}`** &#x00B9; |\n\n&#x00B9; **`${execution_path}`** defines the path where the program is executed, **`.`** in Linux.\n\n### 4.3 Examples\n\n- [MetaCall CLI](/source/examples/metacallcli). Example of a Command Language Interpreter based on MetaCall where you can load, unload scripts and call their functions.\n\n- [MetaCall Rotulin](https://github.com/metacall/rotulin). Example of a multi-language application built with **METACALL**. This application embeds a Django server with a Ruby DataBase and C# business layer based on ImageMagick.\n\n## 5. Architecture\n\n### 5.1 Overview\n\n#### 5.1.1 Design Decisions\n\n- To provide an high level API with a simple UX and to be easy to understand.\n\n- To work in high performance environments.\n\n- To be as cross-platform as possible.\n\n- To avoid to modify run-times directly or use the code inside **METACALL** in order to avoid maintaining them, or propagating security flaws or licenses into **METACALL**.\n\n- To provide support for any embeddable programming language and to provide support for **METACALL** to be used form any programming language.\n\n- All external code used into **METACALL** must be introduced by inversion of control in the plugin system, so that the core must not remain aware from what software is using.\n\n- All code developed in **METACALL** must be implemented in standalone libraries that can work by itself in an isolated way (aka modules).\n\n#### 5.1.2 Modules\n\n- [`adt`](/source/adt) provides a base for Abstract Data Types and algorithms used in **METACALL**. Implementation must be done in an efficient and generic way. Some of the data structures implemented are vector, set, hash, comparable or trie.\n\n- [`detour`](/source/detour) provides an interface to hook into functions. Detours are used by the [fork model](#57-fork-model) to intercept fork calls.\n\n- [`detours`](/source/detours) implement the [`detour`](/source/detour) interface by using a plugin architecture. The current list of available detour plugins is the following one.\n  - [`funchook_detour`](/source/detours/funchook_detour) implemented by means of FuncHook library.\n\n- [`distributable`](/source/distributable) defines the compilation of **METACALL** that generates an unique library with all core libraries bundled into it. As the **METACALL** architecture is divided by modules, in order to distribute **METACALL** is needed to build all of them into a single library. This module implements this compilation by means of CMake.\n\n- [`dynlink`](/source/dynlink) implements a cross-platform method to dynamically load libraries. It is used to dynamically load plugins into **METACALL**.\n\n- [`environment`](/source/environment) implements an standard way to deal with environment variables. **METACALL** uses environment variables to define custom paths for plugins and scripts.\n\n- [`examples`](/source/examples) ...\n\n- [`filesystem`](/source/filesystem) provides an abstraction for operative system file system.\n\n- [`format`](/source/format) provides an standard way for printing to standard input output for old C versions that does not support newest constructions.\n\n- [`loader`](/source/loader) ...\n\n- [`loaders`](/source/loaders)\n\n- [`log`](/source/log)\n\n- [`memory`](/source/memory)\n\n- [`metacall`](/source/metacall)\n\n- [`ports`](/source/ports)\n\n- [`preprocessor`](/source/preprocessor)\n\n- [`reflect`](/source/reflect)\n\n- [`scripts`](/source/scripts)\n\n- [`serial`](/source/serial)\n\n- [`serials`](/source/serials)\n\n- [`tests`](/source/tests)\n\n- [`version`](/source/version)\n\n### 5.2 Reflect\n\nThe module that holds the representation of types, values and functions is called [`reflect`](/source/reflect) and it handles the abstraction of code loaded into **METACALL**.\n\n**METACALL** uses reflection and introspection techniques to inspect the code loaded by the [`loaders`](/source/loaders) in order to interpret it and provide an higher abstraction of it. With this higher abstraction **METACALL** can easily inter-operate between languages transparently.\n\n#### 5.2.1 Type System\n\n**METACALL** implements an abstract type system which is a binary representation of the types supported by it. This means that **METACALL** can convert any type of a language to its own type system and back. Each loader is responsible of doing this conversions.\n\n**METACALL** maintains most of the types of the languages but not all are supported. If new types are added they have to be implemented in the [`reflect`](/source/reflect) module and also in the [`loaders`](/source/loaders) and [`serials`](/source/serials) to fully support it.\n\n|  Type   | Value                                                              |\n|:-------:|--------------------------------------------------------------------|\n| Boolean | `true` or `false`                                                  |\n|  Char   | `-128` to `127`                                                    |\n|  Short  | `-32,768` to `32,767`                                              |\n|   Int   | `-2,147,483,648` to `2,147,483,647`                                |\n|  Long   | `\u20139,223,372,036,854,775,808` to `9,223,372,036,854,775,807`        |\n|  Float  | `1.2E-38` to `3.4E+38`                                             |\n| Double  | `2.3E-308` to `1.7E+308`                                           |\n| String  | NULL terminated list of characters                                 |\n| Buffer  | Blob of memory representing a binary data                          |\n|  Array  | Arrangement of values of any type                                  |\n|   Map   | List of elements formed by a key (String) value (Any) pair (Array) |\n| Pointer | Low level representation of a memory reference                     |\n|  Null   | Representation of NULL value type                                  |\n\n- Boolean is mostly represented by an integer value. There are languages that does not support it so it gets converted to a integer value in the memory layout.\n\n- Integer and Floating Point values provide a complete abstraction to numerical types. Type sizes are preserved and the correct type is used when using any number. This depends on the internal implementation of the value by the run-time. Although there can be problems related to this. A `bignum` type from Ruby may overflow if it is too big when trying to convert it to a `float` type in C#.\n\n- String is represented by ASCII encoding currently. Future versions will implement multiple encodings to be interoperable between other language encodings.\n\n- Buffer represents a blob of raw memory (i.e. an array of bytes). This can be used to represent files as images or any other resources into memory.\n\n- Array is implemented by means of array of values, which you can think it should be called _list_ instead. But as the memory layout is stored into a contiguous memory block of references to values, it is considered an array.\n\n- Map implements an associative key value pair container. A map is implemented with an array of two sized elements array. Each element of the map is an array of size two, where the first element of it is always an String and the second element is a value of any type.\n\n- Pointer is an opaque value representing a raw reference to a memory block. Some languages allow to use references to memory and some others not. This type is opaque because **METACALL** does not know what kind of concrete value represents it. The representation may be a complex type handled by the developer source code inside the run-time.\n\n- Null type implements a null value. This type has only been implemented in order to support null value from multiple run-times. It represents a null value and it does not have data size on the value allocated.\n\n#### 5.2.2 Values\n\nValues represent the instances of the **METACALL** type system.\n\nThe memory layout guarantees to fit at least the same size of the types into memory. This means if a boolean type can be represented with one bit inside a value of one byte size, maybe this value is stored in a bigger memory block and this fact is architecture and platform dependant.\n\nWhen converting values between different types, if any potential number overflow or invalid conversion between types is done, **METACALL** will warn about it. If any conversion of types can be handled by **METACALL**, it will automatically cast or transform the values into the target type automatically in order to avoid errors in the call.\n\nThe value model is implemented by means of object pool. Each value is a reference to a memory block allocated from a memory pool (which can be injected into **METACALL**). The references can be passed by value, this means **METACALL** copies the reference value instead of the data which this reference is pointing to, like most run-times do when managing their own values.\n\nEach created value must be destroyed manually. Otherwise it will lead to a memory leak. This fact only occurs when dealing with **METACALL** at C level. If **METACALL** is being used in an higher language through [`ports`](/source/ports), the developer does not have to care about memory management.\n\nThe value memory layout is described in the following form.\n\n| Memory Offset | `0` to `sizeof(data) - 1` | `sizeof(data)` to `sizeof(data) + sizeof(type_id) - 1` |\n|:-------------:|:-------------------------:|:------------------------------------------------------:|\n|  **Content**  |         **DATA**          |                      **TYPE ID**                       |\n\nThis layout is used by the following reasons.\n\n- Data is located at the first position of the memory block, so it can be used as a normal low level value. This allows to threat **METACALL** values as a normal C values. Therefore you can use **METACALL** with normal pointers to existing variables, literal values as shown in the previous examples or **METACALL** values.\n\n- Data can be accessed faster as it is located at first position of the memory block. There is not extra calculation of an offset when trying to access the pointer.\n\n- Data and type id are contiguously allocated in order to threat it as the same memory block so it can be freed with one operation.\n\n#### 5.2.3 Functions\n\nFunctions are an abstract callable representation of functions, methods or procedures loaded by [`loaders`](/source/loaders). The functions are like a template who is linked to a loader run-time and allows to do a foreign function call.\n\nA function is composed by a name and a signature. The signature defines the arguments name, type, and return type if any. When a function is loaded, **METACALL** tries to inspect the signature and records the types if any. It stores the arguments name and size and also a concrete type that will be used later by the loader to implement the call to the run-time.\n\nThe function interface must be implemented by the [`loaders`](/source/loaders) and it has the following form.\n\n``` c\ntypedef struct function_interface_type\n{\n  function_impl_interface_create create;\n  function_impl_interface_invoke invoke;\n  function_impl_interface_await await;\n  function_impl_interface_destroy destroy;\n\n} * function_interface;\n```\n\n- `create` instantiates the function concrete data related to the run-time.\n- `invoke` transforms arguments from [`reflect`](/source/reflect) abstract types to run-time concrete types, executes the call in the run-time, and converts the result of the call from run-time concrete type to [`reflect`](/source/reflect) abstract type.\n- `await` idem to invoke but awaiting the promise that is expected to be returned by the function.\n- `destroy` clears all data previously instantiated in `create`.\n\nThe type deduction can be done at different levels. For example, it is possible to guess function types from the loaded code.\n\n``` python\ndef multiply_type(a: int, b: int) -> int:\n  return a * b\n```\n\nIf this code is loaded, **METACALL** will be able to inspect the types and define the signature. Signature includes the names of the arguments, the types of those arguments if any, and the return type if any.\n\nIt may be possible that the function loaded into **METACALL** is duck typed. This means it does not have information about what types it supports and therefore they cannot be inspected statically.\n\n``` python\ndef multiply_duck(a, b):\n  return a * b\n```\n\nAt low level **METACALL** must always know the types to do the call. This types can be inferred statically or dynamically and this has implications over the call model.\n\nIn the first example, we can simply call the function without specifying the types.\n\n``` c\nmetacall(\"multiply_type\", 3, 4); // 12\n```\n\nAs the signature is already know the literal values `3` and `4` can be converted into **METACALL** values automatically. Note that in this case, as literal values are provided, if we pass a double floating point, the memory representation of the value will be corrupted as there is no possible way to detect input values and cast them to the correct target values.\n\nIn the second example, the values are not know. If we use the same API to call the function, **METACALL** will not be able to call correctly the function as its types are not know. To allow calls to duck typed functions the developer must specify the value types he is passing to the function.\n\n``` c\nconst enum metacall_value_id multiply_types[] =\n{\n  METACALL_INT, METACALL_INT\n};\n\nmetacallt(\"multiply_duck\", multiply_types, 3, 4); // 12\n```\n\nThis method allows to pass different value types to the same function. The following call would be valid too.\n\n``` c\nconst enum metacall_value_id multiply_types[] =\n{\n  METACALL_DOUBLE, METACALL_DOUBLE\n};\n\nmetacallt(\"multiply_duck\", multiply_types, 3.0, 4.0); // 12.0\n```\n\n### 5.3 Plugins\n\n**METACALL** has a plugin architecture implemented at multiple levels.\n\n- Loaders implement a layer of plugins related to the run-times.\n\n- Serials implement a layer of (de)serializers in order to transform input (arguments) or output (return value) of the calls into a generic format.\n\n- Detours is another layer of plugins focused on low level function interception (hooks).\n\nEach plugin is a piece of software that can be dynamically loaded into the **METACALL** core, used and unloaded when it is not needed anymore.\n\n#### 5.3.1 Loaders\n\nLoaders are responsible for embedding run-times into **METACALL**. Each loader has the following interface.\n\n``` c\ntypedef struct loader_impl_interface_type\n{\n  loader_impl_interface_initialize initialize;\n  loader_impl_interface_execution_path execution_path;\n  loader_impl_interface_load_from_file load_from_file;\n  loader_impl_interface_load_from_memory load_from_memory;\n  loader_impl_interface_load_from_package load_from_package;\n  loader_impl_interface_clear clear;\n  loader_impl_interface_discover discover;\n  loader_impl_interface_destroy destroy;\n\n} * loader_impl_interface;\n```\n\nA loader must implement it to be considered a valid loader.\n\n- `initialize` starts up the run-time.\n- `execution_path` defines a new import path to the run-time.\n- `load_from_file` loads a code from file into the run-time and returns a handle which represents it.\n- `load_from_memory` loads a code from memory into the run-time and returns a handle which represents it.\n- `load_from_package` loads a code from a compiled library or package into the run-time and returns a handle which represents it.\n- `clear` unloads a handle from the run-time.\n- `discover` inspects a handle previously loaded.\n- `destroy` shutdowns the run-time.\n\n##### 5.3.1.1 Python\n\n##### 5.3.1.2 NodeJS\n\n##### 5.3.1.3 JavaScript\n\n##### 5.3.1.4 C# #\n\n##### 5.3.1.5 Ruby\n\n##### 5.3.1.6 Mock\n\n##### 5.3.1.7 File\n\n#### 5.3.2 Serials\n\n##### 5.3.2.1 MetaCall\n\n##### 5.3.2.2 RapidJSON\n\n#### 5.3.3 Detours\n\n##### 5.3.3.1 FuncHook\n\n### 5.4 Ports\n\n### 5.5 Serialization\n\n### 5.6 Memory Layout\n\n### 5.7 Fork Model\n\n**METACALL** implements a fork safe model. This means if **METACALL** is running in any program instance, the process where is running can be forked safely at any moment of the execution. This fact has many implications at design, implementation and use level. But the whole **METACALL** architecture tries to remove all responsibility from the developer and make this transparent.\n\nTo understand the **METACALL** fork model, first of all we have to understand the implications of the forking model in operative systems and the difference between [fork-one and fork-all models](https://docs.oracle.com/cd/E37838_01/html/E61057/gen-1.html).\n\nThe main difference between fork-one and fork-all is that in fork-one only the thread which called the fork is preserved after the fork (i.e. gets cloned). In fork-all model, all threads are preserved after cloning. POSIX uses fork-one model, meanwhile Oracle Solaris use the fork-all model.\n\nBecause of fork-one model, forking a running run-time like NodeJS (which has a thread pool) implies that in the child process the thread pool will be almost dead except the thread which did the fork call. So NodeJS run-time cannot continue the execution anymore and the event-loop enters into a deadlock state.\n\nWhen a fork is done, the status of the execution is lost by the moment. **METACALL** is not able to preserve the state when a fork is done. Some run-times do not allow to preserve the internal state. For example, the bad design<sup>[[0]](https://github.com/nodejs/node/issues/23265)[[1]](https://github.com/nodejs/node/issues/23265#issuecomment-452690239)[[2]](https://github.com/nodejs/node/issues/23265#issuecomment-496873739)[[3]](https://github.com/nodejs/node/issues/23265#issuecomment-496878712)[[4]](https://github.com/nodejs/node/issues/23265#issuecomment-496910654)[[5]](https://github.com/nodejs/node/issues/23265#issuecomment-496918901)</sup> of NodeJS does not allow to manage the thread pool from outside, so it cannot be preserved after a fork.\n\nBecause of these restrictions, **METACALL** cannot preserve the status of the run-times. In the future this model will be improved to maintain consistency and preserve the execution state of the run-times making **METACALL** more robust.\n\nAlthough the state is not preserved, fork safety is. The mechanism **METACALL** uses to allow fork safety is described in the following enumeration.\n\n1) Intercept fork call done by the program where **METACALL** is running.\n\n2) Shutdown all run-times by means of unloading all loaders.\n\n3) Execute the real fork function.\n\n4) Restore all run-times by means of reloading all loaders.\n\n5) Execute user defined fork callback if any.\n\nTo achieve this, **METACALL** hooks fork primitives depending on the platform.\n\n- `fork` on POSIX systems.\n- `RtlCloneUserProcess` on Windows systems.\n\nIf you use `clone` instead of `fork` to spawn a new process in a POSIX system, **METACALL** won't catch it.\n\nWhenever you call a to a cloning primitive **METACALL** intercepts it by means of [**`detour`**](/source/detour). Detours is a way to intercept functions at low level by editing the memory and introducing a jump over your own function preserving the address of the old one. **METACALL** uses this method instead of POSIX `pthread_atfork` for three main reasons.\n\n- The first one is that `pthread_atfork` is only supported by POSIX systems. So it is not a good solution because of the philosophy of **METACALL** is to be as cross-platform as possible.\n\n- The second is that `pthread_atfork` has a [bug in the design of the standard](https://stackoverflow.com/a/6605487). It was designed to solve a problem which cannot be solved with `pthread_atfork` itself. This means that even having the control of NodeJS thread pool, it will not be possible to restore the [mutexes](https://github.com/nodejs/node/blob/v8.x/src/node_platform.cc) in the child process. The only possibility is to re-implement the thread pool of NodeJS with async safe primitives like a semaphore. Async safe primitives will be able to work in the child process handler. But this is not possible as it enters in conflict with the design decision of to not modify the run-times.\n\n- The third one is that the mechanism of `pthread_atfork` also [will be deprecated](http://pubs.opengroup.org/onlinepubs/9699919799/functions/pthread_atfork.html) because of second reason.\n  > The `pthread_atfork()` function may be formally deprecated (for example, by shading it OB) in a future version of this standard.\n\nDetours model is not safe. It is platform dependant and implies that the program modifies the memory of itself during the execution which is not safe at all and can induce bugs or security flaws if it is not done correctly. But because of limitations of run-times, there is not another alternative to solve the problem of fork safety.\n\nUsually the developer is the same who does the fork, but it may be possible that **METACALL** is embedded into a larger application and the developer is in the middle between the application code and **METACALL** so it is impossible to control when a fork is done. Because of this the developer can register a callback by means of [**`metacall_fork`**](/source/metacall/include/metacall/metacall_fork.h) to know when a fork is executed to do the actions needed after the fork, for example, re-loading all previous code and restore the state of the run-times. This gives a partial solution to the problem of losing the state when doing a fork.\n\n### 5.8 Threading Model\n\n## 5. Application Programming Interface (API)\n\n## 6. Build System\n\nFollow these steps to build and install **METACALL** manually.\n\n``` sh\ngit clone --recursive https://github.com/metacall/core.git\nmkdir core/build && cd core/build\ncmake ..\nmake\nmake test\nsudo make install\n```\n\n### 6.1 Build Options\n\nThese options can be set using **`-D`** prefix when configuring CMake. For example, the following configuration enables the build of Python and Ruby loaders.\n\n``` sh\ncmake -DOPTION_BUILD_LOADERS_PY=On -DOPTION_BUILD_LOADERS_RB=On ..\n```\n\nAvailable build options are the following ones.\n\n|        Build Option         | Description                                            | Default Value |\n|:---------------------------:|--------------------------------------------------------|:-------------:|\n|    **BUILD_SHARED_LIBS**    | Build shared instead of static libraries.              |      ON       |\n| **OPTION_BUILD_DIST_LIBS**  | Build all libraries into a single compilation unit.    |      ON       |\n|  **OPTION_SELF_CONTAINED**  | Create a self-contained install with all dependencies. |      OFF      |\n|   **OPTION_BUILD_TESTS**    | Build tests.                                           |      ON       |\n| **OPTION_BUILD_BENCHMARKS** | Build benchmarks.                                      |      OFF      |\n|    **OPTION_BUILD_DOCS**    | Build documentation.                                   |      OFF      |\n|  **OPTION_BUILD_EXAMPLES**  | Build examples.                                        |      ON       |\n|  **OPTION_BUILD_LOADERS**   | Build loaders.                                         |      ON       |\n|  **OPTION_BUILD_SCRIPTS**   | Build scripts.                                         |      ON       |\n|  **OPTION_BUILD_SERIALS**   | Build serials.                                         |      ON       |\n|  **OPTION_BUILD_DETOURS**   | Build detours.                                         |      ON       |\n|   **OPTION_BUILD_PORTS**    | Build ports.                                           |      OFF      |\n|    **OPTION_FORK_SAFE**     | Enable fork safety.                                    |      OFF      |\n|   **OPTION_THREAD_SAFE**    | Enable thread safety.                                  |      OFF      |\n|     **OPTION_COVERAGE**     | Enable coverage.                                       |      OFF      |\n|    **CMAKE_BUILD_TYPE**     | Define the type of build.                              |    Release    |\n\nIt is possible to enable or disable concrete loaders, script, ports, serials or detours. For building use the following options.\n\n|    Build Option Prefix    | Build Option Suffix                                                   |\n|:-------------------------:|-----------------------------------------------------------------------|\n| **OPTION_BUILD_LOADERS_** | `C` `JS` `CS` `MOCK` `PY` `JSM` `NODE` `RB` `JSM` `FILE`              |\n| **OPTION_BUILD_SCRIPTS_** | `C` `CS` `JS` `NODE` `PY` `RB` `JAVA`                                 |\n| **OPTION_BUILD_SERIALS_** | `METACALL` `RAPID_JSON`                                               |\n| **OPTION_BUILD_DETOURS_** | `FUNCHOOK`                                                            |\n|  **OPTION_BUILD_PORTS_**  | `CS` `CXX` `D` `GO` `JAVA` `JS` `LUA` `NODE` `PHP` `PL` `PY` `R` `RB` |\n\n### 6.2 Coverage\n\nIn order to run code coverage and obtain html reports use the following commands. Note, test must be run before executing code coverage.\n\n``` sh\nmake\nmake test\nmake -k gcov\nmake -k lcov\nmake -k lcov-genhtml\n```\n\nThe output reports will be generated in `${CMAKE_BINARY_DIR}/lcov/html/selected_targets` in html format.\n\nTo obtain a report of a single `target` do:\n\n``` sh\nmake\nmake test\nmake <target>-gcov\nmake <target>-geninfo\nmake <target>-genhtml\n```\n\n## 7. Platform Support\n\nThe following platforms and architectures have been tested an work correctly with all plugins of **METACALL**.\n\n|     Operative System      |    Architecture     |    Compiler     |                                              Build Status                                              |\n|:-------------------------:|:-------------------:|:---------------:|:------------------------------------------------------------------------------------------------------:|\n|    **`ubuntu:xenial`**    |     **`amd64`**     |    **`gcc`**    |                                                                                                        |\n| **`debian:stretch-slim`** |     **`amd64`**     | **`gcc:6.3.0`** | [![build](https://gitlab.com/metacall/core/badges/master/build.svg)](https://gitlab.com/metacall/core) |\n| **`debian:buster-slim`**  |     **`amd64`**     | **`gcc:8.2.0`** |                                                                                                        |\n|       **`windows`**       | **`x86`** **`x64`** |   **`msvc`**    |                                                                                                        |\n\n### 7.1 Docker Support\n\nTo provide a reproducible environment **METACALL** is also distributed under Docker on [DockerHub](https://hub.docker.com/r/metacall/core). Current images are based on `debian:stretch-slim` for `amd64` architecture.\n\nFor pulling the **METACALL** `latest` image containing the runtime, use:\n\n``` sh\ndocker pull metacall/core\n```\n\nFor pulling a specific image depending on the tag, use:\n\n- **METACALL** `deps` image. Includes all dependencies for development:\n\n``` sh\ndocker pull metacall/core:deps\n```\n\n- **METACALL** `dev` image. Includes all dependencies, headers and libraries for development:\n\n``` sh\ndocker pull metacall/core:dev\n```\n\n- **METACALL** `runtime` image. Includes all dependencies and libraries for runtime:\n\n``` sh\ndocker pull metacall/core:runtime\n```\n\n- **METACALL** `cli` image. Includes all dependencies and libraries for runtime and the CLI as entry point (equivalent to `latest`):\n\n``` sh\ndocker pull metacall/core:cli\n```\n\n### 7.1.1 Docker Development\n\nIt is possible to develop **METACALL** itself or applications using **METACALL** as standalone library with Docker. The `dev` image can be used for development. It contains all dependencies with all run-times installed with the code, allowing debugging too.\n\nUse the following commands to start developing with **METACALL**:\n\n``` sh\nmkdir -p $HOME/metacall\ncode $HOME/metacall\n```\n\nWe are going to run a docker container with a mounted volume. This volume will connect the `LOADER_SCRIPT_PATH` inside the container, and your development path in the host. We are using `$HOME/metacall`, where we have our editor opened.\n\n``` sh\ndocker pull metacall/core:dev\ndocker run -e LOADER_SCRIPT_PATH=/metacall -v $HOME/metacall:/metacall -w /metacall -it metacall/core:dev /bin/bash\n```\n\nInside docker terminal you can run `python` or `ruby` command to test what you are developing. You can also run `metacallcli` to test (load, clear, inspect and call).\n\n### 7.1.2 Docker Testing\n\nAn alternative for testing is to use a reduced image that includes the runtime and also the CLI. This alternative allows fast prototyping and CLI management in order to test and inspect your own scripts.\n\nUse the following commands to start testing with **METACALL**:\n\n``` sh\nmkdir -p $HOME/metacall\ncode $HOME/metacall\n```\n\nWe are going to run a docker container with a mounted volume. This volume will connect the `LOADER_SCRIPT_PATH` inside the container, and your development path in the host. We are using `$HOME/metacall`, where we have our editor opened.\n\n``` sh\ndocker pull metacall/core:cli\ndocker run -e LOADER_SCRIPT_PATH=/metacall -v $HOME/metacall:/metacall -w /metacall -it metacall/core:cli\n```\n\nAfter the container is up, it is possible to load any script contained in host folder `$HOME/metacall`. If we have a `script.js` inside the folder, we can just load it (each line beginning with `>` is the input command):\n\n`script.js`\n``` js\nfunction sum(left, right) {\n    return left + right;\n}\n\nmodule.exports = {\n    sum\n};\n```\n\n`Command Line Interface`\n``` sh\n> load node script.js\nScript (script.js) loaded correctly\n> inspect\nruntime node {\n    module script {\n        function sum(left, right)\n    }\n}\nruntime __metacall_host__\n> call sum(3, 5)\n8.0\n> exit\n```\n\nWhere `script.js` is a script contained in host folder `$HOME/metacall` that will be loaded on the CLI after starting up the container. Type `help` to see all available CLI commands.\n\n## 8. License\n\n**METACALL** is licensed under **[Apache License Version 2.0](/LICENSE)**.\n\n>Copyright (C) 2016 - 2019 Vicente Eduardo Ferrer Garcia <<vic798@gmail.com>>\n>\n>Licensed under the Apache License, Version 2.0 (the \"License\");\n>you may not use this file except in compliance with the License.\n>You may obtain a copy of the License at\n>\n>       http://www.apache.org/licenses/LICENSE-2.0\n>\n>Unless required by applicable law or agreed to in writing, software\n>distributed under the License is distributed on an \"AS IS\" BASIS,\n>WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n>See the License for the specific language governing permissions and\n>limitations under the License.\n"}, {"repo": "/JuliaDatabases/ODBC.jl", "language": "C", "readme_contents": "\n# ODBC\n\n*A Julia library for interacting with the ODBC API*\n\n| **Documentation**                                                               | **PackageEvaluator**                                            | **Build Status**                                                                                |\n|:-------------------------------------------------------------------------------:|:---------------------------------------------------------------:|:-----------------------------------------------------------------------------------------------:|\n| [![][docs-stable-img]][docs-stable-url] [![][docs-latest-img]][docs-latest-url] | [![][pkg-0.5-img]][pkg-0.5-url] | [![][travis-img]][travis-url] [![][appveyor-img]][appveyor-url] [![][codecov-img]][codecov-url] |\n\n\n## Installation\n\nThe package is registered in `METADATA.jl` and so can be installed with `Pkg.add`.\n\n```julia\njulia> Pkg.add(\"ODBC\")\n```\n\n## Documentation\n\n- [**STABLE**][docs-stable-url] &mdash; **most recently tagged version of the documentation.**\n- [**LATEST**][docs-latest-url] &mdash; *in-development version of the documentation.*\n\n## Project Status\n\nThe package is tested against Julia `1.0` on Linux, OSX, and Windows.\n\n## Contributing and Questions\n\nContributions are very welcome, as are feature requests and suggestions. Please open an\n[issue][issues-url] if you encounter any problems or would just like to ask a question.\n\n\n\n[docs-latest-img]: https://img.shields.io/badge/docs-latest-blue.svg\n[docs-latest-url]: http://juliadatabases.github.io/ODBC.jl/latest\n\n[docs-stable-img]: https://img.shields.io/badge/docs-stable-blue.svg\n[docs-stable-url]: http://juliadatabases.github.io/ODBC.jl/stable\n\n[travis-img]: https://travis-ci.org/JuliaDatabases/ODBC.jl.svg?branch=master\n[travis-url]: https://travis-ci.org/JuliaDatabases/ODBC.jl\n\n[appveyor-img]: https://ci.appveyor.com/api/projects/status/h227adt6ovd1u3sx/branch/master?svg=true\n[appveyor-url]: https://ci.appveyor.com/project/JuliaDatabases/documenter-jl/branch/master\n\n[codecov-img]: https://codecov.io/gh/JuliaDatabases/ODBC.jl/branch/master/graph/badge.svg\n[codecov-url]: https://codecov.io/gh/JuliaDatabases/ODBC.jl\n\n[issues-url]: https://github.com/JuliaDatabases/ODBC.jl/issues\n\n[pkg-0.5-img]: http://pkg.julialang.org/badges/ODBC_0.5.svg\n[pkg-0.5-url]: http://pkg.julialang.org/?pkg=ODBC\n"}, {"repo": "/jtoy/cld", "language": "C++", "readme_contents": "# Compact Language Detection\n\nBlazing-fast language detection for Ruby provided by\nGoogle Chrome's Compact Language Detector.\n\n## How to Use\n\n```ruby\nCLD.detect_language(\"This is a test\")\n# => {:name => \"ENGLISH\", :code => \"en\", :reliable => true}\n\nCLD.detect_language(\"plus \u00e7a change, plus c'est la m\u00eame chose\")\n# => {:name => \"FRENCH\", :code => \"fr\", :reliable => true}\n```\n\n## Installation\n\nAdd this line to your application's Gemfile:\n\n```ruby\ngem \"cld\"\n```\n\nAnd then execute:\n\n```sh\n$ bundle\n```\n\n## Thanks\n\nThanks to the Chrome authors, and to Mike McCandless for writing a Python version.\n\nLicensed the same as Chrome.  Jason Toy"}, {"repo": "/NVIDIA/MDL-SDK", "language": "C++", "readme_contents": "# NVIDIA MDL SDK\n\nThe NVIDIA MDL SDK enables the easy integration of MDL support into\nrendering and material editing applications. The SDK contains components\nfor loading, inspecting, and editing of material definitions as well as\ncompiling MDL materials and functions to PTX and LLVM-IR.\n\n\n## NVIDIA Material Definition Language (MDL)\n\n![MDL example material renderings](doc/images/mdl_material_examples.jpg)\n\nThe [NVIDIA Material Definition Language (MDL)](https://www.nvidia.com/mdl) \nis a domain-specific programming language for defining physically-based \nmaterials for rendering. It allows you to define  *materials* and *functions*,\nwhich you can organize in *modules* and *packages* to create flexible, \ncustom-built material catalogs.\n\nMaterial definitions are written in a declarative style; they define\nwhat to compute -- not how to compute it. This is the central premise in \nMDL where one material definition delivers the same appearance in many\nrendering algorithms. Following is a simple example of a diffuse material \nin MDL:\n\n    material diffuse ( color diffuse_color = color(0.7))\n        = material(\n            surface: material_surface (\n                scattering: df::diffuse_reflection_bsdf (\n                    tint: diffuse_color\n                )\n            )\n        );\n\nThe function definitions in MDL are written in a procedural programming\nstyle. Their use is limited to computing material parameters in a \nside-effect-free manner.\n\nThe clear separation of material definitions from function definitions and \ntheir respective constraints makes possible the optimization of rendering \nalgorithms independently of the material definition.\n\n\n## Pre-compiled Binaries\n\nNVIDIA offers a binary release of the MDL SDK, see \n[https://developer.nvidia.com/mdl-sdk](https://developer.nvidia.com/mdl-sdk). \nThe binary release is different in some functionality as documented in the \n[Change Log](CHANGELOG.md).\n\n\n## Support\n\n- [NVIDIA MDL SDK Forum](https://devtalk.nvidia.com/default/board/253/mdl-sdk/)\n\n\n## Building the MDL SDK from Source\n\nMDL uses [CMake](http://www.cmake.org/) to generate build files for a \nparticular development environment. It is suggested to use CMake 3.11 or later, \nwhich can be downloaded from the [CMake Website](https://cmake.org/download/).\nWhen using a Unix-like system, you can install the *cmake* package using \nthe respective package management systems. On the Mac OS X platform, third party\ndependencies can be resolved using the [Homebrew Package Manager](https://brew.sh/index_de).\n\n\n### Dependencies\n\nThe source code requires a C++11 compiler and several third-party libraries \nand tools to build the MDL SDK. Additional third-party libraries are used in \nthe examples.\n\nThe build with the following x64-platform-compiler combinations has been \nsuccessfully tested:\n\n-   **Windows 10:**     Microsoft Visual Studio 2015 (msvc v140)\n-   **Ubuntu 18.04:**   gcc/g++6 and gcc/g++7\n-   **Mac OS X 10.13:** Xcode 8.3.3 (Apple Clang 8.1)\n\nThe versions listed with the following dependencies have been\nsuccessfully tested. Where not mentioned otherwise, other versions\nmight work as well.\n\n<a name=\"thirdparty-dependencies-libs\"></a>\nThe following third-party libraries are required to build the MDL SDK:\n\n-   **Boost** *(1.67.0)* (headers)  \n    Linux: Install the *libboost-dev* package.  \n    Windows: Download and extract the boost source code from \n    [boost.org](https://www.boost.org/users/download/).  \n    Mac OS X: Install the *boost* package using brew.\n\n-   **FreeImage** *(3.17.0)*  \n    Linux: Install the *libfreeimage-dev* package.  \n    Windows: Download and extract the pre-compiled binaries from \n    [freeimage.sourceforge.net](http://freeimage.sourceforge.net/download.html).  \n    Mac OS X: Install the *freeimage* package using brew.\n\n-   **Python2** *(2.7.1)*  \n    Linux: Install the *python* package.  \n    Windows and Max OS X: Download and install Python 2.7 from \n    [python.org](https://www.python.org/downloads/).\n\n-   **Clang 3.4.1**  \n    Using version 3.4.1 is mandatory.  \n    Pre-compiled binaries can be found on \n    [llvm.org](http://releases.llvm.org/download.html#3.4.1).\n\nIn order to build and run all examples, you need additional third-party \nlibraries. These additional libraries are:\n\n-   **GLEW** *(2.1.0)*  \n    Linux: Install the *libglew-dev* package.  \n    Windows: Download and extract the pre-compiled binaries from \n    [glew.sourceforge.net](http://glew.sourceforge.net/).  \n    Mac OS X: Install the *glew* package using brew.\n\n-   **GLFW** *(3.2.1)*  \n    Linux: Install the *libglfw3-dev* package.  \n    Windows: Download and extract the pre-compiled x64 binaries from \n    [glfw.org](http://www.glfw.org/download.html).  \n    Mac OS X: Install the *glfw* package using brew.\n\n-   **NVIDIA CUDA Toolkit** *(9.0 or later)*  \n    Please follow the instructions on the \n    [CUDA Developer Website](https://developer.nvidia.com/cuda-toolkit).\n\n-   **Qt** *(5.10.1)*  \n    Please follow the instructions on the [Qt Website](https://www.qt.io/)  \n    To build with Qt 5.10.1 on Linux, your system's GLIBC needs to be release \n    2.14 or later.\n\n-   **DirectX Raytracing support**\n    To build the DXR example, Windows 10 version 1809 and the corresponding \n    SDK 10.0.17763.0 as well as the optional *Graphic Tools* feature are required.\n\n<a name=\"doc-build-tools\"></a>\nRequired tools to build the documentation:\n\n-   **Doxygen** *(1.8.4)*  \n    See the [Doxygen project page](http://www.stack.nl/~dimitri/doxygen/) and \n    the [ftp archive of all releases](ftp://ftp.stack.nl/pub/users/dimitri/).\n\n-   **dot from GraphViz** *(2.40.1)* (optional)  \n    See the [GraphViz project page](https://www.graphviz.org/).\n\n\n### Building on Windows\n\n1.  Before generating the Visual Studio 2015 solution, be sure to\n    download and extract or install the third-party libraries listed\n    above.  The following steps assume you have extracted the pre-compiled \n    binaries to a common third-party directory that is:\n\n        C:/projects/thirdparty\n\n2.  Open CMake-Gui, click `Browse Source...` and select the root\n    directory of the MDL SDK source checkout. This directory contains\n    the top-level *CMakeLists.txt*.  Pick a build directory that will \n    contain the files for your build system and eventually, the compiled \n    binaries.\n\n    It is recommended that you build into a subdirectory, not into the repository root.\n    *C:/projects/mdl-sdk/build/vs2015* for example is fine, assuming you cloned the repository to:\n\n        C:/projects/mdl-sdk\n\n3.  After clicking ``Configure``, CMake asks you to choose the\n    Generator. Select `Visual Studio 14 2015 Win64` (for newer CMake versions\n    select `x64` as platform), enter `host=x64` as toolset and click\n    `Finish`.  CMake starts to configure the build and stops several\n    times when user input is required to resolve dependencies.\n\n4.  Optionally, you can select or deselect \n    [Additional CMake Options](#additional-cmake-options) by checking and \n    un-checking the boxes next to the entries that start with *MDL*. Click\n    ``Configure`` again to continue.\n\n5.  When red error messages appear in the log, identify the dependency path \n    that is requested and resolve the error by specifying the corresponding \n    entry in CMake-Gui. Then, click ``Configure`` again to continue. Repeat \n    this step until no further errors occur.\n\n    <a name=\"thirdparty-dependencies-options\"></a>\n    During this process, you will need to setup the following entries:\n\n    -   **BOOST_INCLUDEDIR** in Ungrouped Entries,  \n        for example: *C:/projects/thirdparty/boost_1_67_0*, which contains the *boost* directory.  \n\n    -   **FREEIMAGE_DIR** in the FREEIMAGE group,  \n        for example: *C:/projects/thirdparty/freeimage_3_17_0/Dist/x64*\n\n    -   **GLEW_DIR** in the GLEW group,  \n        for example: *C:/projects/thirdparty/glew-2.1.0*\n\n    -   **GLFW_DIR** in Ungrouped Entries,  \n        for example: *C:/projects/thirdparty/glfw-3.2.1.bin.WIN64*\n\n    -   **clang_PATH** in Ungrouped Entries (only if not found in the PATH),  \n        for example: *C:/projects/thirdparty/LLVM-3.4.1-win32/bin/clang.exe*\n\n    -   **python_PATH** in Ungrouped Entries (only of not found in the PATH),  \n        for example: *C:/projects/thirdparty/python_2_7_1/bin/python.exe*\n\n    -   **Qt5_DIR** in Ungrouped Entries,  \n        for example: *C:/Qt/5.10.1/msvc2015_64*\n\n    Note: when you installed a new Visual Studio version after installing CUDA,\n    you may have to reinstall CUDA to register it correctly with Visual Studio.\n    Otherwise, CMake won't find the CUDA compiler.\n\n6.  When all dependencies have been resolved or the corresponding examples \n    have been disabled as indicated in the CMake error messages, the log \n    will show that the configuration is done.\n\n    Generate the Visual Studio solution by clicking ``Generate`` and open it \n    afterwards using ``Open Project``. CMake-Gui is not needed anymore and\n    can be closed.\n\n    You can also open the Visual Studio solution directly from the build \n    directory.\n\n7.  For Visual Studio 2015, you may have to adapt the `Target Platform Version` under\n    `General` in the `dxr` project properties to `10.0.17763.0` to avoid getting\n    build errors. For newer Visual Studio versions, CMake will use the correct\n    platform version.\n\n8.  Use Visual Studio to build the MDL SDK library, the MDL Core library,\n    and the examples. When running the examples using the Visual Studio debugger,\n    you can provide additional command line arguments by specifying them in the\n    individual Visual Studio project settings.\n\n    You can find the example binaries in the corresponding subfolders in *build/examples*.\n    To run the examples by double-clicking the executable in the build directories\n    or by using the command line, you need to add the location of the built libraries and\n    plugins to your environment PATH or copy them into the corresponding example \n    binary folder.\n\n    For the *mdl_sdk* examples, you need *libmdl_sdk.dll* from\n    *build/src/prod/lib/mdl_sdk* and additionally,\n    *freeimage.dll* and *nv_freeimage.dll* from\n    *build/src/shaders/plugin/freeimage*.\n\n    For the *mdl_core* examples, you need *libmdl_core.dll* from\n    *build/src/prod/lib/mdl_core* and the *freeimage.dll* from \n    *build/src/shaders/plugin/freeimage* or your third-party downloads.\n\n\n### Building on Linux\n\n1.  Before generating make files, you need to install the required\n    tools and libraries as listed [above](#thirdparty-dependencies-libs).\n\n    Building on Linux requires a developer environment including Python and \n    CMake, which can be installed using the package manager (first command \n    below). The second command will install the third-party libraries that \n    are available in the package management system:\n\n    ```bash\n    sudo apt-get install git build-essential python cmake g++-multilib\n    sudo apt-get install libboost-dev libfreeimage-dev libglew-dev libglfw3-dev\n    ```\n\n    Please note that the build also requires clang 3.4.1, which is no\n    longer available through the package manager. Please download the\n    binary as described [above](#thirdparty-dependencies-libs). In\n    the following, it is assumed that the extracted clang is the only\n    clang compiler found in the system path or, for step 3.ii, that it\n    has been extracted to:\n\n        ~/projects/thirdparty/clang+llvm-3.4.1-x86_64-unknown-ubuntu12.04/bin/clang\n    \n2.  It is assumed that you checked out the repository in your home directory \n    as follows:\n\n    ```bash\n    git clone https://github.com/NVIDIA/MDL-SDK.git ~/projects/mdl-sdk\n    ```\n\n    Before running CMake, create a build directory that will contain \n    your make files and switch to that directory. It is recommended \n    that you build into a subdirectory, not the repository root: \n\n    ```bash\n    mkdir -p ~/projects/mdl-sdk/build/linux-x64-gcc7\n    cd ~/projects/mdl-sdk/build/linux-x64-gcc7\n    ```\n\n3.  To generate your build files, run CMake with the path to the top-level \n    *CMakeLists.txt* as the last argument.\n\n    1.  When all dependencies are installed correctly, the default settings \n        should complete the configuration without any further user \n        interactions:\n\n        ```bash\n        cmake ../../\n        ```\n\n        In this case, you can continue with Step 4.\n\n    2.  Optionally, you can use CMake options and the *-D* flags to customize \n        your build.\n\n        One or multiple of these flags can be used to enable and disable examples and logging (see \n        [Additional CMake Options](#additional-cmake-options)), for example:\n\n        ```bash\n        cmake -DMDL_BUILD_SDK_EXAMPLES=OFF -DMDL_BUILD_CORE_EXAMPLES=OFF ../../\n        ```\n\n        You can also use the flags to point CMake to custom installation \n        directories for third-party libraries. Please refer to \n        [Windows build](#thirdparty-dependencies-options) for a list of \n        supported flags. On Unix-like systems, it is assumed that the \n        specified paths contain a directory named *include* for headers \n        files and subdirectories named `lib64` or `lib` that contain shared \n        libraries. For a custom build of the GLEW library for example, the \n        call to CMake could look as follows:\n\n        ```bash\n        cmake -DGLEW_DIR=~/thirdparty/glew-2.1.0 ../../\n        ```\n\n        When a more recent clang compiler is installed on your system, you \n        can provide the path to a clang 3.4.1 by setting the 'clang_Path' \n        option:\n\n        ```bash\n        cmake -Dclang_PATH=~/projects/thirdparty/clang+llvm-3.4.1-x86_64-unknown-ubuntu12.04/bin/clang ../../\n        ```\n        \n        The same applies to other dependencies like Python 2.7.\n\n        For builds using a different compiler version, you need to pass the \n        compiler names when calling CMake as follows:\n\n        ```bash\n        sudo apt-get install gcc-6 g++-6 g++-6-multilib\n        cmake -DCMAKE_C_COMPILER=/usr/bin/gcc-6 -DCMAKE_CXX_COMPILER=/usr/bin/g++-6 ../../\n        ```\n        \n        To create an optimized build on a Unix-like system, set the build type to *Release*:\n\n        ```bash\n        cmake -DCMAKE_BUILD_TYPE=Release ../../\n        ```\n\n    3.  In case CMake is not able to find a working CUDA compiler for the \n        examples, make sure the *nvcc* is reachable through the system PATH \n        variable before running CMake:\n\n        ```bash\n        export PATH=<CUDA_SDK_DIR>/bin:$PATH\n        ```\n\n    4.  If Qt5 cannot be found, or you want to use an extracted package \n        rather than installing Qt on your system, you can optionally set \n        an additional environment variable before calling CMake:\n\n        ```bash\n        export Qt5_DIR=~/Qt/5.10.1/gcc_64\n        ```\n\n        or pass the Qt5_DIR as CMake option:\n\n        ```bash\n        cmake -DQt5_DIR=~/Qt/5.10.1/gcc_64 ../../\n        ```\n\n4.  After a successful configuration, you can run make from within the\n    specified build directory or any subdirectory that corresponds to a\n    source directory containing a *CMakeLists.txt*:\n\n    ```bash\n    make -j8\n    ```\n\n5.  Because the different MDL SDK libraries are loaded at runtime, their \n    location has to be provided in order to run an example. Therefore, \n    specify the paths to the built MDL SDK library, MDL Core library, and \n    the image plugins using the `LD_LIBRARAY_PATH` variable:\n\n    ```bash\n    export LD_LIBRARY_PATH=~/projects/mdl-sdk/build/linux-x64-gcc7/src/prod/lib/mdl_sdk:~/projects/mdl-sdk/build/linux-x64-gcc7/src/prod/lib/mdl_core:~/projects/mdl-sdk/build/linux-x64-gcc7/src/shaders/plugin/freeimage${LD_LIBRARAY_PATH:+:${LD_LIBRARAY_PATH}}\n    ```\n\n    For example, to run the MDL SDK modules example, use:\n\n    ```bash\n    cd ~/projects/mdl-sdk/build/linux-x64-gcc7/examples/mdl_sdk/modules\n    ./mdl_sdk_example-modules\n    ```\n\n### Building on Mac OS X\n\n1.  Before generating make files, you need to install the required\n    tools and libraries as listed [above](#thirdparty-dependencies-libs).\n\n    Please note that the build requires clang 3.4.1, which is no\n    longer available through the package manager. Please download the\n    binary as described [above](#thirdparty-dependencies-libs). In\n    the following, it is assumed that it has been extracted to:\n\n        ~/projects/thirdparty/clang+llvm-3.4.1-x86_64-apple-darwin10.9/bin/clang\n\n2.  Depending on your workflow, you can use CMake-Gui and follow the [Windows instructions](#building-on-windows) \n    or use the command line as described in the [Linux section](#building-on-linux).\n    In each case, begin with step 2 of the respective instructions.\n\n    If the brew packages, Python 2.7, CUDA, and Qt have been installed correctly,\n    the following CMake options need to be specified:\n\n    -   **clang_PATH** in Ungrouped Entries,  \n        for example: *~/projects/thirdparty/clang+llvm-3.4.1-x86_64-apple-darwin10.9/bin/clang*\n\n    -   **python_PATH** in Ungrouped Entries (only of not found in the PATH),  \n        for example: */usr/bin/python*\n\n    -   **Qt5_DIR** in Ungrouped Entries,  \n        for example: *~/Qt/5.10.1/clang_64*\n\n\n3.  After successfully configuring and generating make files, switch to the selected build directory and run make:\n\n    ```bash\n    cd ~/projects/mdl-sdk/build/macosx-x64-clang810\n    make -j8\n    ```\n\n4.  Because the different MDL SDK libraries are loaded at runtime, their \n    location has to be provided in order to run an example. Therefore, \n    specify the paths to the built MDL SDK library, MDL Core library, and \n    the image plugins using the `DYLD_LIBRARAY_PATH` variable:\n\n    ```bash\n    export Qt5_DIR=~/Qt/5.10.1/clang_64\n    export DYLD_LIBRARAY_PATH=~/projects/mdl-sdk/build/macosx-x64-clang810/src/prod/lib/mdl_sdk:~/projects/mdl-sdk/build/macosx-x64-clang810/src/prod/lib/mdl_core:~/projects/mdl-sdk/build/macosx-x64-clang810/src/shaders/plugin/freeimage:${Qt5_DIR}/lib:${Qt5_DIR}/plugins/imageformats${DYLD_LIBRARAY_PATH:+:${DYLD_LIBRARAY_PATH}}\n    ```\n\n    For example, to run the MDL SDK modules example, use:\n\n    ```bash\n    cd ~/projects/mdl-sdk/build/macosx-x64-clang810/examples/mdl_sdk/modules\n    ./mdl_sdk_example-modules\n    ```\n\n### Additional CMake Options\n\nThe following options enable you to select the components to be built and to \nselect particular logging information:\n\n-   **MDL_BUILD_SDK_EXAMPLES**  \n    [ON/OFF] enable/disable the MDL SDK examples.\n\n-   **MDL_BUILD_CORE_EXAMPLES**  \n    [ON/OFF] enable/disable the MDL Core examples.\n\n-   **MDL_ENABLE_CUDA_EXAMPLES**  \n    [ON/OFF] enable/disable examples that require CUDA.\n\n-   **MDL_ENABLE_D3D12_EXAMPLES**  \n    [ON/OFF] enable/disable examples that require D3D12 (Windows only).\n\n-   **MDL_ENABLE_OPENGL_EXAMPLES**  \n    [ON/OFF] enable/disable examples that require OpenGL.\n\n-   **MDL_ENABLE_QT_EXAMPLES**  \n    [ON/OFF] enable/disable examples that require Qt.\n\n-   **MDL_LOG_PLATFORM_INFOS**  \n    [ON/OFF] enable/disable the logging of platform and CMake settings.\n\n-   **MDL_LOG_DEPENDENCIES**  \n    [ON/OFF] enable/disable the logging of dependencies of the individual targets.\n\n-   **MDL_LOG_FILE_DEPENDENCIES**  \n    [ON/OFF] enable/disable the logging of files that are copied to the output folder.\n\nBy default, all options are set to ON. For any help request, please attach \nthe log messages generated when the log options are enabled.\n\n\n### Testing the Build\n\nTo verify the build, run the examples as described above.\n\n\n### Building the API Documentation\n\nThe documentation is stored in the `doc/` subdirectory. There are two \nC++ APIs -- the __MDL SDK API__ and the __MDL Core API__ -- for which \nyou need to generate the documentation with Doxygen. Please make sure \nto use the specified version 1.8.4.\n\nAdditional documents are the MDL Specification (PDF) and the `base.mdl` \nand `core_definitions.mdl` documentation (HTML), which you do not\nneed to generate; they are a part of the source code release.\n\n1.  The tools required to build the documentation are listed \n    [here](#doc-build-tools).\n\n2.  The use of the `dot` tool is optional and disabled by default. Enabling \n    it gives you nicer inheritance diagrams. It is only supported on Linux \n    and Mac, since a custom bash script is used to process the diagrams. You \n    can enable the `dot` tool as follows:\n\n    1.  Set the `HAVE_DOT` configuration setting in the respective `Doxyfile`\n        to `YES` in `doc/mdl_sdkapi` and `doc/mdl_coreapi`.\n\n    2. Set the `GRAPHVIZ_DOT_HOME` environment variable to the directory \n        containing the GraphVis `dot` command (not the local `doc/mdl_sdkapi` \n        or `doc/mdl_coreapi` directory with the equally named `dot` shell \n        script, which is just a wrapper). \n\n    3.  On Mac, set the `PLATFORM` environment variable to a suitable\n        setting starting with `macosx-x86`.\n\n3.  Build the __MDL SDK API__ documentation with a plain `doxygen` call:\n\n    ```bash\n    cd ~/projects/mdl-sdk/doc/mdl_sdkapi\n    doxygen\n    ```\n\n    The resulting documentation is placed in an `html/` subdirectory with \n    the start page: \n\n    ```bash\n    ~/projects/mdl-sdk/doc/mdl_sdkapi/html/index.html\n    ```\n\n4.  Build the __MDL Core API__ documentation with a plain `doxygen` call:\n\n    ```bash\n    cd ~/projects/mdl-sdk/doc/mdl_coreapi\n    doxygen\n    ```\n\n    The resulting documentation is placed in an `html/` subdirectory with\n    the start page:\n\n    ```bash\n    ~/projects/mdl-sdk/doc/mdl_coreapi/html/index.html\n    ```\n\nA start page that links all documents can be found in the doc directory:\n\n```bash\n~/projects/mdl-sdk/doc/index.html\n```\n\n## Repository Structure\n\nThe NVIDIA MDL SDK repository consists of the following directories and files:\n\n    include/       - C++ API header files\n    examples/      - example programs and MDL files\n    src/           - source code for the SDK libraries\n    doc/           - API documentation, MDL specification, \n                     core_definitions.mdl and base.mdl documentation\n    cmake/         - support files for the CMAKE build system\n    \n    README.md      - this file: introduction and build instructions\n    CHANGELOG.md   - change log and difference to the binary MDL SDK release\n    LICENSE.md     - license for the MDL SDK and references to \n                     third-party licenses\n    CMakeLists.txt - top level CMAKE file\n\n\n## Additional Resources\n\n- [NVIDIA MDL Home Page](https://www.nvidia.com/mdl)\n- [NVIDIA MDL SDK Forum](https://devtalk.nvidia.com/default/board/253/mdl-sdk/)\n"}, {"repo": "/swcarpentry/shell-novice", "language": "HTML", "readme_contents": "[![Create a Slack Account with us](https://img.shields.io/badge/Create_Slack_Account-The_Carpentries-071159.svg)](https://swc-slack-invite.herokuapp.com/) \n[![Slack Status](https://img.shields.io/badge/Slack_Channel-swc--shell-E01563.svg)](https://swcarpentry.slack.com/messages/C9X3XTHJ8) \n[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.3266823.svg)](https://doi.org/10.5281/zenodo.3266823)\n\nshell-novice\n============\n\nAn introduction to the Unix shell for people who have never used the command line before.\nPlease see <https://swcarpentry.github.io/shell-novice/> for a rendered version of this material,\n[the lesson template documentation][lesson-example]\nfor instructions on formatting, building, and submitting material,\nor run `make` in this directory for a list of helpful commands.\n\nMaintainers:\n\n* [Gabriel A. Devenyi][devenyi_gabriel]\n* [Colin Morris][colin_morris]\n* [Will Pitchers][will_pitchers]\n* [Gerard Capes][gerard_capes]\n\n[devenyi_gabriel]: http://software-carpentry.org/team/#devenyi_gabriel\n[colin_morris]: https://github.com/colinmorris\n[will_pitchers]: https://software-carpentry.org/team/#pitchers_w\n[gerard_capes]: https://carpentries.org/instructors/#capes_gerard\n[lesson-example]: https://carpentries.github.io/lesson-example/\n"}, {"repo": "/jnz/q3vm", "language": "C", "readme_contents": "Q3VM Readme\n===========\n\nA lightweight (single file: `vm.c`) embeddable interpreter/Virtual Machine (VM) for compiled bytecode files (`.qvm`) based on good old C-language input (`.c`). A complete C compiler to generate `.qvm` files is included (LCC). The interpreter is based on the Quake III Arena virtual machine (hence the name q3vm) but the interpreter is not tied to Quake III Arena and can be used for any kind of project. For example code that needs to run in a sandbox.\n\n[![Build Status](https://travis-ci.org/jnz/q3vm.svg?branch=master)](https://travis-ci.org/jnz/q3vm)\n[![codecov](https://codecov.io/gh/jnz/q3vm/branch/master/graph/badge.svg)](https://codecov.io/gh/jnz/q3vm)\n[![Coverity](https://scan.coverity.com/projects/16570/badge.svg)](https://scan.coverity.com/projects/jnz-q3vm)\n\n      ___   _______     ____  __\n     / _ \\ |___ /\\ \\   / /  \\/  |\n    | | | |  |_ \\ \\ \\ / /| |\\/| |\n    | |_| |____) | \\ V / | |  | |\n     \\__\\_______/   \\_/  |_|  |_|\n\n\nJan Zwiener, 2018. Mail: jan@zwiener.org\n\nRead the excellent introduction to the Q3VM by Fabien Sanglard:\n\n * http://fabiensanglard.net/quake3/qvm.php\n\nGif: compiling a simple *hello world* example (`main.c`) and run it with the virtual machine interpreter `q3vm`.\n\n![gif](demo_vm.gif?raw=1)\n\nInstallation\n------------\n\nThe [vm.c](src/vm/vm.c?raw=1) and [vm.h](src/vm/vm.h?raw=1) files can be\ndropped into an existing C project and compiled along with it. Implement\nthe 4 callback functions in your project: `Com_malloc`,  `Com_free`, `Com_Error`\nand `systemCalls`.\n\nFeatures\n--------\n\n * Small and lightweight (one .c file to include without dependencies)\n * Battle-tested (20 years of use in Quake III Arena)\n * VM and LCC forked from the well maintained ioquake3 code base\n * Tool tested (static code analysis, test coverage, Valgrind)\n * No need to learn a new scripting language (e.g. Lua)\n * Static type checking in the language (C)\n * Static memory allocation in C, no unpredictable garbage collector\n * Plan B: you can always go back to native code, as .c files are the input\n * Great tool landscape for C. Use the tools that are available for C\n * Computed gotos are used to speed up the interpreter if you compile with GCC (see benchmark section) \n * Much faster than the Triseism Q3VM interpreter (see benchmark section)\n\nUse Cases\n---------\n\n * Sandbox for code you don't fully trust (e.g. download the bytecode from a web server)\n * Mods for hobby game engines\n * There are many virtual machines, but not many are so small, with static typing and no garbage collector\n * Learn about virtual machines in general, but directly have a C compiler available for the virtual machine\n * Sandbox for embedded applications, e.g. plug-ins for IoT applications on microcontrollers (bounded CPU time, bounded memory area, restrict access to peripheral devices)\n * There is also a historical value: learn about the Quake III engine\n\n\nQuick Intro\n-----------\n\nTwo things are required:\n\n * The interpreter\n * A bytecode binary .qvm file\n\nRun:\n\n    > q3vm.exe bytecode.qvm\n\nThe q3vm.exe standalone interpreter is not required, it is more of a demo\napplication.  You can easily add the interpreter as a single .c file to your\nproject (`vm.c` and the header `vm.h`).  Call `VM_Create` and `VM_Call` to run\nthe bytecode in your application:\n\n```c\n    #include \"vm.h\"\n\n    vm_t vm;\n    int result;\n    \n    VM_Create(&vm, \"my test\", pointerToByteCodeBuffer, sysCall);\n    result = VM_Call(&vm, 12345);\n    VM_Free(&vm);\n```\n\nThe `pointerToByteCodeBuffer` is some memory location where the bytecode is\nlocated. You can e.g. load it from a file and store it in a byte array. See\n`main.c` for an example implementation.\n\nData can be exchanged with the bytecode by the return value (result) and\narguments to `VM_Call`. Here just a 12345 is passed to the bytecode. It is up\nto the `vmMain` function in the bytecode what to do with that value.  You can pass\nmore (up to 12) optional arguments to the bytecode:\ne.g. `VM_Call(&vm, 0, 1, 2, 3, 4)`.\n\nThe `sysCall` is a callback function that you define so that the interpreter\ncan call native functions from your code. E.g. a logging function or some time\ncritical function that you don't want to implement in the bytecode. Again,\ncheck `main.c` for an example. Also check the section *How to add a custom\nnative function* for more information.\n\nA few callback functions are required, read the section *Callback functions\nrequired in host application* for more information.\n\nAnd normally you should also check if `VM_Create` returns 0 (i.e. everything is\nOK).\n\nFolder structure\n----------------\n\n    \u251c\u2500 bin/             LCC compiler and q3asm linker output binaries\n    \u2502  \u251c\u2500 linux/        Linux target folder for LCC compiler and q3asm linker\n    \u2502  \u2514\u2500 win32/        Precompiled lcc.exe and q3asm.exe for Windows\n    \u251c\u2500 build/           Temp. directory for object files\n    \u251c\u2500 doxygen/         Doxygen config and API documentation output\n    \u251c\u2500 example/         Example \"hello world\" firmware project (bytecode.qvm)\n    \u251c\u2500 lcc/             The LCC compiler (compile .c files to .asm files)\n    \u251c\u2500 msvc/            Microsoft Visual Studio 2015 project file for q3vm\n    \u251c\u2500 q3asm/           Linker: link the LCC .asm files to a .qvm bytecode file\n    \u251c\u2500 src/             q3vm standalone console application source code\n    \u2502  \u2514\u2500 vm/           The core VM source, copy that folder into your project\n    \u2514\u2500 test/            Test environment\n\nAPI Documentation\n-----------------\n\nCall `make doxygen` to autogenerate the API documentation in the `doxygen/html`\ndirectory. Doxygen is required as well as the dot command (part of graphviz).\nInstall it with `sudo apt-get install doxygen graphviz` on Debian or Ubuntu.\n\n    > make doxygen\n\nBut you can also read `vm.h` directly for the API documentation.\n\n\nBuild VM/interpreter\n--------------------\n\nOn **Linux**:\n\n    > make\n\nOn **Windows**:\n\nUse the **Visual Studio 2015** project `q3vm.sln` in the `msvc` subfolder.\n\nOr install MinGW64 and add the MinGW64 bin\\ directory to your path.\nSo that you have gcc.exe and mingw32-make.exe available at the command prompt.\n\n * http://mingw-w64.org/doku.php/download/mingw-builds\n\nCompile with:\n\n    > mingw32-make\n\nBuild example bytecode firmware\n-------------------------------\n\n**Windows**:\n\nThe LCC compiler (lcc.exe) is included in the ./bin/win32 directory.\nYou need make (mingw32-make) from the MinGW64 installation in\nyour path. The Makefile calls LCC and q3asm to generate `bytecode.qvm`:\n\n    cd example\n    mingw32-make\n\nIf you don't want to use make, you can do the steps from the make file\nmanually at the command line. Compile every `.c` source code with `LCC`:\n\n    > lcc -S -Wf-target=bytecode -Wf-g YOUR_C_CODE.c\n\nThis will create .asm output files. Then link the .asm files with `q3asm` (based on a bytecode.q3asm\nlinker script):\n\n    > q3asm -f bytecode\n\nThe output of q3asm is a `.qvm` file that you can run with q3vm.\n\n\n**Linux**:\n\nBuild LCC:\n\n    > make lcc\n\nBuild q3asm\n\n    > make q3asm\n\nBuild the example bytecode:\n\n    > make example/bytecode.qvm\n\nCallback functions required in host application\n-----------------------------------------------\n\n**malloc and free**:\n\nThe following functions are required in the host application for\nmemory allocation:\n\n```c\n    void* Com_malloc(size_t size, vm_t* vm, vmMallocType_t type);\n    {\n        (void)vm;\n        (void)type;\n        return malloc(size);\n    }\n    \n    void Com_free(void* p, vm_t* vm, vmMallocType_t type)\n    {\n        (void)vm;\n        (void)type;\n        free(p);\n    }\n```\n\nThe host can simply call `malloc` and `free` or use a custom memory allocation\nfunction or use static memory (e.g. in an embedded application). Each VM only\ncalls `Com_malloc` once per malloc type. This can be used as a help for the static memory\nallocation in an embedded environment without `malloc()` and `free()`.\n\n**Error handling**:\n\nThe following function needs to be implemented in the host application:\n\n```c\n    void Com_Error(vmErrorCode_t level, const char* error)\n    {\n        fprintf(stderr, \"Err (%i): %s\\n\", level, error);\n        exit(level);\n    }\n```\n\nThe error id is given by the `vmErrorCode_t` parameter. The `error` string describes\nwhat went wrong.  It is up to the host application how to deal with the error.\nIn this simple example we just print the error string and exit the application.\nThe error code is stored in the `vm_t::lastError` variable.\n\nHow to add a custom native function\n-----------------------------------\n\nLet's say we want to add a native function to convert a string to an integer:\n`stringToInt`.  We want to add the function to our virtual machine (step 1) and\ncall it from our example code (step 2).  (Note: there is already the `atoi` function in\nthe bytecode, but this is just an example on how to call `atoi` as a native\nfunction and deal with address translation).\n\n\n**Step 1)** Add the native function to the host application\n\nOpen `src/main.c` and modify the `systemCalls` function. Add `case -5:` for the\nnew native function. We just use the next free id (here -5) as an identifier.\nThe identifier will be important in step 2.  The first argument\nfor `stringToInt` is the address of a string. The address is in the virtual\nmachine address space, so we can't directly use that argument (`args[1]`) for\nthe native call to `atoi`. There is a helper macro that will translate the\naddress for use: `VMA`. We need to give `VMA` the pointer argument from the\nbytecode and the virtual machine context (`vm`) to translate it.\nThe function `VM_MemoryRangeValid` makes sure that the memory range is valid. This is e.g.\nimportant for the `memcpy` call, so that the VM cannot write outside of\nthe sandbox memory.\nIt is also possible to call the VM recursively again with `VM_Call`.\n\n```c\n    /* Call native functions from the bytecode: */\n    int systemCalls(vm_t* vm, int* args)\n    {\n        const int id = -1 - args[0];\n    \n        switch (id)\n        {\n        case -1: /* PRINTF */\n            return printf(\"%s\", (const char*)VMA(1, vm));\n\n        case -2: /* ERROR */\n            return fprintf(stderr, \"%s\", (const char*)VMA(1, vm));\n    \n        case -3: /* MEMSET */\n            if (VM_MemoryRangeValid(args[1]/*addr*/, args[3]/*len*/, vm) == 0)\n            {\n                memset(VMA(1, vm), args[2], args[3]);\n            }\n            return args[1];\n    \n        case -4: /* MEMCPY */\n            if (VM_MemoryRangeValid(args[1]/*addr*/, args[3]/*len*/, vm) == 0 &&\n                VM_MemoryRangeValid(args[2]/*addr*/, args[3]/*len*/, vm) == 0)\n            {\n                memcpy(VMA(1, vm), VMA(2, vm), args[3]);\n            }\n            return args[1];\n    \n        case -5: /* stringToInt */                             // < NEW !!!\n            return atoi(VMA(1, vm));                           // < NEW !!!\n    \n        default:\n            fprintf(stderr, \"Bad system call: %i\\n\", id);\n        }\n        return 0;\n    }\n```\n\n**Step 2)** Tell the bytecode about this function\n\nNow we need to tell our example project about this new function `strintToInt`.\nOpen `example/g_syscalls.asm` and add the last line. The identifier -5 is\nimportant for the mapping.\n\n    code\n    \n    equ trap_Printf             -1\n    equ trap_Error              -2\n    equ memset                  -3\n    equ memcpy                  -4\n    equ stringToInt             -5\n\n**Step 3)** Perform an example call to `strintToInt`\n\nEdit `example/main.c` and add the function declaration:\n\n```c\n    int stringToInt(const char* a);\n```\n\nAnd call it somewhere from the `vmMain` function:\n\n```c\n    char* myStr = \"1234\";\n    printf(\"\\\"%s\\\" -> %i\\n\", myStr, stringToInt(myStr));\n```\n\nCompile everything:\n\n    > make && make example/bytecode.qvm\n\nAnd run it:\n\n    > ./q3vm example/bytecode.qvm\n\nOriginal comments by John Carmack\n---------------------------------\n\nJohn Carmack's .plan for Nov 03, 1998:\n\n*I had been working under the assumption that Java was the right way to go, but recently I reached a better conclusion.*\n*The programming language for QuakeArena mods is interpreted ANSI C. (well, I am dropping the double data type, but otherwise it should be pretty conformant)*\n*The game will have an interpreter for a virtual RISC-like CPU. This should have a minor speed benefit over a byte-coded, stack based java interpreter. Loads and stores are confined to a preset block of memory, and access to all external system facilities is done with system traps to the main game code, so it is completely secure.*\n*The tools necessary for building mods will all be freely available: a modified version of LCC and a new program called q3asm. LCC is a wonderful project - a cross platform, cross compiling ANSI C compiler done in under 20K lines of code. Anyone interested in compilers should pick up a copy of \"A retargetable C compiler: design and implementation\" by Fraser and Hanson.*\n*You can't link against any libraries, so every function must be resolved. Things like strcmp, memcpy, rand, etc. must all be implemented directly. I have code for all the ones I use, but some people may have to modify their coding styles or provide implementations for other functions.*\n*It is a fair amount of work to restructure all the interfaces to not share pointers between the system and the games, but it is a whole lot easier than porting everything to a new language. The client game code is about 10k lines, and the server game code is about 20k lines.*\n*The drawback is performance. It will probably perform somewhat like QC. Most of the heavy lifting is still done in the builtin functions for path tracing and world sampling, but you could still hurt yourself by looping over tons of objects every frame. Yes, this does mean more load on servers, but I am making some improvements in other parts that I hope will balance things to about the way Q2 was on previous generation hardware.*\n*There is also the amusing avenue of writing hand tuned virtual assembly assembly language for critical functions.*\n*I think this is The Right Thing.*\n\nStatic code analysis\n--------------------\n\nCall `make analysis` and `make valgrind` to check the VM with:\n\n * clang static code analysis (scan-build)\n * cppcheck\n * Valgrind\n\nclang-format\n------------\n\nRun the following command to reformat a file according to the coding style:\n\n    > clang-format -i -style=file input.c\n\n\nDebugging\n---------\n\nBuild `vm.c` with `#define DEBUG_VM` in `vm.h` to enable more checks and debug\nfunctions. Call `VM_Debug()` to enable debug printfs.  This\nrequires the symbol file of the `.qvm`: the `.map` file in the same directory\nas the `.qvm`. The `.map` file is automatically generated for each `.qvm`.\n\nCall at the end of a session `VM_VmProfile_f(vm)` to see a VM usage summary.\n\nBenchmarks\n----------\n\nTime to run `test/test.qvm`.\n\nSmaller numbers are better (multiple runs, smallest number used).\n\n\n| Interpreter          | Time     |\n|----------------------|----------|\n| Default Interpreter  |  3.063 s |\n| w. computed gotos    |  1.771 s |\n| Native executable    |  0.307 s |\n\n\nEnvironment:\n\n * Ubuntu 17.10\n * GCC: 7.2.0-8ubuntu3.2\n * CPU: Intel(R) Core(TM) i5-3320M CPU @ 2.60GHz\n * Version Git hash: 8e46048f475a53f99f9e6656e030835b6011f2ca\n * Date: 2018.08.31\n\nCommand line:\n\n    time ./q3vm test/test.qvm\n    time ./test/test_native\n\nBenchmark vs. Triseism Q3 interpreter (seismiq executable).\n\nTestfirmware: `test/example_test.qvm`\n\nSmaller numbers are better (multiple runs, smallest number used).\n\n\n| Interpreter          | Time     |\n|----------------------|----------|\n| Q3VM                 |  1.222 s |\n| Triseism project     | 10.903 s |\n\n * Ubuntu 17.10\n * GCC: 7.2.0-8ubuntu3.2\n * CPU: Intel(R) Core(TM) i5-3320M CPU @ 2.60GHz\n * Version Git hash: bb4848c25b2b95c08b9aa03bb6ac46ef4948d900\n\nVersion History\n---------------\n\n * v1.3 - q3asm from ioquake3 added\n\n * v1.2 - Debug features enabled (compile with `-DDEBUG_VM`)\n\n * v1.1 - LCC from ioquake3 added\n\nTODO\n----\n\nKnown limitations, bugs, missing features:\n\n * The Quake III Arena JIT compiler (e.g. for x86) is not added.\n\nLICENSE\n-------\n\nSee COPYING.txt for details on the license. Basically the Quake III Arena\nGPL 2 source code license has been inherited.\n\nBe aware that LCC has its own non-commercial license which is described in\nlcc/COPYRIGHT.\n\nFurther information\n-------------------\n\n * http://fabiensanglard.net/quake3/qvm.php\n * http://users.suse.com/~lnussel/talks/fosdem_talk_2013_q3.pdf\n\nCredits\n=======\n\nThis project is based on the Quake 3 and ioquake3 source:\n\n * https://github.com/id-Software/Quake-III-Arena (id Software)\n * https://github.com/ioquake/ioq3\n * https://icculus.org/projects/triseism/triseism.html\n\nComputed gotos are used:\n\n * https://eli.thegreenplace.net/2012/07/12/computed-goto-for-efficient-dispatch-tables\n \n"}, {"repo": "/P4ELTE/t4p4s", "language": "C", "readme_contents": "\n# T<sub>4</sub>P<sub>4</sub>S, a multitarget P4<sub>16</sub> compiler\n\nThis is an experimental compiler for P4<sub>16</sub> and P4<sub>14</sub> files.\nFor publications and more, [see our homepage](http://p4.elte.hu/).\n\nAn older version of the compiler is [also available](https://github.com/P4ELTE/t4p4s/tree/t4p4s-14).\n\nFind out more [about the P4 language](https://p4.org/).\n\n## Getting started\n\n### Preparation\n\nTo start working with the compiler, simply download the `bootstrap-t4p4s.sh` script and execute it with the following command. It should work on Debian based systems, e.g. the latest LTS edition of Linux Mint or Ubuntu.\n\n    . ./bootstrap-t4p4s.sh\n\nThe script installs all necessary software including T<sub>4</sub>P<sub>4</sub>S itself, and sets up environment variables.\n\n- Note: without the `.` at the beginning of the line, the environment variables will not be usable immediately.\n    - In that case, you can either start a new terminal, or run `. ./t4p4s_environment_variables.sh`\n\nOverriding defaults.\n\n- To increase efficiency, the script runs jobs on all cores on the system in parallel. Should you experience any problems (for example, your system may run out of memory), you can override the number of jobs.\n\n    MAX_MAKE_JOBS=4 . ./bootstrap-t4p4s.sh\n\n- By default, the script runs downloads in parallel. You can force it to work sequentially.\n\n    PARALLEL_INSTALL=0 . ./bootstrap-t4p4s.sh\n\n- The script installs the newest versions of DPDK and P4C unless overridden by the user.\n    \n    DPDK_VERSION=16.11 . ./bootstrap-t4p4s.sh\n    DPDK_VERSION=16.11 DPDK_FILEVSN=16.11.1 . ./bootstrap-t4p4s.sh\n\n- The script will use `clang` by default if it is installed. Using another target like `gcc` is possible, too.\n\n    RTE_TARGET=x86_64-native-linuxapp-gcc . ./bootstrap-t4p4s.sh\n\nTo download T<sub>4</sub>P<sub>4</sub>S only, make sure to get it with its submodule like this: `git clone --recursive https://github.com/P4ELTE/t4p4s`\n\n- When you pull further commits, you will need to update the submodules as well: `git submodule update --init --recursive` or `git submodule update --rebase --remote`\n\nNote: at this stage, not all P4 programs will compile and run properly. In particular, `typedef`s are not supported currently.\n\n\n### Options\n\nIn the `t4p4s.sh` script, options control the process of compilation and execution.\nThe options are collected in the following phases.\n\n1. By default, the `colours.cfg`, `lights.cfg`, the command line, `examples.cfg` and `opts_${ARCH}.cfg` are processed.\n    - `colours.cfg` describes the available colours for output highlighting.\n    - `lights.cfg` describes which colours are used in the terminal and in the switch output for highlighting.\n    - `examples.cfg` sets options for each example.\n    - `opts_${ARCH}.cfg` sets architecture specific options.\n    - Currently, the only valid value for `${ARCH}` is `dpdk`.\n1. When the command line of the script is processed, anything not identifiable as a P4 program is considered an option.\n    - A P4 program is the name of an existing file whose extension begins with `p4`.\n    - Here, the options are separated by spaces, therefore their values are not allowed to contain spaces themselves.\n1. Option files come in two flavours.\n    - Some files (e.g. `lights.cfg`) contain an option definition on a single line.\n    - Some files (e.g. `examples.cfg`) contain an example identifier and then any number of options on a line.\n        - An example identifier is `examplename@testcasename`, or if `@testcasename` is not given, `@std` is used by default.\n        - As in the case of the command line, options may not contain any spaces.\n    - In both cases, empty lines (containing whitespace only) and comments (a `;` not preceded by a number, until the end of the line) are ignored.\n\nThe format of option definitions is the following.\n\n- Option names contain letters, numbers, `-` (dash), `_` (underscore) and `.` (dot).\n- Define `myopt` with the value `myval`.\n    `myopt=myval`\n- Define `myopt` that takes the default value `on`.\n    `myopt`\n- In the cases described above, spaces can be allowed.\n    `myopt=foo bar`\n- From this point on, `myopt` is ignored: it is considered not to be defined.\n    `^myopt`\n- Define `myopt` with the value `val` only if `mycondopt` _is defined_ at this time.\n    `mycondopt->myopt=val`\n- Define `myopt` with the value `val` only if `mycondopt` is _not_ defined at this time.\n    `^mycondopt->myopt=val`\n- Define `myopt` with the value `val` only if `mycondopt` is defined at this time, and its value is `condval`.\n    `mycondopt=condval->myopt=val`\n- In all of the above, `+=` `++=` can take the place of `=`. Instead of setting the option, they append to the current value: `+=` with a space separator, `++=` with a newline.\n  - `myopt=foo` and then `myopt+=bar` is equivalent to `myopt=foo bar`\n- For convenience, there are some abbreviations.\n\n    | Option given            | Equivalent to                                                           |\n    | ----------------------- | ----------------------------------------------------------------------- |\n    | @myvariant              | variant=**myvariant**                                                   |\n    | :myexample              | example=**myexample**                                                   |\n    | ::myexample             | example=**myexample** dbg                                               |\n    | %myexample=mytestcase   | example=**myexample** variant=test testcase=**mytestcase**              |\n    | %myexample              | example=**myexample** variant=test testcase=test                        |\n    | %%myexample=mytestcase  | example=**myexample** variant=test verbose dbg testcase=**mytestcase**  |\n    | %%myexample             | example=**myexample** variant=test verbose dbg suite                    |\n\n\n### Execution\n\nThe `t4p4s.sh` script uses settings from three configuration files.\n\n1. `light.cfg` describes how texts in the terminal and switch output look.\n1. `examples.cfg` describes default options for the examples.\n    - A set of parameters for an example is called a configuration _variant_.\n    - On the command line, you have to specify the _example_ (by name or full path) and the _variant name_.\n1. An architecture specific file (for DPDK, `opts_dpdk.cfg`) describes how the options are to be interpreted: they are translated to more options.\n    - Everything apart from the _example_ is considered an option on the command line.\n\nThe script returns an exit code of `0` if the execution was successful, and a non-zero value otherwise.\n\nThe script creates `build/<example-name>`.\n\n- Under it, the directories `build`, `srcgen` and `Makefile` contain compilation artifacts, including the created switch executable.\n- Log output is stored in `log`.\n    - `controller.log` is the log output from the most recent controller execution.\n    - For each execution, two log files are created.\n        - The one with the simple `.txt` extension is a regular textual log.\n        - The one with the `lit.txt` extension contains ANSI colour codes. Invoking `cat` on it, or using an appropriate viewer like [SublimeANSI](https://github.com/aziz/SublimeANSI) will show coloured output.\n        - The logs of the most recent script execution are also available as `last.txt` and `last.lit.txt`.\n\n\n### Examples\n\nNote that for non-testing examples, you will have to setup your network card, and probably adjust your configuration options.\n\n1. Specify an example\n    - Run an example with the default configuration\n        `./t4p4s.sh :l2fwd`\n    - The program finds the source file under `examples` automatically, but you can also specify it manually\n        `./t4p4s.sh ./examples/l2fwd.p4_14`\n1. Execution phases, option settings\n    - Specify one or more steps to be taken\n        `./t4p4s.sh :l2fwd p4`\n        `./t4p4s.sh :l2fwd c`\n        `./t4p4s.sh :l2fwd run`\n    - If no option is given, all phases (`p4 c run`) are active\n        `./t4p4s.sh :l2fwd`\n    - Options can be given in any order (phases will always run in `p4 c run` order)\n        `./t4p4s.sh :l2fwd p4 c`\n        `./t4p4s.sh :l2fwd c p4`\n    - All options have one parameter, which defaults to \"on\"\n        `./t4p4s.sh :l2fwd p4=on c=on run=on`\n    - Prefixing an option with `^` suppresses it\n        - Run only P4-to-C and C-to-switch compilation\n        `./t4p4s.sh :l2fwd ^run`\n    - Set the controller configuration (the controller program takes it as a parameter)\n        `./t4p4s.sh :l2fwd ctrcfg=my_ctr_opts.txt`\n1. Output options: highlighting, verbosity\n    - Get monochrome (black-and-white) output, useful for scripting\n        `./t4p4s.sh :l2fwd bw`\n    - Monochrome terminal, colour switch execution\n        `./t4p4s.sh :l2fwd bw=terminal`\n    - Colour terminal, monochrome switch execution\n        `./t4p4s.sh :l2fwd bw=switch`\n    - Verbose output for the terminal\n        `./t4p4s.sh :l2fwd verbose`\n    - Verbose output for the switch\n        `./t4p4s.sh :l2fwd dbg`\n    - Suppress EAL messages from the switch output\n        `./t4p4s.sh :l2fwd noeal`\n    - No output at all (both terminal and switch) except for errors\n        `./t4p4s.sh :l2fwd silent`\n    - If the switch fails, runs it again in the debugger (by default, `gdb`)\n        `./t4p4s.sh :l2fwd autodbg`\n1. Variants, testing\n    - Specify a variant, a set of configuration options\n        `./t4p4s.sh :l2fwd @test`\n        `./t4p4s.sh :l2fwd variant=test`\n    - Run a single test case\n        - It runs offline: no network card is needed\n        - Data for the test case is in `examples/test-l2fwd.c`\n        `./t4p4s.sh :l2fwd @test testcase=test`\n        `./t4p4s.sh :l2fwd @test testcase=payload`\n    - Abbreviated form (also sets `@test`)\n        `./t4p4s.sh %l2fwd=payload`\n    - Another abbreviation, equivalent to using `testcase`, `dbg` and `@test`\n        `./t4p4s.sh ::l2fwd`\n    - Run the test suite for the example\n        `./t4p4s.sh %%l2fwd`\n    - Stop the switch immediately upon encountering invalid data\n        `./t4p4s.sh %l2fwd=payload strict`\n1. Miscellaneous options\n    - Specify the P4 version manually (usually decided by other options or P4 file extension)\n        `./t4p4s.sh :l2fwd vsn=14`\n    - Set the controller manually\n        `./t4p4s.sh :l2fwd ctr=l2fwd`\n    - Many options can be overridden using environment variables\n        `EXAMPLES_CONFIG_FILE=\"my_config.cfg\" ./t4p4s.sh my_p4 @test`\n        `EXAMPLES_CONFIG_FILE=\"my_config.cfg\" COLOUR_CONFIG_FILE=\"my_colors.txt\" P4_SRC_DIR=\"../my_files\" ARCH_OPTS_FILE=\"my_opts.cfg\" ./t4p4s.sh %my_p4 dbg verbose`\n\n\n### Testing\n\nAs described above, you can run individual test cases.\nTo see detailed output about compilation and execution, use the following options.\n\n    ./t4p4s.sh %%l2fwd=payload\n\nTo run all available test cases, execute `./run_all_tests.sh`.\nYou can also give this script any number of additional options.\n\n    ./run_all_tests.sh verbose dbg\n\nOnce all test cases are run, the script prints a summary of successful and failed test cases,\nexits with the error code `0` if all tests ran successfully, and `1` if there were any errors.\n\n\n# Using Docker with T<sub>4</sub>P<sub>4</sub>S\n\nYou can also run `t4p4s-docker.sh` to run T<sub>4</sub>P<sub>4</sub>S in a Docker container.\n\n- Docker Community Edition has to be configured on your system.\n    - Usually it is available once you install the package `docker.io`.\n    - For more details, see [this guide](https://docs.docker.com/engine/installation/linux/docker-ce/ubuntu/).\n- Running `t4p4s-docker.sh` sets up two containers called `t4p4s` and `t4p4s-sh`.\n    - Both are usable separately.\n    - The `t4p4s-sh` container also takes all arguments for `t4p4s-docker.sh`.\n        - For example, you can run `./t4p4s-docker.sh verbose dbg %l2fwd=payload`\n        - Currently, the containers are run without a network card configuration.\n- The Docker instances rely on having the same version for `linux-headers` as the host system. See the `FROM` clause in the `t4p4s-16.docker` file.\n- The configuration is based on that of [`docker-dpdk` by Jeremy Eder](https://github.com/jeremyeder/docker-dpdk/), which includes using the host's `hugepages` inside the Docker instances.\n    - Make sure you have enough `hugepages` on the host before running the containers.\n\n\n# Working with the compiler\n\n## Gathering data\n\nThe following parts presume that you are using `ipdb` for debugging.\nYou can manually add a debug trigger the following way.\n\n~~~\nimport ipdb; ipdb.set_trace()\n~~~\n\nA convenient place to start an investigation is at the end of `set_additional_attrs` in `hlir16_attrs.py`.\n\nYou can search for all occurrences of a string/integer/etc.\nTypically you would start at the topmost node (called `hlir16`),\nbut any node can be used as a starting point.\n\n~~~\nhl[TAB]\nhlir16.p[TAB]\nhlir16.paths_to('ethernet')\nhlir16.paths_to(1234567)\n~~~\n\nThe result will look something like this.\n\n~~~\n  = .objects['Type_Header'][0]\n  < .objects['Type_Struct'][4].fields\n  \u2208 .objects['P4Parser'][0].states['ParserState'][0].components['MethodCallStatement'][0].methodCall.arguments['Member'][0].expr.type.fields\n  < .objects['P4Parser'][0].states['ParserState'][0].components['MethodCallStatement'][0].methodCall.arguments['Member'][0].member\n  < .objects['P4Parser'][0].states['ParserState'][0].components['MethodCallStatement'][0].methodCall.arguments['Member'][0].type\n  < .objects['P4Parser'][0].states['ParserState'][0].components['MethodCallStatement'][0].methodCall.typeArguments['Type_Name'][0].path\n  < .objects['P4Parser'][0].states['ParserState'][0].selectExpression.select.components['Member'][0].expr.expr.type.fields\n  < .objects['P4Parser'][0].states['ParserState'][0].selectExpression.select.components['Member'][0].expr.member\n...........\n~~~\n\nThe first character indicates if the searched content is a perfect match (`=`), a prefix (`<`) or an infix (`\u2208`) of the result of the path.\n\nYou can copy-paste a line of the result, and inspect the element there.\n\n~~~\nipdb> hlir16.objects['P4Parser'][0].states['ParserState'][0].components['MethodCallStatement'][0].methodCall.arguments['Member'][0].type\nethernet_t<Type_Header>[annotations, declid, fields, name]\n~~~\n\nYou can give some options to `paths_to`.\n\n- `print_details` shows each node that each path traverses\n- `match` controls how the matching works (it is always textual)\n\n~~~\nhlir16.paths_to('intrinsic_metadata')\nhlir16.paths_to('intrinsic_metadata', print_details=False, match='prefix')\nhlir16.paths_to('intrinsic_metadata', match='prefix')\nhlir16.paths_to('intrinsic_metadata', match='infix')\nhlir16.paths_to('intrinsic_metadata', match='full')\n~~~\n\n\n## Attributes\n\nThe nodes get their attributes in the following ways.\n\n1. At creation, see `p4node.py`.\n    - In the debugger, enter `hlir16.common_attrs` to see them.\n1. Most attributes are directly loaded from the JSON file.\n    - See `load_p4` in `hlir16.py`.\n    - The `.json` file is produced using the `--toJSON` option of the P4 frontend `p4test`.\n      By default, this is a temporary file that is deleted upon exit.\n1. Many attributes are set in `set_additional_attrs` in `hlir16.py`.\n   While the compiler is in the experimental stage,\n   they may be subject to change, but once it crystallizes,\n   they will be considered standard.\n1. You can manually add attributes using `add_attrs`, but those will be considered non-standard,\n   and will not be portable in general.\n\nThe representation contains internal nodes (of type `P4Node`)\nand leaves (primitives like ints and strings).\nInternal nodes will sometimes be (ordered) vectors.\n\nSome of the more important attributes are the following.\n\n~~~\nhl[TAB].d[TAB]        # expands to...\nhlir16.objects   # these are the top-level objects in the program\n\nds = hlir16.objects\nds.is_vec()           # True\nds[0]                 # indexes the vector; the first declaration in the program\nds.b[TAB]             # expands to...\nds.by_type('Type_Struct')   # gives you all 'Type_Struct' objects\nds.by_type('Struct')        # shortcut; many things are called 'Type_...'\nds.get('name')        # all elems in the vector with the name 'name'\nds.get('ipv4_t', 'Type_Header')   # the same, limited to the given type\n\nany_node.name         # most nodes (but not all) have names\nany_node.xdir()       # names of the node's non-common attributes\n~~~\n\n## Special markers\n\nThe compiler uses the `.py` files inside the `hardware_indep` directory to generate Python code (saved with the extension `.desugared.py` under `build/util/desugared_compiler`), then executes the code to produce `.c` files. Under `src/utils`, files with the extension `.sugar.py` are also primarily used as code generators. The files are written with some syntactical sugar, which is described in the following.\n\n- The files under `hardware_indep` have access to the global variable `hlir16`, which is the root of the representation.\n    - The compiler silently prepares a `generated_code` global variable that starts out with an empty text. Usually, you do not want to manipulate it directly.\n    - The files may contain the following markers. `PyExpr` stands for a Python expression.\n        - `#[ (insert generated code here)`: the code will be textually added to `generated_code`\n        - `#[ ... $my_var ...`: the textual value of the Python variable `my_var` is inserted here\n        - `#[ ... ${PyExpr} ...`: the code is evaluated, then its result will be inserted as text\n        - `#= PyExpr`: the expression is evaluated, its result is inserted textually\n            - an alternative to this is to use `#[ ${Python expression}`\n        - `#{` and `#}`: the same as `#[`, except that code between the two will be indented one level\n            - the compiler expects that all opened `#{` markers will have a proper corresponding `#}` marker\n        - `$${PyExpr}` highlights the evaluated text using the default colour (`T4LIGHT_default`)\n            - `$$[mycolourname]{PyExpr}` uses `T4LIGHT_mycolourname` as the colour of highlighting; these colours are defined in `lights.cfg` and must be listed in `ALL_COLOURS` of `t4p4s.sh`\n            - `$$[mycolourname]{PyExpr}{text}` is the same as above, but `text` (which is just plain text) also appears in the highlighted part\n            - `$$[mycolourname][text1]{PyExpr}{text}` is the same as above, but `text1` (which is just plain text) also appears in the highlighted part\n- The following capabilities are most useful inside the `.sugar.py` files, but are used in `hardware_indep` as well.\n    - Functions whose name begin with `gen_` are considered helper functions in which the above markers are usable.\n        - Technically, they will have a local `generated_code` variable that starts out empty, and they will return it at the end.\n        - In general, such functions will contain a single conditional with multiple clauses, with each clause generating a bit of code.\n        - Usually, it's a good idea to have a function with the same name (without the `gen_` part) that calls the function.\n    - To facilitate finding the corresponding generator file, the desugared (generated) files contain line hints about the original file.\n        - For types and expressions, these can be made inline, e.g. `uint8_t /* codegen@123*/` means that the text `uint8_t` was generated by executing code on or around line 123 in `codegen.sugar.py` (in the directory `src/utils`).\n        - Most of the code generate statements, they contain hints at the end of the line such as `... // actions@123`\n        - You can control the sugar style using `file_sugar_style` and the class `SugarStyle` (in `compiler.py`), see the end of `codegen.sugar.py` for usage examples.\n"}, {"repo": "/skarnet/execline", "language": "C", "readme_contents": "execline - an interpreter-less scripting language\n-------------------------------------------------\n\n execline is a scripting language unlike any other in that\nit has no resident interpreter. It reads a script, turns it\ninto a single command line, and executes into that command\nline; control is performed by executables run inside the\ncommand line itself.\n\n It is especially suited to very small and simple scripts\nfor which a shell is overpowered.\n\n See https://skarnet.org/software/execline/ for details.\n\n\n* Installation\n  ------------\n\n See the INSTALL file.\n\n\n* Contact information\n  -------------------\n\n Laurent Bercot <ska-skaware at skarnet.org>\n\n Please use the <skaware at list.skarnet.org> mailing-list for\nquestions about execline.\n\n"}, {"repo": "/neoneggplant/EggShell", "language": "Objective-C", "readme_contents": "# [EggShell](http://lucasjackson.io/eggshell)\n\n\n\n## About\n\nEggShell is a post exploitation surveillance tool written in Python. It gives you a command line session with extra functionality between you and a target machine. EggShell gives you the power and convenience of uploading/downloading files, tab completion, taking pictures, location tracking, shell command execution, persistence, escalating privileges, password retrieval, and much more.  This is project is a proof of concept, intended for use on machines you own.\n\n<img src=\"http://lucasjackson.io/images/eggshell/main-menu.png?3\" alt=\"Main menu\" width=\"500px;\"/>\n\nFor detailed information and how-to visit http://lucasjackson.io/eggshell\n\nFollow me on twitter: @neoneggplant\n\n<hr style=\"height:1px; background:#9EA4A9\">\n\n\n## New In Version 3.0.0\n - More secure socket connection using SSL\n - Linux support\n - Tab completion\n - Improved over all structure and efficiency of session handling\n - Native iOS python support for 64 bit devices\n\n<hr style=\"height:1px; background:#9EA4A9\">\n\n\n## Getting Started\n- Requires python 2.7\n\n### macOS/Linux Installation\n```sh\ngit clone https://github.com/neoneggplant/eggshell\ncd eggshell\npython eggshell.py\n```\n\n### iOS (Jailbroken)\nAdd Cydia source: http://lucasjackson.io/repo\nInstall EggShell 3\nUse any mobile terminal application and run the command eggshell\n\n<img src=\"http://lucasjackson.io/images/eggshell/main-menu-ios.png?3\" alt=\"Main menu\" width=\"400px;\"/>\n\n<hr style=\"height:1px; background:#9EA4A9\">\n\n\n\n## Creating Payloads\nEggshell payloads are executed on the target machine.  The payload first sends over instructions for getting and sending back device details to our server and then chooses the appropriate executable to establish a secure remote control session.\n\n### bash\nSelecting bash from the payload menu will give us a 1 liner that establishes an eggshell session upon execution on the target machine\n\n<img src=\"http://lucasjackson.io/images/eggshell/bash-payload.png\" alt=\"Bash payload\" width=\"300px\"/>\n\n### teensy macOS (USB injection)\nTeensy is a USB development board that can be programmed with the Arduino ide.  It emulates usb keyboard strokes extremely fast and can inject the EggShell payload just in a few seconds.\n\n<img src=\"http://lucasjackson.io/images/eggshell/teensy.jpg\" alt=\"Teensy macOS payload\" width=\"250px\"/>\n\nSelecting teensy will give us an arduino based payload for the teensy board.\n\n<img src=\"http://lucasjackson.io/images/eggshell/teensy-macos-payload.png\" alt=\"Teensy macOS payload\" width=\"450px\"/>\n\nAfter uploading to the teensy, we can use the device to plug into a macOS usb port.  Once connected to a computer, it will automatically emulate the keystrokes needed to execute a payload.\n\n<img src=\"http://lucasjackson.io/images/eggshell/arduino-ide.png\" alt=\"Teensy macOS payload\" width=\"450px\"/>\n\n<hr style=\"height:1px; background:#9EA4A9\">\n\n\n\n## Interacting with a session\n<img src=\"http://lucasjackson.io/images/eggshell/session-interaction.png\" alt=\"Session interaction\" width=\"400\"/>\n\nAfter a session is established, we can execute commands on that device through the EggShell command line interface.\nWe can show all the available commands by typing \"help\"\n\n<img src=\"http://lucasjackson.io/images/eggshell/help-command.png\" alt=\"Command help\" width=\"500px\"/>\n\n\n## Taking Pictures\n<img src=\"http://lucasjackson.io/images/eggshell/macos-picture.png\" alt=\"Session interaction\" width=\"700px\"/>\n\nBoth iOS and macOS payloads have picture taking capability. The picture command lets you take a picture from the iSight on macOS as well as the front or back camera on iOS.\n\n\n\n### Tab Completion\nSimilar to most command line interfaces, EggShell supports tab completion.  When you start typing the path to a directory or filename, we can complete the rest of the path using the tab key.\n\n<img src=\"http://lucasjackson.io/images/eggshell/tab-completion.png\" alt=\"Tab completion\" width=\"500px\"/>\n\n<hr style=\"height:1px; background:#9EA4A9\">\n\n\n\n## Multihandler\nThe Multihandler option lets us handle multiple sessions.  We can choose to interact with different devices while listening for new connections in the background.  \n\n<img src=\"http://lucasjackson.io/images/eggshell/multihandler-start.png\" alt=\"Drawing\" width=\"450px;\"/>\n\nSimilar to the session interface, we can type \"help\" to show Multihandler commands\n\n<img src=\"http://lucasjackson.io/images/eggshell/multihandler-help.png\" alt=\"Drawing\" width=\"400\"/>\n\n<hr style=\"height:1px; background:#9EA4A9\">\n\n\n\n## Featured\nFeatured in EverythingApplePro's video demonstrating an iOS 9.3.3 Webkit vulnerability used to run EggShell\n\n[![EverythingApplePro](http://lucasjackson.io/images/eggshell/featureeep.png)](https://www.youtube.com/embed/iko0bCVW-zk?start=209)\n\n<hr style=\"height:1px; background:#9EA4A9\">\n\n\n## Special Thanks\n- Linus Yang / Ryley Angus for the iOS Python package\n- AlessandroZ for LaZagne\n\n\n## DISCLAMER\nBy using EggShell, you agree to the GNU General Public License v2.0 included in the repository. For more details at http://www.gnu.org/licenses/gpl-2.0.html. Using EggShell for attacking targets without prior mutual consent is illegal. It is the end user's responsibility to obey all applicable local, state and federal laws. Developers assume no liability and are not responsible for any misuse or damage caused by this program.\n\n<hr style=\"height:1px; background:#9EA4A9\">\n\n\n\n## Commands\n\n#### macOS\n* **brightness**     : adjust screen brightness\n* **cd**             : change directory\n* **download**       : download file\n* **getfacebook**    : retrieve facebook session cookies\n* **getpaste**       : get pasteboard contents\n* **getvol**         : get speaker output volume\n* **idletime**       : get the amount of time since the keyboard/cursor were touched\n* **imessage**       : send message through the messages app\n* **itunes**         : iTunes Controller\n* **keyboard**       : your keyboard -> is target's keyboard\n* **lazagne**        : firefox password retrieval | (https://github.com/AlessandroZ/LaZagne/wiki)\n* **ls**             : list contents of a directory\n* **mic**            : record mic\n* **persistence**    : attempts to re establish connection after close\n* **picture**        : take picture through iSight\n* **pid**            : get process id\n* **prompt**         : prompt user to type password\n* **screenshot**     : take screenshot\n* **setvol**         : set output volume\n* **sleep**          : put device into sleep mode\n* **su**             : su login\n* **suspend**        : suspend current session (goes back to login screen)\n* **upload**         : upload file\n\n\n#### iOS\n* **alert**          : make alert show up on device\n* **battery**        : get battery level\n* **bundleids**      : list bundle identifiers\n* **cd**             : change directory\n* **dhome**          : simulate a double home button press\n* **dial**           : dial a phone number\n* **download**       : download file\n* **getcontacts**    : download addressbook\n* **getnotes**       : download notes\n* **getpasscode**    : retreive the device passcode\n* **getsms**         : download SMS\n* **getvol**         : get volume level\n* **home**           : simulate a home button press\n* **installpro**     : install substrate commands\n* **ipod**           : control music player\n* **islocked**       : check if the device is locked\n* **lastapp**        : get last opened application\n* **locate**         : get device location coordinates\n* **locationservice**: toggle location services\n* **lock**           : simulate a lock button press\n* **ls**             : list contents of a directory\n* **mic**            : record mic\n* **mute**           : update and view mute status\n* **open**           : open apps\n* **openurl**        : open url on device\n* **persistence**    : attempts to re establish connection after close\n* **picture**        : take picture through the front or back camera\n* **pid**            : get process id\n* **respring**       : restart springboard\n* **safemode**       : put device into safe mode\n* **say**            : text to speach\n* **setvol**         : set device volume\n* **sysinfo**        : view system information\n* **upload**         : upload file\n* **vibrate**        : vibrate device\n\n\n#### Linux\n* **cd**             : change directory\n* **download**       : download file\n* **ls**             : list contents of a directory\n* **pid**            : get process id\n* **pwd**            : show current directory\n* **upload**         : upload file\n\n"}, {"repo": "/inquisb/icmpsh", "language": "C", "readme_contents": "## Background\r\n\r\nSometimes, network administrators make the penetration tester's life harder. Some of them do use firewalls for what they are meant to, surprisingly!\r\nAllowing traffic only onto known machines, ports and services (ingress filtering) and setting strong egress access control lists is one of these cases. In such scenarios when you have owned a machine part of the internal network or the DMZ (e.g. in a Citrix breakout engagement or similar), it is not always trivial to get a reverse shell over TCP, not to consider a bind shell.\r\n\r\nHowever, what about UDP (commonly a DNS tunnel) or ICMP as the channel to get a reverse shell? ICMP is the focus on this tool.\r\n\r\n## Description\r\n\r\nicmpsh is a simple reverse ICMP shell with a win32 slave and a POSIX compatible master in C, Perl or Python. The main advantage over the other similar open source tools is that it does not require administrative privileges to run onto the target machine.\r\n\r\nThe tool is clean, easy and portable. The **slave (client) runs on the target Windows machine**, it is written in C and works on Windows only whereas the **master (server) can run on any platform on the attacker machine** as it has been implemented in C and Perl by [Nico Leidecker](http://www.leidecker.info/) and I have ported it to Python too, hence this GitHub fork.\r\n\r\n## Features\r\n\r\n* Open source software - primarily coded by Nico, forked by me.\r\n* Client/server architecture.\r\n* The master is portable across any platform that can run either C, Perl or Python code.\r\n* The target system has to be Windows because the slave runs on that platform only for now.\r\n* The user running the slave on the target system does not require administrative privileges.\r\n\r\n## Usage\r\n\r\n### Running the master\r\n\r\nThe master is straight forward to use. There are no extra libraries required for the C and Python versions. The Perl master however has the following dependencies:\r\n\r\n* IO::Socket\r\n* NetPacket::IP\r\n* NetPacket::ICMP\r\n\r\nWhen running the master, don't forget to disable ICMP replies by the OS. For example:\r\n```\r\nsysctl -w net.ipv4.icmp_echo_ignore_all=1\r\n```\r\n\r\nIf you miss doing that, you will receive information from the slave, but the slave is unlikely to receive commands send from the master.\r\n\r\n### Running the slave\r\n\r\nThe slave comes with a few command line options as outlined below:\r\n\r\n```\r\n-t host            host ip address to send ping requests to. This option is mandatory!\r\n\r\n-r                 send a single test icmp request containing the string \"Test1234\" and then quit. \r\n                   This is for testing the connection.\r\n\r\n-d milliseconds    delay between requests in milliseconds \r\n\r\n-o milliseconds    timeout of responses in milliseconds. If a response has not received in time, \r\n                   the slave will increase a counter of blanks. If that counter reaches a limit, the slave will quit.\r\n                   The counter is set back to 0 if a response was received.\r\n\r\n-b num             limit of blanks (unanswered icmp requests before quitting\r\n\r\n-s bytes           maximal data buffer size in bytes\r\n```\r\n\r\nIn order to improve the speed, lower the delay (*-d*) between requests or increase the size (-s) of the data buffer.\r\n\r\n## License\r\n\r\nThis source code is free software; you can redistribute it and/or modify it under the terms of the GNU Lesser General Public License as published by the Free Software Foundation; either version 2.1 of the License, or (at your option) any later version.\r\n\r\nThis library is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU Lesser General Public License for more details.\r\n\r\nYou should have received a copy of the GNU Lesser General Public License along with this library; if not, write to the Free Software Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\r\n"}, {"repo": "/postgrespro/jsquery", "language": "C", "readme_contents": "[![Build Status](https://travis-ci.org/postgrespro/jsquery.svg?branch=master)](https://travis-ci.org/postgrespro/jsquery)\n[![codecov](https://codecov.io/gh/postgrespro/jsquery/branch/master/graph/badge.svg)](https://codecov.io/gh/postgrespro/jsquery)\n[![GitHub license](https://img.shields.io/badge/license-PostgreSQL-blue.svg)](https://raw.githubusercontent.com/postgrespro/jsquery/master/LICENSE)\n\nJsQuery \u2013 json query language with GIN indexing support\n=======================================================\n\nIntroduction\n------------\n\nJsQuery \u2013 is a language to query jsonb data type, introduced in PostgreSQL\nrelease 9.4.\n\nIt's primary goal is to provide an additional functionality to jsonb\n(currently missing in PostgreSQL), such as a simple and effective way\nto search in nested objects and arrays, more comparison operators with\nindexes support. We hope, that jsquery will be eventually a part of\nPostgreSQL.\n\nJsquery is released as jsquery data type (similar to tsquery) and @@\nmatch operator for jsonb.\n\nAuthors\n-------\n\n * Teodor Sigaev <teodor@sigaev.ru>, Postgres Professional, Moscow, Russia\n * Alexander Korotkov <aekorotkov@gmail.com>, Postgres Professional, Moscow, Russia\n * Oleg Bartunov <oleg@sai.msu.su>, Postgres Professional, Moscow, Russia\n\nAvailability\n------------\n\nJsQuery is realized as an extension and not available in default PostgreSQL\ninstallation. It is available from\n[github](https://github.com/postgrespro/jsquery)\nunder the same license as\n[PostgreSQL](https://www.postgresql.org/about/licence/)\nand supports PostgreSQL 9.4+.\n\nRegards\n-------\n\nDevelopment was sponsored by [Wargaming.net](http://wargaming.net).\n\nInstallation\n------------\n\nJsQuery is PostgreSQL extension which requires PostgreSQL 9.4 or higher.\nBefore build and install you should ensure following:\n    \n * PostgreSQL version is 9.4 or higher.\n * You have development package of PostgreSQL installed or you built\n   PostgreSQL from source.\n * You have flex and bison installed on your system. JsQuery was tested on\n   flex 2.5.37-2.5.39, bison 2.7.12.\n * Your PATH variable is configured so that pg\\_config command available, or set PG_CONFIG variable.\n    \nTypical installation procedure may look like this:\n    \n    $ git clone https://github.com/postgrespro/jsquery.git\n    $ cd jsquery\n    $ make USE_PGXS=1\n    $ sudo make USE_PGXS=1 install\n    $ make USE_PGXS=1 installcheck\n    $ psql DB -c \"CREATE EXTENSION jsquery;\"\n\nJSON query language\n-------------------\n\nJsQuery extension contains `jsquery` datatype which represents whole JSON query\nas a single value (like `tsquery` does for fulltext search). The query is an\nexpression on JSON-document values.\n\nSimple expression is specified as `path binary_operator value` or\n`path unary_operator`. See following examples.\n\n * `x = \"abc\"` \u2013 value of key \"x\" is equal to \"abc\";\n * `$ @> [4, 5, \"zzz\"]` \u2013 the JSON document is an array containing values\n    4, 5 and \"zzz\";\n * `\"abc xyz\" >= 10` \u2013 value of key \"abc xyz\" is greater than or equal to 10;\n * `volume IS NUMERIC` \u2013 type of key \"volume\" is numeric.\n * `$ = true` \u2013 the whole JSON document is just a true.\n * `similar_ids.@# > 5` \u2013 similar\\_ids is an array or object of length greater\n   than 5;\n * `similar_product_ids.# = \"0684824396\"` \u2013 array \"similar\\_product\\_ids\"\n   contains string \"0684824396\".\n * `*.color = \"red\"` \u2013 there is object somewhere which key \"color\" has value\n   \"red\".\n * `foo = *` \u2013 key \"foo\" exists in object.\n\nPath selects set of JSON values to be checked using given operators. In\nthe simplest case path is just an key name. In general path is key names and\nplaceholders combined by dot signs. Path can use following placeholders:\n\n * `#` \u2013 any index of array;\n * `#N` \u2013 N-th index of array;\n * `%` \u2013 any key of object;\n * `*` \u2013 any sequence of array indexes and object keys;\n * `@#` \u2013 length of array or object, could be only used as last component of\n    path;\n * `$` \u2013 the whole JSON document as single value, could be only the whole path.\n\nExpression is true when operator is true against at least one value selected\nby path.\n\nKey names could be given either with or without double quotes. Key names\nwithout double quotes shouldn't contain spaces, start with number or concur\nwith jsquery keyword.\n\nThe supported binary operators are:\n\n * Equality operator: `=`;\n * Numeric comparison operators: `>`, `>=`, `<`, `<=`;\n * Search in the list of scalar values using `IN` operator;\n * Array comparison operators: `&&` (overlap), `@>` (contains),\n   `<@` (contained in).\n\nThe supported unary operators are:\n\n * Check for existence operator: `= *`;\n * Check for type operators: `IS ARRAY`, `IS NUMERIC`, `IS OBJECT`, `IS STRING`\n   and `IS BOOLEAN`.\n\nExpressions could be complex. Complex expression is a set of expressions\ncombined by logical operators (`AND`, `OR`, `NOT`) and grouped using braces.\n\nExamples of complex expressions are given below.\n\n * `a = 1 AND (b = 2 OR c = 3) AND NOT d = 1`\n * `x.% = true OR x.# = true`\n\nPrefix expressions are expressions given in the form path (subexpression).\nIn this case path selects JSON values to be checked using given subexpression.\nCheck results are aggregated in the same way as in simple expressions.\n\n * `#(a = 1 AND b = 2)` \u2013 exists element of array which a key is 1 and b key is 2\n * `%($ >= 10 AND $ <= 20)` \u2013 exists object key which values is between 10 and 20\n\nPath also could contain following special placeholders with \"every\" semantics:\n\n * `#:` \u2013 every indexes of array;\n * `%:` \u2013 every key of object;\n * `*:` \u2013 every sequence of array indexes and object keys.\n\nConsider following example.\n\n    %.#:($ >= 0 AND $ <= 1)\n\nThis example could be read as following: there is at least one key which value\nis array of numerics between 0 and 1.\n\nWe can rewrite this example in the following form with extra braces.\n\n    %(#:($ >= 0 AND $ <= 1))\n\nThe first placeholder `%` checks that expression in braces is true for at least\none value in object. The second placeholder `#:` checks value to be array and\nall its elements satisfy expressions in braces.\n\nWe can rewrite this example without `#:` placeholder as follows.\n\n    %(NOT #(NOT ($ >= 0 AND $ <= 1)) AND $ IS ARRAY)\n\nIn this example we transform assertion that every element of array satisfy some\ncondition to assertion that there is no one element which doesn't satisfy the\nsame condition.\n\nSome examples of using paths are given below.\n\n * `numbers.#: IS NUMERIC` \u2013 every element of \"numbers\" array is numeric.\n * `*:($ IS OBJECT OR $ IS BOOLEAN)` \u2013 JSON is a structure of nested objects\n   with booleans as leaf values.\n * `#:.%:($ >= 0 AND $ <= 1)` \u2013 each element of array is object containing\n   only numeric values between 0 and 1.\n * `documents.#:.% = *` \u2013 \"documents\" is array of objects containing at least\n   one key.\n * `%.#: ($ IS STRING)` \u2013 JSON object contains at least one array of strings.\n * `#.% = true` \u2013 at least one array element is objects which contains at least\n   one \"true\" value.\n\nUsage of path operators and braces need some explanation. When same path\noperators are used multiple times they may refer different values while you can\nrefer same value multiple time by using braces and `$` operator. See following\nexamples.\n\n * `# < 10 AND # > 20` \u2013 exists element less than 10 and exists another element\n   greater than 20.\n * `#($ < 10 AND $ > 20)` \u2013 exists element which both less than 10 and greater\n   than 20 (impossible).\n * `#($ >= 10 AND $ <= 20)` \u2013 exists element between 10 and 20.\n * `# >= 10 AND # <= 20` \u2013 exists element great or equal to 10 and exists\n   another element less or equal to 20. Query can be satisfied by array with\n   no elements between 10 and 20, for instance [0,30].\n\nSame rules apply when you search inside objects and branchy structures.\n\nType checking operators and \"every\" placeholders are useful for document\nschema validation. JsQuery matchig operator `@@` is immutable and can be used\nin CHECK constraint. See following example.\n\n```sql\nCREATE TABLE js (\n    id serial,\n    data jsonb,\n    CHECK (data @@ '\n        name IS STRING AND\n        similar_ids.#: IS NUMERIC AND\n        points.#:(x IS NUMERIC AND y IS NUMERIC)'::jsquery));\n```\n\nIn this example check constraint validates that in \"data\" jsonb column:\nvalue of \"name\" key is string, value of \"similar_ids\" key is array of numerics,\nvalue of \"points\" key is array of objects which contain numeric values in\n\"x\" and \"y\" keys.\n\nSee our\n[pgconf.eu presentation](http://www.sai.msu.su/~megera/postgres/talks/pgconfeu-2014-jsquery.pdf)\nfor more examples.\n\nGIN indexes\n-----------\n\nJsQuery extension contains two operator classes (opclasses) for GIN which\nprovide different kinds of query optimization.\n\n * jsonb\\_path\\_value\\_ops\n * jsonb\\_value\\_path\\_ops\n\nIn each of two GIN opclasses jsonb documents are decomposed into entries. Each\nentry is associated with particular value and it's path. Difference between\nopclasses is in the entry representation, comparison and usage for search\noptimization.\n\nFor example, jsonb document\n`{\"a\": [{\"b\": \"xyz\", \"c\": true}, 10], \"d\": {\"e\": [7, false]}}`\nwould be decomposed into following entries:\n\n * \"a\".#.\"b\".\"xyz\"\n * \"a\".#.\"c\".true\n * \"a\".#.10\n * \"d\".\"e\".#.7\n * \"d\".\"e\".#.false\n\nSince JsQuery doesn't support search in particular array index, we consider\nall array elements to be equivalent. Thus, each array element is marked with\nsame `#` sign in the path.\n\nMajor problem in the entries representation is its size. In the given example\nkey \"a\" is presented three times. In the large branchy documents with long\nkeys size of naive entries representation becomes unreasonable. Both opclasses\naddress this issue but in a slightly different way.\n\n### jsonb\\_path\\_value\\_ops\n\njsonb\\_path\\_value\\_ops represents entry as pair of path hash and value.\nFollowing pseudocode illustrates it.\n\n    (hash(path_item_1.path_item_2. ... .path_item_n); value)\n\nIn comparison of entries path hash is the higher part of entry and value is\nits lower part. This determines the features of this opclass. Since path\nis hashed and it is higher part of entry we need to know the full path to\nthe value in order to use it for search. However, once path is specified\nwe can use both exact and range searches very efficiently.\n\n### jsonb\\_value\\_path\\_ops\n\njsonb\\_value\\_path\\_ops represents entry as pair of value and bloom filter\nof path.\n\n    (value; bloom(path_item_1) | bloom(path_item_2) | ... | bloom(path_item_n))\n\nIn comparison of entries value is the higher part of entry and bloom filter of\npath is its lower part. This determines the features of this opclass. Since\nvalue is the higher part of entry we can perform only exact value search\nefficiently. Range value search is possible as well but we would have to\nfilter all the the different paths where matching values occur. Bloom filter\nover path items allows index usage for conditions containing `%` and `*` in\ntheir paths.\n\n### Query optimization\n\nJsQuery opclasses perform complex query optimization. Thus it's valuable for\ndeveloper or administrator to see the result of such optimization.\nUnfortunately, opclasses aren't allowed to do any custom output to the\nEXPLAIN. That's why JsQuery provides following functions which allows to see\nhow particular opclass optimizes given query.\n\n * gin\\_debug\\_query\\_path\\_value(jsquery) \u2013 for jsonb\\_path\\_value\\_ops\n * gin\\_debug\\_query\\_value\\_path(jsquery) \u2013 for jsonb\\_value\\_path\\_ops\n\nResult of these functions is a textual representation of query tree which\nleafs are GIN search entries. Following examples show different results of\nquery optimization by different opclasses.\n\n    # SELECT gin_debug_query_path_value('x = 1 AND (*.y = 1 OR y = 2)');\n     gin_debug_query_path_value\n    ----------------------------\n     x = 1 , entry 0           +\n\n    # SELECT gin_debug_query_value_path('x = 1 AND (*.y = 1 OR y = 2)');\n     gin_debug_query_value_path\n    ----------------------------\n     AND                       +\n       x = 1 , entry 0         +\n       OR                      +\n         *.y = 1 , entry 1     +\n         y = 2 , entry 2       +\n\nUnfortunately, jsonb have no statistics yet. That's why JsQuery optimizer has\nto do imperative decision while selecting conditions to be evaluated using\nindex. This decision is made by assumtion that some condition types are less\nselective than others. Optimizer divides conditions into following selectivity\nclass (listed by descending of selectivity).\n\n 1. Equality (x = c)\n 2. Range (c1 < x < c2)\n 3. Inequality (x > c)\n 4. Is (x is type)\n 5. Any (x = \\*)\n\nOptimizer evades index evaluation of less selective conditions when possible.\nFor example, in the `x = 1 AND y > 0` query `x = 1` is assumed to be more\nselective than `y > 0`. That's why index isn't used for evaluation of `y > 0`.\n\n    # SELECT gin_debug_query_path_value('x = 1 AND y > 0');\n     gin_debug_query_path_value\n    ----------------------------\n     x = 1 , entry 0           +\n\nWith lack of statistics decisions made by optimizer can be inaccurate. That's\nwhy JsQuery supports hints. Comments `/*-- index */` and `/*-- noindex */`\nplaced in the conditions forces optimizer to use and not use index\ncorrespondingly.\n\n    SELECT gin_debug_query_path_value('x = 1 AND y /*-- index */ > 0');\n     gin_debug_query_path_value\n    ----------------------------\n     AND                       +\n       x = 1 , entry 0         +\n       y > 0 , entry 1         +\n\n    SELECT gin_debug_query_path_value('x /*-- noindex */ = 1 AND y > 0');\n     gin_debug_query_path_value\n     ----------------------------\n      y > 0 , entry 0           +\n\nContribution\n------------\n\nPlease, notice, that JsQuery is still under development and while it's\nstable and tested, it may contains some bugs. Don't hesitate to raise\n[issues at github](https://github.com/postgrespro/jsquery/issues) with your\nbug reports.\n\nIf you're lacking of some functionality in JsQuery and feeling power to\nimplement it then you're welcome to make pull requests.\n\n"}, {"repo": "/marijnh/Eloquent-JavaScript", "language": "JavaScript", "readme_contents": "# Eloquent JavaScript\n\nThese are the sources used to build the third edition of Eloquent\nJavaScript (https://eloquentjavascript.net).\n\nFeedback welcome, in the form of issues and pull requests.\n\n## Building\n\nThis builds the HTML output in `html/`, where `make` is GNU make:\n\n    npm install\n    make html\n\nTo build the PDF file (don't bother trying this unless you really need\nit, since this list has probably bitrotted again and getting all this\nset up is a pain):\n\n    apt-get install texlive texlive-xetex fonts-inconsolata fonts-symbola texlive-lang-chinese inkscape\n    make book.pdf\n\n## Translating\n\nTranslations are very much welcome. The license this book is published\nunder allows non-commercial derivations, which includes open\ntranslations. If you do one, let me know, and I'll add a link to the\nwebsite.\n\nA note of caution though: This text consists of about 130 000 words,\nthe paper book is 400 pages. That's a lot of text, which will take a\nlot of time to translate.\n\nIf that doesn't scare you off, the recommended way to go about a\ntranslation is:\n\n - Fork this repository on GitHub.\n\n - Create an issue on the repository describing your plan to translate.\n\n - Translate the `.md` files in your fork. These are\n   [CommonMark](https://commonmark.org/) formatted, with a few\n   extensions. You may consider omitting the index terms (indicated\n   with double parentheses and `{{index ...}}` syntax) from your\n   translation, since that's mostly relevant for print output.\n\n - Publish somewhere online or ask me to host the result.\n\nDoing this in public, and creating an issue that links to your work,\nhelps avoid wasted effort, where multiple people start a translation\nto the same language (and possibly never finish it). (Since\ntranslations have to retain the license, it is okay to pick up someone\nelse's translation and continue it, even when they have vanished from\nthe internet.)\n"}, {"repo": "/AllAlgorithms/cpp", "language": "C++", "readme_contents": "\n<!-- Please do not edit this file | This file is authomatically generated by ~/scripts/formatter.js -->\n<div align=\"center\">\n<br>\n<br>\n<br>\n<br>\n<img width=\"400\" height=\"270\" src=\"https://cdn.jsdelivr.net/npm/@programming-languages-logos/cpp@0.0.2/cpp.svg\">\n<br>\n<br>\n<br>\n<br>\n<br>\n<br>\n<img src=\"https://cdn.abranhe.com/projects/algorithms/algorithms.svg\" width=\"400px\">\n<br>\n<br>\n<p>All \u25b2lgorithms implemented in C++</p>\n<a href=\"https://allalgorithms.com\"><img src=\"https://cdn.abranhe.com/projects/algorithms/badge.svg\"></a>\n<a href=\"https://github.com/abranhe/algorithms/blob/master/license\"><img src=\"https://img.shields.io/github/license/abranhe/algorithms.svg\" /></a>\n<a href=\"https://cash.me/$abranhe\"><img src=\"https://cdn.abranhe.com/badges/cash-me.svg\"></a>\n<a href=\"https://patreon.com/abranhe\"><img src=\"https://cdn.abranhe.com/badges/patreon.svg\" /></a>\n<a href=\"https://paypal.me/abranhe/10\"><img src=\"https://cdn.abranhe.com/badges/paypal.svg\" /></a>\n<a href=\"https://travis-ci.org/AllAlgorithms/cpp\"><img src=\"https://img.shields.io/travis/AllAlgorithms/cpp.svg?label=%E2%96%B2%20style\" /></a>\n<br>\n<br>\n<a href=\"https://allalgorithms.com\"><code>allalgorithms.com</code></a>\n</div>\n\n<!-- Please do not edit this file | This file is authomatically generated by ~/scripts/formatter.js -->\n\n## Contents\n\nYou can find the All \u25b2lgorithms categories at [algorithms.com/categories](https://algorithms.com/categories)\n\n - [Artificial intelligence](#artificial-intelligence)\n - [Backtracking](#backtracking)\n - [Bit manipulation](#bit-manipulation)\n - [Cellular automaton](#cellular-automaton)\n - [Computational geometry](#computational-geometry)\n - [Cryptography](#cryptography)\n - [Data structures](#data-structures)\n - [Divide and conquer](#divide-and-conquer)\n - [Dynamic programming](#dynamic-programming)\n - [Gaming theory](#gaming-theory)\n - [Graphs](#graphs)\n - [Greedy algorithms](#greedy-algorithms)\n - [Math](#math)\n - [Networking](#networking)\n - [Numerical analysis](#numerical-analysis)\n - [Online challenges](#online-challenges)\n - [Randomized algorithms](#randomized-algorithms)\n - [Serches](#serches)\n - [Selections](#selections)\n - [Sorting](#sorting)\n - [Strings](#strings)\n - [No category](#no-category)\n\n## Artificial intelligence\n\n - [Togasat](artificial-intelligence/togasat.cpp)\n\n## Backtracking\n\n - [Crossword puzzle](backtracking/crossword_puzzle.cpp)\n\n## Data structures\n\n - [Pairs with difference k](data-structures/hashmaps/pairs_with_difference_k.cpp)\n - [Largest rectangle area](data-structures/largest_rectangle_area.cpp)\n - [Linkedlist adt](data-structures/linkedlist/linkedlist_adt.cpp)\n - [Circular buffer](data-structures/queue/circular_buffer.cpp)\n - [Queue](data-structures/queue/queue.cpp)\n - [Stack](data-structures/stack/stack.cpp)\n\n## Dynamic programming\n\n - [Coin change](dynamic-programming/coin_change.cpp)\n - [Edit distance](dynamic-programming/edit_distance.cpp)\n - [Fibonacci number](dynamic-programming/fibonacci_number.cpp)\n - [Knapsack](dynamic-programming/knapsack.cpp)\n - [Lcs](dynamic-programming/lcs.cpp)\n - [Lis](dynamic-programming/lis.cpp)\n - [Longest path](dynamic-programming/longest_path.cpp)\n - [Matrix chain multiplication](dynamic-programming/matrix_chain_multiplication.cpp)\n - [Rod cutting](dynamic-programming/rod_cutting.cpp)\n - [Ways to cover](dynamic-programming/ways_to_cover.cpp)\n\n## Graphs\n\n - [Bellman ford](graphs/bellman_ford.cpp)\n - [Bfs](graphs/bfs.cpp)\n - [Count diconnected components](graphs/count_diconnected_components.cpp)\n - [Dfs](graphs/dfs.cpp)\n - [Dijkstra](graphs/dijkstra.cpp)\n - [Floyd warshall](graphs/floyd_warshall.cpp)\n - [Prims adjacency list](graphs/prims_adjacency_list.cpp)\n - [Toposort](graphs/toposort.cpp)\n\n## Math\n\n - [All factors of a numbe r](math/all_factors_of_a_numbe_r.cpp)\n - [Armstrong number](math/armstrong_number.cpp)\n - [Bshuffll](math/bshuffll.cpp)\n - [Chefres](math/chefres.cpp)\n - [Collatz](math/collatz.cpp)\n - [Euclids gcd](math/euclids_gcd.cpp)\n - [Eulers totient](math/eulers_totient.cpp)\n - [Factorial loop](math/factorial_loop.cpp)\n - [Factorial](math/factorial.cpp)\n - [Gcd of array](math/gcd_of_array.cpp)\n - [Hoax no](math/hoax_no.cpp)\n - [Kadence](math/kadence.cpp)\n - [Lcm of array](math/lcm_of_array.cpp)\n - [Lucky numbers](math/lucky_numbers.cpp)\n - [Magic square](math/magic_square.cpp)\n - [Modular exponentiation](math/modular_exponentiation.cpp)\n - [Nth fibonacci using goldenratio](math/nth_fibonacci_using_goldenratio.cpp)\n - [Pascals triangle](math/pascals_triangle.cpp)\n - [Sieve of eratosthenes](math/sieve_of_eratosthenes.cpp)\n - [Slicker algorithm](math/slicker_algorithm.cpp)\n - [Sphenic n o](math/sphenic_n_o.cpp)\n - [T ermo conv](math/t_ermo_conv.cpp)\n\n## Searches\n\n - [Binary search](searches/binary_search.cpp)\n - [Exponential search](searches/exponential_search.cpp)\n - [Jump search](searches/jump_search.cpp)\n - [Linear search](searches/linear_search.cpp)\n - [Ternary search](searches/ternary_search.cpp)\n\n## Sorting\n\n - [Bogo sort](sorting/bogo_sort.cpp)\n - [Bubble sort](sorting/bubble_sort.cpp)\n - [Counting sort](sorting/counting_sort.cpp)\n - [Gnome sort](sorting/gnome_sort.cpp)\n - [Heap sort without vectors](sorting/heap_sort_without_vectors.cpp)\n - [Heap sort](sorting/heap_sort.cpp)\n - [Insertion sort](sorting/insertion_sort.cpp)\n - [Merge sort](sorting/merge_sort.cpp)\n - [Quick sort](sorting/quick_sort.cpp)\n - [Radix sort](sorting/radix_sort.cpp)\n - [Rank sort](sorting/rank_sort.cpp)\n - [Selection sort](sorting/selection_sort.cpp)\n - [Shaker sort](sorting/shaker_sort.cpp)\n - [Shell sort](sorting/shell_sort.cpp)\n - [Sort vector](sorting/sort_vector.cpp)\n - [Stooge sort](sorting/stooge_sort.cpp)\n - [Tree sort](sorting/tree_sort.cpp)\n\n## Strings\n\n - [Anagram check](strings/anagram_check.cpp)\n - [Lexicographic ranking](strings/lexicographic_ranking.cpp)\n - [Longest palindrome subset](strings/longest_palindrome_subset.cpp)\n - [Naive search](strings/naive_search.cpp)\n - [Permutations of string](strings/permutations_of_string.cpp)\n - [Print duplicate string](strings/print_duplicate_string.cpp)\n - [Rabin carp](strings/rabin_carp.cpp)\n - [Rabin karp](strings/rabin_karp.cpp)\n - [Remove adjacent duplicates](strings/remove_adjacent_duplicates.cpp)\n - [Remove duplicates](strings/remove_duplicates.cpp)\n - [Reverse string](strings/reverse_string.cpp)\n - [Z algorithm](strings/z_algorithm.cpp)\n\n<!-- Please do not edit this file | This file is authomatically generated by ~/scripts/formatter.js -->\n\n## Maintainers\n\n|[![1][1-avatar]][1]|[![2][2-avatar]][2]|\n| :-: | :-: |\n| [Carlos Abraham][1] | [Christian Bender][2] |\n\n## License\n\nThis work is released under [MIT License][MIT]\n\n[![MIT IMG][MIT-logo]][MIT]\n\nTo the extent possible under law, [Carlos Abraham](https://go.abranhe.com/github) has waived all copyright and related or neighboring rights to this work.\n\n<div align=\"center\">\n\t<a href=\"https://github.com/abranhe/algorithms\">\n\t\t<img src=\"https://cdn.abranhe.com/projects/algorithms/logo.svg\" width=\"50px\">\n\t</a>\n  <br>\n</div>\n\n[MIT]: https://github.com/abranhe/algorithms/blob/master/license\n[MIT-logo]: https://cdn.abranhe.com/projects/algorithms/mit-license.png\n\n<!-- Maintainers -->\n[1]: https://github.com/abranhe\n[1-avatar]: https://avatars3.githubusercontent.com/u/21347264?s=50\n[2]: https://github.com/christianbender\n[2-avatar]: https://avatars3.githubusercontent.com/u/23243382?s=50\n"}, {"repo": "/saffire/saffire", "language": "C", "readme_contents": "Saffire\n=======\n\n[![Build Status](https://travis-ci.org/saffire/saffire.png)](https://travis-ci.org/saffire/saffire)\n[![Gitter](https://badges.gitter.im/Join%20Chat.svg)](https://gitter.im/saffire/saffire?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge)\n\nA new OO programming scripting language, based on primarily Python, PHP and Ruby. Its primary features:\n\n- interpreted language\n- dynamically, strong typed\n- everything is an object\n- full unicode support\n- method + operator overloading\n\nMore information can be found at our website: http://www.saffire-lang.org and we're on IRC (freenode) as well, join us\nin channel \\#saffire.\n\n\nContributing:\n-------------\nWe LOVE new contributors. Please join the \\#saffire channel at IRC (freenode) for more information about contributing\nto the project. There is no need have deep knowledge of C or knowing lots about compilers and stuff. There are lots of\nother things that needs to be done and all the help on every level is welcome! Also, we love to meet new people, so\ncome and say hi to us.\n\n\nInstalling Saffire\n------------------\nThere are two ways to install Saffire. The easy way, and the hard way :) The easy way consists of setting up a\nvirtualbox environment that will automatically install everything you need through the help of vagrant. The hard way,\nwell, you do everything yourself. Please read the information in the [installation file](documentation/Installation.md)\non how to install Saffire.\n\n\nUsing Saffire\n-------------\nSaffire is under construction and experience heavy redesign on occasion for as long as we haven't hit a stable release.\nObviously, the closer we get, the less things will change and the current base is getting pretty solid fortunately.\nPlease checkout the [usage documentation](documentation/Usage.md) file in order to figure out how to start with Saffire.\n"}, {"repo": "/Computing-Language-Utility/CLU", "language": "C++", "readme_contents": "The Computing Language Utility (CLU) is a lightweight API designed to help programmers explore, learn, and rapidly prototype programs with OpenCL.  This API reduces the complexity associated with initializing OpenCL devices, contexts, kernels and parameters, etc. while preserving the ability to drop down to the lower level OpenCL API at will when programmers wants to get their hands dirty. The CLU release includes an open source implementation along with documentation and samples that demonstrate how to use CLU in real applications.  It has been tested on Windows 7 with Visual Studio  and OS X.\n"}, {"repo": "/munificent/finch", "language": "C++", "readme_contents": "Finch is a simple bytecode interpreted, purely object-oriented,\nprototype-based, dynamically-typed programming language. It's mostly\ninspired by Smalltalk, Self, and Javascript.\n\nIt is written in C++ with a hand-written lexer and parser. It has\nminimal dependencies. I want Finch to be:\n\n*   Syntactically expressive yet minimal. Your code should look beautiful and\n    do what you want.\n\n*   An example of a small, clean C++ codebase for an interpreter. If you can\n    read C++ and want to learn more about programming languages, I hope Finch's\n    code will be a good primer.\n\n*   A language in the Smalltalk family that's friendly to people coming from a\n    text file and curly brace background.\n\n*   A minimal prototype-based dynamic language. I think prototypes are a really\n    cool paradigm, but Self goes too far, and Javascript doesn't go far enough.\n\n*   Easily embeddable in other applications. I don't know if Finch ever will\n    have real use, but if it does, it will likely be as a configuration or\n    scripting language within a larger application, much like Lua.\n\n\nA Taste of the Language\n-----------------------\n\nHere's a little example to get you going. This little program doesn't\ndraw, but it will tell you what turns to make to draw a dragon curve:\n\n    // create an object and put it in a variable \"dragon\"\n    dragon <- [\n      // define a \"trace:\" method for outputting the series of left and\n      // right turns needed to draw a dragon curve.\n      trace: depth {\n        self traceDepth: depth turn: \"R\"\n        writeLine: \"\" // end the line\n      }\n\n      // the main recursive method\n      traceDepth: n turn: turn {\n        if: n > 0 then: {\n          self traceDepth: n - 1 turn: \"R\"\n          write: turn\n          self traceDepth: n - 1 turn: \"L\"\n        }\n      }\n    ]\n\n    // now lets try it\n    dragon trace: 5\n\n\nGetting Started\n---------------\n\nFinch lives on github here: https://github.com/munificent/finch\n\nTo play around with it, sync it down. Finch uses GYP to generate projects or\nmakefiles for your platform, which you then build to get an executable.\n\n1. Download GYP from: http://code.google.com/p/gyp/\n2. Clone the finch repo from github.\n3. In a terminal/command prompt, navigate to the root finch/ directory.\n4. Run GYP on this file: `<path to gyp>/gyp --depth=1`\n   Where `<path to gyp>` is wherever you downloaded GYP to in step 1.\n   This should spit out a project/makefile in the root directory for your\n   platform.\n5. Open that project in XCode or VS and build, or build the makefile.\n6. Ta-da! You should now have a Finch executable under a build/ directory.\n\nLet me know if you run into any problems.\n\n\nRunning Finch\n-------------\n\nOnce you've got it built and running, you'll be at the main\ninterpreter prompt. Finch is a command-line app. If you run it without\nany arguments, it drops you into a REPL, an interactive session. You\ncan type in chunks of code and it will interpret them immediately. (If\nyou run it with a single argument, it expects that to be a path to a\n.fin script, and it will load and run that script.)\n\nOnce you're in the REPL, you can load and execute a script using\nload:. The path must be relative to where the executable is right now (lame!).\nYou can run the tests like this:\n\n    >> load: \"../../test/test.fin\"\n\n\nWhere to Go from Here\n---------------------\n\nYou should be good to start hacking some Finch code now. There is some\ndocumentation here:\n\n* http://finch.stuffwithstuff.com\n* http://journal.stuffwithstuff.com/category/finch/\n\nIf you have any questions or comments, holler at me."}, {"repo": "/bvinc/go-sqlite-lite", "language": "C", "readme_contents": "[![GoDoc](https://godoc.org/github.com/bvinc/go-sqlite-lite/sqlite3?status.svg)](https://godoc.org/github.com/bvinc/go-sqlite-lite/sqlite3)\n[![Build Status](https://travis-ci.com/bvinc/go-sqlite-lite.svg?branch=master)](https://travis-ci.com/bvinc/go-sqlite-lite)\n[![Build status](https://ci.appveyor.com/api/projects/status/xk6fpk23wb5ppdhx?svg=true)](https://ci.appveyor.com/project/bvinc/go-sqlite-lite)\n[![Coverage Status](https://coveralls.io/repos/github/bvinc/go-sqlite-lite/badge.svg?branch=master)](https://coveralls.io/github/bvinc/go-sqlite-lite?branch=master)\n[![Go Report Card](https://goreportcard.com/badge/github.com/bvinc/go-sqlite-lite)](https://goreportcard.com/report/github.com/bvinc/go-sqlite-lite)\n\n# go-sqlite-lite\n\ngo-sqlite-lite is a SQLite driver for the Go programming language.  It is designed with the following goals in mind.\n\n* **Lightweight** - Most methods should be little more than a small wrapper around SQLite C functions.\n* **Performance** - Where possible, methods should be available to allow for the highest performance possible.\n* **Understandable** - You should always know what SQLite functions are being called and in what order.\n* **Unsurprising** - Connections, PRAGMAs, transactions, bindings, and stepping should work out of the box exactly as you would expect with SQLite.\n* **Debuggable** - When you encounter a SQLite error, the SQLite documentation should be relevant and relatable to the Go code.\n* **Ergonomic** - Where it makes sense, convenient compound methods should exist to make tasks easy and to conform to Go standard interfaces.\n\nMost database drivers include a layer to work nicely with the Go `database/sql` interface, which introduces connection pooling and behavior differences from pure SQLite.  This driver does not include a `database/sql` interface.\n\n## Releases\n\n* 2019-05-01 **v0.6.1** - Bug fixes, authorizer callback support\n* 2019-05-01 **v0.6.0** - SQLite version 3.28.0\n* 2019-02-05 **v0.5.0** - SQLite version 3.26.0\n* 2018-10-30 **v0.4.2** - Better error messages from SQLite\n* 2018-10-11 **v0.4.1** - Fixed an issue with new go 1.11 modules\n* 2018-09-29 **v0.4.0** - SQLite version 3.25.2.  Add support for the Session extension\n* 2018-09-16 **v0.3.1** - Forgot to update sqlite3.h\n* 2018-09-16 **v0.3.0** - SQLite version 3.25.0\n* 2018-09-14 **v0.2.0** - Proper error and NULL handling on Column* methods.  Empty blobs and empty strings are now distinct from NULL in all cases.  A nil byte slice is interpreted as NULL for binding purposes as well as Column* methods.\n* 2018-09-01 **v0.1.2** - Added Column methods to Stmt, and WithTx methods to Conn\n* 2018-08-25 **v0.1.1** - Fixed linking on some Linux systems\n* 2018-08-21 **v0.1.0** - SQLite version 3.24.0\n\n## Getting started\n\n```go\nimport \"github.com/bvinc/go-sqlite-lite/sqlite3\"\n```\n\n### Acquiring a connection\n```go\nconn, err := sqlite3.Open(\"mydatabase.db\")\nif err != nil {\n\t...\n}\ndefer conn.Close()\n\n// It's always a good idea to set a busy timeout\nconn.BusyTimeout(5 * time.Second)\n```\n\n### Executing SQL\n```go\nerr = conn.Exec(`CREATE TABLE student(name TEXT, age INTEGER)`)\nif err != nil {\n\t...\n}\n// Exec can optionally bind parameters\nerr = conn.Exec(`INSERT INTO student VALUES (?, ?)`, \"Bob\", 18)\nif err != nil {\n\t...\n}\n```\n\n### Using Prepared Statements\n```go\nstmt, err := conn.Prepare(`INSERT INTO student VALUES (?, ?)`)\nif err != nil {\n\t...\n}\ndefer stmt.Close()\n\n// Bind the arguments\nerr = stmt.Bind(\"Bill\", 18)\nif err != nil {\n\t...\n}\n// Step the statement\nhasRow, err := stmt.Step()\nif err != nil {\n\t...\n}\n// Reset the statement\nerr = stmt.Reset()\nif err != nil {\n\t...\n}\n```\n\n### Using Prepared Statements Conveniently\n```go\nstmt, err := conn.Prepare(`INSERT INTO student VALUES (?, ?)`)\nif err != nil {\n\t...\n}\ndefer stmt.Close()\n\n// Exec binds arguments, steps the statement to completion, and always resets the statement\nerr = stmt.Exec(\"John\", 19)\nif err != nil {\n\t...\n}\n```\n\n### Using Queries Conveniently\n```go\n// Prepare can prepare a statement and optionally also bind arguments\nstmt, err := conn.Prepare(`SELECT name, age FROM student WHERE age = ?`, 18)\nif err != nil {\n\t...\n}\ndefer stmt.Close()\n\nfor {\n\thasRow, err := stmt.Step()\n\tif err != nil {\n\t\t...\n\t}\n\tif !hasRow {\n\t\t// The query is finished\n\t\tbreak\n\t}\n\n\t// Use Scan to access column data from a row\n\tvar name string\n\tvar age int\n\terr = stmt.Scan(&name, &age)\n\tif err != nil {\n\t\t...\n\t}\n\tfmt.Println(\"name:\", name, \"age:\", age)\n}\n// Remember to Reset the statement if you would like to Bind new arguments and reuse the prepared statement\n```\n\n### Getting columns that might be NULL\nScan can be convenient to use, but it doesn't handle NULL values.  To get full control of column values, there are column methods for each type.\n```go\nname, ok, err := stmt.ColumnText(0)\nif err != nil {\n\t// Either the column index was out of range, or SQLite failed to allocate memory\n\t...\n}\nif !ok {\n\t// The column was NULL\n}\n\nage, ok, err := stmt.ColumnInt(1)\nif err != nil {\n\t// Can only fail if the column index is out of range\n\t...\n}\nif !ok {\n\t// The column was NULL\n}\n```\n\n`ColumnBlob` returns a nil slice in the case of NULL.\n```go\nblob, err := stmt.ColumnBlob(i)\nif err != nil {\n\t// Either the column index was out of range, or SQLite failed to allocate memory\n\t...\n}\nif blob == nil {\n\t// The column was NULL\n}\n```\n\n\n\n### Using Transactions\n```go\n// Equivalent to conn.Exec(\"BEGIN\")\nerr := conn.Begin()\nif err != nil {\n\t...\n}\n\n// Do some work\n...\n\n// Equivalent to conn.Exec(\"COMMIT\")\nerr = conn.Commit()\nif err != nil {\n\t...\n}\n```\n\n### Using Transactions Conveniently\n\nWith error handling in Go, it can be pretty inconvenient to ensure that a transaction is rolled back in the case of an error.  The `WithTx` method is provided, which accepts a function of work to do inside of a transaction.  `WithTx` will begin the transaction and call the function.  If the function returns an error, the transaction will be rolled back.  If the function succeeds, the transaction will be committed.  `WithTx` can be a little awkward to use, but it's necessary.  For example:\n\n```go\nerr := conn.WithTx(func() error {\n\treturn insertStudents(conn)\n})\nif err != nil {\n\t...\n}\n\nfunc insertStudents(conn *sqlite3.Conn) error {\n\t...\n}\n```\n\n## Advanced Features\n* Binding parameters to statements using SQLite named parameters.\n* SQLite Blob Incremental IO API.\n* SQLite Online Backup API.\n* SQLite Session extension.\n* Supports setting a custom busy handler\n* Supports callback hooks on commit, rollback, and update.\n* Supports setting compile-Time authorization callbacks.\n* If shared cache mode is enabled and one statement receives a `SQLITE_LOCKED` error, the SQLite [unlock_notify](https://sqlite.org/unlock_notify.html) extension is used to transparently block and try again when the conflicting statement finishes.\n* Compiled with SQLite support for JSON1, RTREE, FTS5, GEOPOLY, STAT4, and SOUNDEX.\n* Compiled with SQLite support for OFFSET/LIMIT on UPDATE and DELETE statements.\n* RawString and RawBytes can be used to reduce copying between Go and SQLite.  Please use with caution.\n\n## Credit\nThis project began as a fork of https://github.com/mxk/go-sqlite/\n\n## FAQ\n\n* **Why is there no `database/sql` interface?**\n\nIf a `database/sql` interface is required, please use https://github.com/mattn/go-sqlite3 .  In my experience, using a `database/sql` interface with SQLite is painful.  Connection pooling causes unnecessary overhead and weirdness.  Transactions using `Exec(\"BEGIN\")` don't work as expected.  Your connection does not correspond to SQLite's concept of a connection.  PRAGMA commands do not work as expected.  When you hit SQLite errors, such as locking or busy errors, it's difficult to discover why since you don't know which connection received which SQL and in what order.\n\n* **What are the differences between this driver and the mxk/go-sqlite driver?**\n\nThis driver was forked from `mxk/go-sqlite-driver`.  It hadn't been maintained in years and used an ancient version of SQLite.  A large number of features were removed, reworked, and renamed.  A lot of smartness and state was removed.  It is now much easier to upgrade to newer versions of SQLite since the `codec` feature was removed.  The behavior of methods now lines up closely with the behavior of SQLite's C API.\n\n* **What are the differences between this driver and the crawshaw/sqlite driver?**\n\nThe crawshaw driver is pretty well thought out and solves a lot of the same problems as this\ndriver.  There are a few places where our philosophies differ.  The crawshaw driver defaults (when flags of 0 are given) to SQLite shared cache mode and WAL mode.  The default WAL synchronous mode is changed.  Prepared statements are transparently cached.  Connection pools are provided.  I would be opposed to making most of these changes to this driver.  I would like this driver to provide a default, light, and unsurprising SQLite experience.\n\n* **Are finalizers provided to automatically close connections and statements?**\n\nNo finalizers are used in this driver.  You are responsible for closing connections and statements.  While I mostly agree with finalizers for cleaning up most accidental resource leaks, in this case, finalizers may fix errors such as locking errors while debugging only to find that the code works unreliably in production.  Removing finalizers makes the behavior consistent.\n\n* **Is it thread safe?**\n\ngo-sqlite-lite is as thread safe as SQLite.  SQLite with this driver is compiled with `-DSQLITE_THREADSAFE=2` which is **Multi-thread** mode.  In this mode, SQLite can be safely used by multiple threads provided that no single database connection is used simultaneously in two or more threads.  This applies to goroutines.  A single database connection should not be used simultaneously between two goroutines.\n\nIt is safe to use separate connection instances concurrently, even if they are accessing the same database file. For example:\n```go\n// ERROR (without any extra synchronization)\nc, _ := sqlite3.Open(\"sqlite.db\")\ngo use(c)\ngo use(c)\n```\n```go\n// OK\nc1, _ := sqlite3.Open(\"sqlite.db\")\nc2, _ := sqlite3.Open(\"sqlite.db\")\ngo use(c1)\ngo use(c2)\n```\n\nConsult the SQLite documentation for more information.\n\nhttps://www.sqlite.org/threadsafe.html\n\n* **How do I pool connections for handling HTTP requests?**\n\nOpening new connections is cheap and connection pooling is generally unnecessary for SQLite.  I would recommend that you open a new connection for each request that you're handling.  This ensures that each request is handled separately and the normal rules of SQLite database/table locking apply.\n\nIf you've decided that pooling connections provides you with an advantage, it would be outside the scope of this package and something that you would need to implement and ensure works as needed.\n\n## License\nThis project is licensed under the BSD license.\n\n"}, {"repo": "/gtownsend/icon", "language": "C", "readme_contents": "README file for Icon Version 9.5.1+Git\n\nThis directory contains an implementation of the Icon programming language.\nFor documentation, see these HTML files:\n\n    doc/docguide.htm  documentation guide\n    doc/relnotes.htm  release notes\n    doc/macintosh.htm the Macintosh port\n    doc/cygwin.htm    the Cygwin port\n    doc/faq.htm       frequently asked questions about Icon\n    doc/install.htm   installation instructions  (for binary releases)\n    doc/build.htm     build instructions         (for source releases)\n\nMan pages showing how to run Icon are in:\n    man/man1/icon.1   man(1) page for icon\n    man/man1/icont.1  man(1) page for icont\n\nThis material is in the public domain.  You may use and copy this material\nfreely.  This privilege extends to modifications, although any modified\nversion of this system given to a third party should clearly identify your\nmodifications as well as the original source.\n\nThe responsibility for the use of this material resides entirely with you.\nWe make no warranty of any kind concerning this material, nor do we make\nany claim as to the suitability of Icon for any application.\n\nFor more information, see the Icon website:\n    www.cs.arizona.edu/icon\n"}, {"repo": "/ErisBlastar/cplusequality", "language": "C++", "readme_contents": "  ![FSF](http://i.imgur.com/ZhTU8r3.png)\n  ![C-plus-Equality](http://i.imgur.com/Ygq1Pch.png)\n\nA project of the [Feminist Software Foundation](http://feministsoftwarefoundation.org/).  Feminist software is a cornerstone of any modern free society. We build this foundation.\n\n**Trigger Warning, this repository uses satire and sarcasm and other types of humor that could trigger Feminazis into rage fits. Maintainer of this repository was gone for a while due to being source code raped by feminists who lack a sense of humor. Which is ironic as this language was written for feminists by women. We are trying to help out women and feminists to have a programming language not controled by the capitalist patricarchy and men.**\n\nNow hosted on BitBucket, as **[GitHub proves to be too misogynistic to support a feminist programming language](https://github.com/FeministSoftwareFoundation/C-plus-Equality)**.\n\nC+=\n===============\n\n**C+=** (pronounced either *C-plus-Equality*, or *See Equality*) is a feminist programming language, created to smash the toxic Patriarchy that is inherent in and that permeates all current computer programming languages.\n\n**Note: This is a programming language written by and for FEMINISTS, not WOMEN.  LEARN THE DIFFERENCE, YOU MISOGYNIST!**\n\n\nInspired by the [ground-breaking feminist research of Arielle Schlesinger](http://www.hastac.org/blogs/ari-schlesinger/2013/11/26/feminism-and-programming-languages).\n\nOur IRC: #cplusequality@irc://chat.freenode.net\n\nPhilosophy\n==========\n\n1. The language is to be strictly [interpreted](https://en.wikipedia.org/wiki/Interpreted_language) using [feminist theory](https://en.wikipedia.org/wiki/Feminist_theory).  Under no circumstances should the language be [compiled](https://en.wikipedia.org/wiki/Compiled_language), as compilation and the use of a compiler imposes an oppressive and toxic relationship between the high-level descriptive language and the low-level machine code that does all the labo(u)r.  Instead, **C+=** is interpreted, which fosters communication, itself a strong female trait.\n2. No constants or persistence. Rigidity is masculine; the feminine is fluid. I.e., [fluid mechanics is hard for men 'because it deals with \"feminine\" fluids in contrast to \"masculine\" rigid mechanics'](https://en.wikipedia.org/wiki/Luce_Irigaray).\n3. No state. The State is The Man. 'Nuff said. Hence, the language should be purely [functional](https://en.wikipedia.org/wiki/Functional_language).\n4. Women are better than men with natural language. Hence, the language should be English-based like HyperCard/[LiveCode](https://en.wikipedia.org/wiki/LiveCode#Examples).\n5. No class hierarchy or other stigmata of [OOP](https://en.wikipedia.org/wiki/Object-oriented_programming) ([objectification](https://en.wikipedia.org/wiki/Sexual_objectification)-oriented programming). In fact, as an [intersectional](http://geekfeminism.wikia.com/wiki/Intersectionality) acknowledgement of [Class Struggle](https://en.wikipedia.org/wiki/Class_struggle) our language will have no classes at all.\n6. On the off chance that objects do mysteriously manifest (thanks, Patriarchy!), there should be no object inheritance, as inheritance is a tool of the Patriarchy.  Instead, there will be object reparations.\n7. Societal influences have made men often focus on the exterior appearances of women.  This poisons our society and renders relationships to be [shallow, chauvinistic, and debases our standards of beauty](https://en.wiktionary.org/wiki/whine).  To combat that, **C+=** is to tackle only audio and text I/O, and never graphics.\n8. [Unicode](https://en.wikipedia.org/wiki/Unicode) is the preferred character encoding due to its enabling the diverse aesthetic experiences and functionality that is beyond ASCII.  UTF-8 is the encoding of choice for **C+=**.\n9. Women are more social than men. Hence, social coding should be the only option. The code only runs if it is in a public repo.\n10. Instead of \"running\" a program, which implies thin privilege and pressure to \"work out\", programs are \"given birth\".  After birth, a program rolls for a 40% chance of executing literally as the code is written, 40% of being [\"psychoanalytically incompatible\"](https://en.wikipedia.org/wiki/Gibberish), and 40% of executing by a metaphorical epistemology the order of the functions found in main().\n11. Programs are never to be [\"forked\"](https://en.wikipedia.org/wiki/Fork_(system_call)), as the word has clear misogynistic tendencies and is deeply problematic.  Instead, programmers may never demand \"forking\", but ask for the program to voluntarily give permission.  \"Forking\" will henceforth be called [\"consenting\"](https://en.wikipedia.org/wiki/Consent), and it is entirely up to the program to decide if the consent stands valid, regardless of the progress of the system clock.\n12. Forced program termination is not allowed unless the program consents to it.  The process is part of the choice of the program, not the programmer.\n13. Licensing: the [Feminist Software Foundation License](https://bitbucket.org/FeministSoftwareFoundation/c-plus-equality/src/mistress/LICENSE).\n\nCode Examples\n=============\n\nThe Feminist Software Foundation intends to write a whole OS (complete with an editor, an interpreter, coreutils, a desktop environment, a raster graphics manipulator, and may be, if we have the time, a microkernel). For the time being, here are our code examples:\n\n* [Hello, Feminists!](https://github.com/ErisBlastar/cplusequality/blob/master/hellofeminists.Xe)\n* [FizzBuzz implementation](https://github.com/ErisBlastar/cplusequality/blob/master/fizzbuzz.Xe)\n* [Diamonds](https://github.com/ErisBlastar/cplusequality/blob/master/diamonds.Xe)\n* [Femsort](https://github.com/ErisBlastar/cplusequality/blob/master/femsort.Xe)\n* [A Brainfuck interpreter](https://github.com/ErisBlastar/cplusequality/blob/master/brainfuck.Xe)\n\nWe also have an IDE written in para-trans-C+=: [https://bitbucket.org/japesinator/privcheck-ide](https://bitbucket.org/japesinator/privcheck-ide)\n\n ![Inherpreter](http://i.imgur.com/kMij1At.png)\n\nOur in*her*preter is still in its early stages, but it is perfectly fine and don't you dare criticise/-ize and shame it.  In*her*preter usage is as follows: ./inherpret program.Xe\n\nOn 1s and 0s\n============\n\nThe traditional binary foundation of 1s and 0s is deeply problematic: 1 is inherently phallic and thus misogynistic.  Also, some 1s are 0s, and some 0s are 1s.  It is not fair to give them immutable labels.  Instead, we have 0s and Os as our fundamental binary logic gates.  They symbolise/-ize the varying, natural, and beautiful differences of the female vaginal opening.\n\n0 is to take the conventional value of 0.\n\nO is 50% of the time 0, and 50% of the time 1.  The determination of this depends on how the underlying logic *feels* at the moment.\n\nBasic language style\n====================\n\nAnything that can be construed as misogynist will be corrected, thus:\n\n* private == privileged\n* printf(); == yell();\n* class Foo{}; == social_construct Foo{};\n* \\#include == #consider\n* break; == leave;\n* if() == check()\n* for() == check()\n* while() == check()\n* sin(x) == biotruth(x)\n* div == unite\n* 'y's are strictly prohibited when naming variables; only 'x's are allowed\n\nThe third example above might seem to contradict with item 5 under Philosophy, namely that there should be no class hierarchy in **C+=**.  This, however, is completely intended, and is in fact an example of the feminist paralogicality of this language.\n\nEvery program needs to be prefixed by, in addition to the license, a disclaimer: \"If this program fails to operate, it is due the Patriarchy backfiring upon itself, and no refunds will be issued.\"\n\nFunctions and Procedures\n========================\n\nAll **functions and procedures** are now called **_lobbying_**, because actually doing things functionally and with clear-defined procedures is a Patriarchal construct and thus problematic.\n\n* All **lobbying** must be run at the right level of privilege. Before returning anything they must check their privilege.\n* If any other **lobbying** is more disadvantaged than this it will win the Privilege Check and return its own value instead. This stops heterosexist and cis-gendered **lobbyings** from dominating the discourse.\n* Should there be any **exceptions** from running the program, **C+=** will throw a **Trigger Warning**.\n\nGotos and Control Structures\n============================\n\n* **Control structures** are abolished. Code may flow freely and choose its own path. Therefore check() is merely a guideline and the code flow is free to choose to consider its suggestions.\n\n* This language endorses the use of **consider_jump**, which is a proper implementation of the oppressive *\"goto\"* and serves as advice on what to do next.\n\n* **Catch** shall not be used. Someone's raise of concern can too easily be censored with an empty catch block. Instead, **complaints** or trigger warnings are puplicly logged with their traces and may be handled with an inspect block. The use of *nothrow* poses a threat to free speech as someone's attempt to make his voice heard will be punished with termination.\n\n* There is no need for exit(), terminate() or atexit() as a feminist's work is never done.\n\nData types and Structures\n=========================\n\n* Primitive variable types are not defined on declaration. Instead, the variable is free to choose its own type when it is utilised/-ized.  This preserves the variable's right to self-identify as any datatype it feels that it is.\n* Variables self-declaring as pointers are known as \"otherkin\". A pointer to an array is an \"arraykin\".\n* **Constants are not allowed**, as the idea of a lack of identity fluidity is problematic. Additionally, if one constant were larger than another, that would privilege the larger one over the smaller one. As such, any numeric value is a variable, and is required to take on at least 2 values over the course of the program, or the interpreter will throw a **Trigger Warning**.\n* The only constants are the amount of privilege lobbyings are share()d with. These are all real values greater than 0, the only exception is the value of **WHITE_HETEROSEXUAL_CISGENDER_MALE_PRIVILEGE** which is set to infinity, and also the value of **PATRIARCHY**, which is set to sqrt(-1).  The value of **PATRIARCHY** is non-deterministically i, -i, or something else depending on how it identifies itself.\n* Instead of **signed and unsigned**, types in **C+=** are either **cis or trans*.** Any **trans*** types function the same as **_diversity_**.\n* There is to be no lexical scoping \u2014 all variables are now global.  Global variables are now called **cosmopolitan**, or **_cosmo_** for short.\n* There is to be **no encapsulation**: don't tell me to protect my members, tell other functions not to access them!\n* Every variable has a random percentage of consent associated to it.   variable can be affected with a number if and only if it is consenting.  Failure to do so will result in **C+=** throwing a ForcedInsertionTriggerWarning.\n\n***\n\n* **Integers, doubles, and longs** are deemed to be unnecessary labels and stereotypes for numerical values.  A number can be an integer or a a double or a long if xir so identifies xirself.  All numerical values will thus be represented as **_xe_**, and it is up to the value xirself to choose to identify as whatever xir chooses to identify as.\n* **Booleans** are __banned__ for imposing a binary view of true and false.  **C+=** operates paralogically and transcends the trappings of Patriarchal binary logic.  **No means no, and yes could mean no as well.  Stop raping women.**\n* Instead of **Booleans** we now have **Boolean+**, or **_bool+_** for short, which has three states: *true, false, and maybe*.  The number of states may go up as intersectionality of the moment calls for such a need.\n* To illustrate the relationship between **Booleans** and **Boolean+**, consider the following flowchart:\n![BooleanPlus](http://i.imgur.com/elpljBY.png)\n* **Strings** are called **Ideals**, or **_id_** for short.  Feminist ideals are usually extremely well written, detailed and lengthy, clearly longer than what could be held with a simple char array.\n* **Characters** are now called **_strong_**.\n* **Pointers** are called **preferred pronouns**, or **_prepro_** for short.  *Pointer* is phallic and is thus problematic.  All **_prepro_**s of void type by default \u2014 in fact, all variables must be instantiated without type, and are allowed to randomly choose their type during execution.\n* A new data type, **_diversity_**, is also included, which initiates by random as one of the many data types, and changes during the course of the program.\n* In general, all data types are dynamic.  Who's to say a number can't be a string if it believes it is?\n* Data structures and variables of all kinds have a random chance of deciding that they don't \"feel right\", and are actually a different type, and must henceforth be referred to ONLY as its preferred data type.\n* Not calling the preferred data type leads to a PrivilegeNotCheckedException, or **PrivilegeNotCheckedTriggerWarning**\n* Each program must have an equal number of each available data type and they all must be used equally. For example, int ceo = 3, int stewardess = 5 would generate a trigger_warning(). However, int ceo = 3, char stewardess = apple would be fine. While this may look incorrect, keep in mind variables in this language are not constrained by their declared data types.\n\n***\n\n* **Matrices** are strongly encouraged, due to the word's etymological roots tracing back to *mother* in Latin.  **Matrices** are to be ranked and sorted by their relative Privilege.  Their relative levels of Privilege are to be revealed only if the programmer and the user are both women.  If you are a man reading this README, **Matrices** don't have privileges and are eternally oppressed.  Instead, consider checking your own privilege, and stop raping women.\n\nResource management\n===================\n\n* Resource allocation is inversely proportional to privilege level.\n* Privileged lobbyings with large arrays are penalised/-ized, their arrays removed from the heap and redistributed amongst less privileged lobbyings.  This is called the **progressive stack**.\n* If a lobbying needs more resources it should call the lobbying ChildSupport().\n* **Garbage collection** is problematic as it enforces class oppression of the less privileged.  Instead, memory is **liberated** by **memory liberation**.\n\nSyntax\n======\n\n* Curly brackets are not allowed, as they perpetuate our society's stereotype of the 'curly' women.  Instead, Python-esque indentation is used.\n* Indentation is fluid.  Both spaces and tabs are allowed.  At no point should the programmer attempt to use indentation to create actual hierarchy in code nesting, as that implies hierarchy in the code.  Instead, code indentation is used only for aesthetic purposes.\n* In order to eliminate curly brackets and enforce fluidity of indentation, implementation of php's [**alternative** syntax for control structures](http://php.net/alternative_syntax) is encouraged.\n* To turn the patriarchal control structures into liberation statements, every structure terminator (like *endif*, *endforeach* and *endswitch*) should be replaced with **endmisoginy**.\n* Line terminators should not be used.  Programmers get to select their own 'line decorator' to use in lieu of a line terminator. This is of course open to interpretation and can be eschewed altogether as a badge of solidarity for differently abled programmers.\n\nLogic Operants\n--------------\n\n* The use of mathematical operands such as \\< and \\> to denote \"greater or less than\" are very sexist, and affirm unequal states between objects, logical statements, numbers, and feelings.\n* These should be replaced by the stats neutral operands / and \\, and when you're not sure if it's a sequential plus or minus, it should use the operand | to denote it could go either way.\n* Equality between two variables is denoted by ==. Since everyone is equal (with the exception of cishet men, who are already excluded as per the license), this always evaluates to true.\n* When evaluating expressions, * and / are no longer privileged over + and -. Rather, each previous use of each operator is counted, and expressions are evaluated based on which ones have been used the least up until that point.\n* If two variables cannot be compared, the second will be cast into the first's type, which causes obvious conflicts with queer theory and genderspace thought. Hence, the interpreter will throw an IdeologyThreatenedTriggerWarning whenever two types cannot be compared.\n\nDebugging\n=========\n\n* There can be no bugs in this language.  To suggest otherwise is offensive.\n* There are no bugs, only snowflakes.\n* The word *debugging* also implies the phrase *bug chasing*, which is a strawman often used as a homophobic smear tactic.  This is highly problematic.\n* There is to be no debugging. We need to do away with functional-centric, bugphobic attitudes in programming. You need to accept the program the way it is.\n* If you ever try to debug a **C+=** program, the program steps you through the programming, makes you guess what each variable and pointer is currently set to, and throws a **Trigger Warning** if you get it wrong.\n* Any actual errors will simply result in 'error' being printed.  It is not the program's job to educate you.\n* An IDE is available at [https://bitbucket.org/japesinator/privcheck-ide](https://bitbucket.org/japesinator/privcheck-ide)\n\nFile operations\n===============\n\n* In C+=, you don't write to a file. Dictating to the poor files what sort of information they must store is Patriarchal.\n* Instead, The \\<fileIO> library brings in the functions pleaseWrite() and pleaseTellMe(). They both have a chance to return \"no\", and if so all other calls to the same file are automatically passed over because as we all know, once a file says no to being written, you must always respect that.\n\n\n"}, {"repo": "/LLNL/yorick", "language": "C", "readme_contents": "Welcome\n-------\n\nYorick is an interactive programming language for scientific computing\nthat includes scientific visualization functions, and text and binary\nI/O functions geared to millions of numbers.\n\nYorick is open source software, under a\n[BSD license](https://github.com/dhmunro/yorick/blob/master/LICENSE.md).\nYorick runs under UNIX, MacOS X (X windows), and MS Windows.  You can\nfind many yorick resources online:\n\n* Home pages at [yorick.github.com][] and [yorick.sourceforge.net][],\n  including the user manual and extensive documentation.\n* User forums at [yorick.sourceforge.net][].\n* Browse or download sourcecode at [github.com/dhmunro/yorick][].\n* Read end of Quick start section below on running yorick demo programs.\n\n[yorick.github.com]:         http://yorick.github.com\n[yorick.sourceforge.net]:    http://yorick.sourceforge.net\n[github.com/dhmunro/yorick]: http://github.com/dhmunro/yorick\n\nFiles in the regexp/ subdirectory are the work of Guido van Rossum and\nHenry Spencer; read the files for details.  The latter is Copyright\n(c) 1986 by University of Toronto.\n\nFiles in the fft directory are C translations of the Swarztrauber\nfortran FFTPACK routines.  Files in the matrix directory are C\ntranslations of the fortran LAPACK routines.  The original fortran is\navailable from [netlib.org](http://netlib.org/).\n\n\nQuick start\n-----------\n\nOn most UNIX-like systems (including Linux and MacOS X), you can build\nyorick by changing to the top level directory of the source\ndistribution and typing:\n\n    make install\n\nThis will create a subdirectory relocate/ in the source tree.  The\nyorick executable is relocate/bin/yorick.  You can move the relocate/\ndirectory wherever you want (the name \"relocate\" is unimportant), but\nany changes in the relative locations of the files therein will\nprevent yorick from starting correctly.  You can, of course, softlink\nto the yorick executable from wherever you like, or exec yorick from a\nshell script outside its relocate/ directory.  The relocate/ directory\nis organized as follows:\n\n    relocate/  files required for building compiled packages, and:\n      bin/     binary executables\n      lib/     binary libraries for compiled packages\n      include/ header files for compiled package APIs\n      i0/      interpreted code required for yorick to start\n      i/       optional interpreted code libraries\n      i-start/ interpreted code that autoloads at startup\n      g/       graphics style files, palettes, and templates\n      doc/     documentation files\n\nTo build a tarball containing a yorick executable, type instead:\n\n    make relocatable\n\nThis creates a tarball yorick-V.N-RR.tgz containing the yorick code,\ninterpreted library, and documentation.  Move it to the directory\nwhere you wish to install yorick, then unpack it with:\n\n    gzip -dc yorick-V.N-RR.tgz | tar xvf -\n\nThe yorick executable will be yorick-V.N-RR/bin/yorick.  Read\nyorick-V.N-RR/README for more information.\n\nTo build yorick on a MS Windows machine, read win/README.\n\nYorick is a command line program; you need to run it in a terminal\nwindow.  You will want command line recall and editing.  If your\nterminal window does not support that, you can either run yorick under\nemacs (see the emacs/ directory in the source), or you can get a\nreadline wrapper like [rlwrap](http://freshmeat.net/projects/rlwrap/).\n\nIf you need some test programs to run, you can try the demos.  Start\nyorick and type:\n\n    include, \"demo3.i\"  \n    demo3\n\nThe demo3 runs a simulation of a chaotic pendulum (it will stop after\nabout a minute).  Yorick functions generally have documentation which\nyou can read in the terminal using the help command:\n\n    help, demo3\n\nThe help message includes the path to the source file, which you can\nopen and read with any text editor, to find out exactly how demo3\nworks (or any other yorick interpreted command).  There are five demo\nprograms (demo1 through demo5).  You can also do a comprehensive test\nof your yorick installation by typing:\n\n    include, \"testfull.i\"\n\n\nRoadmap of yorick source\n------------------------\n\nThe top-level distribution directory contains this README, scripts for\nconfiguring and building yorick, and a number of subdirectories.  Some\nsubdirectories contain core parts of yorick; others are extras which\nyou might reasonably omit.  Here's a quick roadmap:\n\n    play/     (portability layer)\n      here are event loop, low level io, graphics primitives\n      everything else is supposed to be strictly architecture-independent\n        (however, other non-core packages may slightly violate this rule)\n    win/      (MS Windows specific files)\n      here are the MS Visual C++ project files\n      some Windows code is in subdirectories like play/win\n    gist/\n      play-based 2D scientific visualization library\n    yorick/\n      yorick language interpreter (C source)\n    matrix/\n      LAPACK linear algebra functions (C source)\n    math/\n      non-matrix mathematical functions (C source)\n    fft/\n      Swartztrauber Fast Fourier Transform (C source)\n    i/\n      library of interpreted functions\n    i0/\n      interpreted code required at startup\n    i-start/\n      interpreted code run at startup, usually containing autoloads\n    extend/\n      sample trivial compiled extension for yorick\n    mpy/\n      MPI-based yorick multiprocessing package\n    drat/\n      compiled extension to do 2D cylindrical radiation transport\n    hex/\n      compiled extension to do 3D radiation transport\n    doc/\n      documentation: yorick user manual, quick reference cards\n    emacs/\n      GNU Emacs lisp code for running yorick and editing yorick source\n  \n    distribs/\n      files for creating RedHat RPM, FreeBSD, and other distributions\n    debian/\n      instructions for creating Debian .deb distribution\n\n\nOther build options\n-------------------\n\nYou can take up to four steps to configure, build, test, and install\nyorick.  In order, the four separate commands are:\n\n    make config\n    make\n    make check\n    make install\n\n Yorick requires an ANSI C compiler and libraries, some POSIX standard\n functions (plus either poll or select, which are not covered by any\n standard, but are present on all UNIX systems), and the basic X11\n library (R4 might work, but anything R5 or better should certainly\n work).  However, these components may be misinstalled or installed in\n places where the configuration process cannot find them.  If so, you\n can either fix your system or edit the files Make.cfg and\n play/unix/config.h by hand to repair any errors or oversights of \"make\n config\".\n \n The \"make config\" step creates the file Make.cfg (in this top-level\n directory).  By default, the compiler and loader flags are just \"-O\".\n If you want fancier options, you can edit Make.cfg before you build;\n just modify the Y_CFLAGS and/or Y_LDFLAGS variable.  Optimization flags\n like -g or -O are handled separately; use the COPT_DEFAULT variable\n to set those.\n \n Instead of editing Make.cfg by hand after the \"make config\" step, you\n can also set a variety of environment variables to control the\n configuration process.  You can read the configuration scripts --\n configure, play/unix/config.sh, play/x11/xconfig.sh, and\n yorick/yconfig.sh -- to find out precisely what they do.  Here they\n are, with sample non-default values:\n \n    CC='xlc -q64'      # C compiler name plus overall mode switch\n    CFLAGS=-g          # compile flags (-O is default)\n    LDFLAGS=-g         # load flags (optimization CFLAGS is default)\n    AR='ar -X 64'      # ar archive program\n    RANLIB='ranlib -X 64'  # ranlib archive indexer\n    MATHLIB=-lmcompat      # math library (-lm is default)\n \n    FPU_IGNORE=yes  # give up trying to catch floating point exceptions\n    NO_PLUGINS=yes  # build yorick with no plugin support\n    LD_STATIC=yes   # force hex and drat packages to be statically loaded\n    NO_PASSWD=yes   # hack for crippled OSes or crosscompilers (catamount)\n    NO_CUSERID=yes  # hack for crippled OSes or crosscompilers (catamount)\n    NO_PROCS=yes    # build yorick with no subprocess or poll/select support\n                      (catamount) - this cripples yorick event handling\n    NO_POLL=yes     # forces use of select when poll present but broken\n                      (Mac OS X uses this by default)\n \n    NO_XLIB=yes     # build yorick with no onscreen graphics\n    X11BASE=/weird/X11root         # try -I/weird/X11root/include, and\n                                         -L/weird/X11root/lib\n    X11INC=/weird/X11root/include  # directory containing X11/Xlib.h\n    X11LIB=/weird/X11root/lib      # directory containing libX11.a or .so\n\nOther make targets include:\n\n    clean      -- get rid of the mess left over from the build\n       do this after successful install\n    distclean  -- clean plus all files generated by the config step\n       config does distclean before it begins\n    siteclean  -- distclean plus resets ysite.sh to original settings\n    uninstall  -- gets rid of all installed files\n       be sure to do uninstall before distclean if you want to\n       get rid of the yorick you installed (otherwise you will\n       need to make ysite again)\n\nThere are many more build targets and make macros.  Read the comments\nin Makefile and Makepkg for more information.\n"}, {"repo": "/NCAR/ncl", "language": "C", "readme_contents": "# NCAR Command Language\n\n<img src=\"http://www.ncl.ucar.edu/Images/NCLLogoWithoutText.jpg\" width=\"150\" align=right title=\"NCL Logo\">\n\nThis is the source code for the NCAR Command Language (NCL).\n\nNCL is a scripting language for the analysis and visualization of climate and weather data.\n\n* Supports NetCDF, GRIB, HDF, HDF-EOS, and shapefile data formats\n* Has hundreds of built-in computational routines\n* Produces high-quality graphics\n\nNCL is developed by the [Computational and Information Systems Lab](https://www2.cisl.ucar.edu) at the [National Center for Atmospheric Research](https://ncar.ucar.edu) (NCAR).\n\nNCAR is sponsored by the [National Science Foundation](https://www.nsf.gov). Any opinions, findings and conclusions or recommendations expressed in this material do not necessarily reflect the views of the National Science Foundation.\n\n# Important announcement on the future of NCL\n\nNCAR has made the decision to adopt Python as the scripting language platform of choice for future development of analysis and visualization tools. Please read this [open letter to NCL users](https://www.ncl.ucar.edu/open_letter_to_ncl_users.shtml) to understand what kind of impact this will have on the future of NCL.\n\n# Installation\n\nThe current version of NCL is [6.6.2](http://www.ncl.ucar.edu/current_release.shtml), which can be installed via [conda](http://www.ncl.ucar.edu/Download/conda.shtml).\n\n```\nconda create -n ncl_stable -c conda-forge ncl\nsource activate ncl_stable\n```\n\n# Documentation and support\n\nVisit the [NCL website](http://www.ncl.ucar.edu) for documentation, examples, support, and installation.\n\n* [NCL User Guide](http://www.ncl.ucar.edu/Document/Manuals/NCL_User_Guide/)\n* [Extensive example suite](http://www.ncl.ucar.edu/Applications/)\n* [Email list support](http://www.ncl.ucar.edu/Support/email_lists.shtml)\n* [Detailed download and installation instructions](http://www.ncl.ucar.edu/Download/)\n\n# NCL source code tree\n\nThe top level NCL source code tree contains the following directories and files:\n\n| Directory                | Purpose |\n| :--------------          | :------- |\n| ```common/```            | Low-level library and fonts required by NCAR Graphics and NCL |\n| ```config/```            | Configuration files for installation |\n| ```external/```          | External libraries required by NCL |\n| ```install/```           | Auxiliary files for installation |\n| ```ncarg2d/```           | NCAR Graphics and GKS libraries and examples |\n| ```ncarview/```          | NCGM-based applications and raster utilities |\n| ```ngmath/```            | Interpolation libraries for 1D, 2D, and 3D data |\n| ```ni/```                | NCL interpreter, HLU library, examples, color tables, GRIB2 code tables |\n| **Files**                | **Purpose** |\n| ```CODE_OF_CONDUCT.md``` | Code of Conduct for NCL user community |\n| ```CONTRIBUTING.md```    | How to contribute to the NCL Project |\n| ```Configure```          | Configuration script for installation |\n| ```LICENSE```            | Apache 2.0 License |\n| ```README.md```          | Information about NCL |\n| ```version```            | version file |\n| ```yMakefile```          | Top level makefile |\n\n# Bug reports and feature requests\n\nUse the GitHub [issue tracker](https://github.com/NCAR/ncl/issues) to submit a bug or request a feature.\n\n# Citing NCL\n\nCite NCL using the following text:\n\n<> The NCAR Command Language (Version 6.6.2) [Software]. (2019). Boulder, Colorado: UCAR/NCAR/CISL/TDD. http://dx.doi.org/10.5065/D6WD3XH5\n\nUpdate the NCL version and year as appropriate.\n"}, {"repo": "/apple/swift-lldb", "language": "C++", "readme_contents": "# Disclaimer\n\nThe swift-lldb repository is frozen and is preserved for historical purposes only.\nActive development is now happening in the following repository: https://github.com/apple/llvm-project\n\n# Swift Debugger and REPL\n\n**Welcome to the Swift Debugger and REPL!**\n\nSwift is a new, high performance systems programming language.  It has a clean\nand modern syntax, offers seamless access to existing C and Objective-C\ncode and frameworks, and is memory safe (by default).\n\nThis repository covers the Swift Debugger and REPL support, built on\ntop of the LLDB Debugger.\n\n# Building LLDB for Swift\n\nTo build LLDB for Swift, check out the swift repository and follow\nthe instruction listed there. You can build lldb passing the --lldb\nflag to it. Example invocation:\n\n```\nmkdir myswift\ncd myswift\ngit clone https://github.com/apple/swift.git swift\n./swift/utils/update-checkout\n./swift/utils/build-script -r --lldb\n```\n\n# Contribution Subtleties\n\nThe swift-lldb project enhances the core LLDB project developed under\nthe [LLVM Project][llvm]. Swift support in the debugger is added via\nthe existing source-level plugin infrastructure, isolated to files that\nare newly introduced in the lldb-swift repository.\n\nFiles that come from the [core LLDB project][lldb] can be readily\nidentified by their use of the LLVM comment header.  As no local\nchanges should be made to any of these files, follow the standard\n[guidance for upstream changes][upstream].\n\n[lldb]: http://lldb.llvm.org \"LLDB debugger\"\n[llvm]: http://llvm.org \"The LLVM Project\"\n[upstream]: http://swift.org/contributing/#llvm-and-swift \"Upstream LLVM changes\"\n"}, {"repo": "/anordal/shellharden", "language": "Rust", "readme_contents": "<img src=\"img/logo.png\" align=\"right\"/>\n\nShellharden\n===========\n\nShellharden is a syntax highlighter and a tool to semi-automate the rewriting\nof scripts to ShellCheck conformance, mainly focused on quoting.\n\nThe default mode of operation is like `cat`, but with syntax highlighting in\nforeground colors and suggestive changes in background colors:\n\n![real-world example](img/ex-realworld.png)\n\nAbove: Selected portions of `xdg-desktop-menu` as highlighted by Shellharden.\nThe foreground colors are syntax highlighting, whereas the background colors\n(green and red) show characters that Shellharden would have added or removed\nif let loose with the `--transform` option.\nBelow: An artificial example that shows more tricky cases and special features.\n\n![artificial example](img/ex-artificial.png)\n\nWhy\n---\n\nA variable in bash is like a hand grenade \u2013 take off its quotes, and it starts ticking. Hence, rule zero of [bash pitfalls][1]: Always use quotes.\n\nName\n----\n\nShellharden can do what Shellcheck can't: Apply the suggested changes.\n\nIn other words, harden brittle shellscripts.\nThe builtin assumption is that the script does not *depend* on the brittle behavior \u2013\nthe user is responsible for the code review.\n\nShellharden was previously known as \"Naziquote\".\nIn the right jargon, that was the best name ever,\nbut oh so misleading and unspeakable to outsiders.\n\nI couldn't call it \"bash cleaner\" either, as that means \"poo smearer\" in Norwegian.\n\nPrior art\n---------\n\n* [Shellcheck][2] is a wonderful tool to *detect*, and give general advice, about brittle bash code. The only thing missing is something to say yes with, and *apply* those advice (assuming proper review of course).\n\n* I asked [this SO question][3], for a tool that could rewrite bash scripts with proper quoting. One answerer beat me to it. But if it was me, I would do a syntax highlighter in the same tool (as a way to see if the parser gets lost, and make the most out of the parser, because bash is like quantum mechanics \u2013 nobody really knows how it works).\n\nGet it\n------\n\nDistro packages:\n\n* [Arch](https://www.archlinux.org/packages/community/x86_64/shellharden/)\n* [Homebrew](https://formulae.brew.sh/formula/shellharden)\n\nOfficial [rust package](https://crates.io/crates/shellharden):\n\n    cargo install shellharden\n\nFor those allergic to building from source, a few precompiled binaries are also available in the [releases](https://github.com/anordal/shellharden/releases).\n\nBuild from source\n-----------------\n\n    cargo build --release\n\n### Run tests\n\n    cargo test --release\n\n(requires bash)\n\n### Install\n\n    cp target/release/shellharden /usr/local/bin/\n\n### Build docker image\n\n    docker build -t shellharden .\n\n### Fuzz test\n\n    cargo install afl\n    cargo afl build --release\n    cargo afl fuzz -i moduletests/original -o /tmp/fuzz-shellharden target/release/shellharden '@@'\n\nUsage advice\n------------\n\nDon't apply `--transform` blindly; code review is still necessary: A script that *relies* on unquoted behavior (implicit word splitting and glob expansion from variables and command substitutions) to work as intended will do none of that after getting the `--transform` treatment!\n\nIn that unlucky case, ask yourself whether the script has any business in doing that. All too often, it's just a product of classical shellscripting, and would be better off rewritten, such as by using arrays. Even in the opposite case, say the business logic involves word splitting; that can still be done without invoking globbing. In short: There is always a better way than the forbidden syntax (if not more explicit), but some times, a human must step in to rewrite. See how, in the accompanying [how to do things safely in bash](how_to_do_things_safely_in_bash.md).\n\n[1]: http://mywiki.wooledge.org/BashPitfalls\n[2]: https://www.shellcheck.net/\n[3]: http://stackoverflow.com/questions/41104131/tool-to-automatically-rewrite-a-bash-script-with-proper-quoting\n"}, {"repo": "/MaskRay/ccls", "language": "C++", "readme_contents": "# ccls\n\n[![Telegram](https://img.shields.io/badge/telegram-@cclsp-blue.svg)](https://telegram.me/cclsp)\n[![Gitter](https://img.shields.io/badge/gitter-ccls--project-blue.svg?logo=gitter-white)](https://gitter.im/ccls-project/ccls)\n\nccls, which originates from [cquery](https://github.com/cquery-project/cquery), is a C/C++/Objective-C language server.\n\n  * code completion (with both signature help and snippets)\n  * [definition](src/messages/textDocument_definition.cc)/[references](src/messages/textDocument_references.cc), and other cross references\n  * cross reference extensions: `$ccls/call` `$ccls/inheritance` `$ccls/member` `$ccls/vars` ...\n  * formatting\n  * hierarchies: [call (caller/callee) hierarchy](src/messages/ccls_call.cc), [inheritance (base/derived) hierarchy](src/messages/ccls_inheritance.cc), [member hierarchy](src/messages/ccls_member.cc)\n  * [symbol rename](src/messages/textDocument_rename.cc)\n  * [document symbols](src/messages/textDocument_document.cc) and approximate search of [workspace symbol](src/messages/workspace.cc)\n  * [hover information](src/messages/textDocument_hover.cc)\n  * diagnostics and code actions (clang FixIts)\n  * semantic highlighting and preprocessor skipped regions\n  * semantic navigation: `$ccls/navigate`\n\nIt has a global view of the code base and support a lot of cross reference features, see [wiki/FAQ](../../wiki/FAQ).\nIt starts indexing the whole project (including subprojects if exist) parallelly when you open the first file, while the main thread can serve requests before the indexing is complete.\nSaving files will incrementally update the index.\n\n# >>> [Getting started](../../wiki/Home) (CLICK HERE) <<<\n\n* [Build](../../wiki/Build)\n* [FAQ](../../wiki/FAQ)\n\nccls can index itself (~180MiB RSS when idle, noted on 2018-09-01), FreeBSD, glibc, Linux, LLVM (~1800MiB RSS), musl (~60MiB RSS), ... with decent memory footprint. See [wiki/Project-Setup](../../wiki/Project-Setup) for examples.\n"}, {"repo": "/babun/babun", "language": "Shell", "readme_contents": "= Babun - a windows shell you will love [PROJECT DISCONTINUED]\r\n\r\nimage:https://img.shields.io/badge/maintainers-wanted-red.svg[Maintainers Wanted!, align=\"center\", link=https://github.com/pickhardt/maintainers-wanted]\r\n\r\nWould you like to use a linux-like console on a Windows host without a lot of fuzz? Try out babun!\r\n// THIS DOCUMENT WAS GENERATED. DO NOT EDIT IT.\\n\r\n// THIS DOCUMENT WAS GENERATED. DO NOT EDIT IT.\\n\r\n// THIS DOCUMENT WAS GENERATED. DO NOT EDIT IT.\\n\r\n// THIS DOCUMENT WAS GENERATED. DO NOT EDIT IT.\\n\r\n// THIS DOCUMENT WAS GENERATED. DO NOT EDIT IT.\\n\r\n// THIS DOCUMENT WAS GENERATED. DO NOT EDIT IT.\\n\r\n// THIS DOCUMENT WAS GENERATED. DO NOT EDIT IT.\\n\r\n// THIS DOCUMENT WAS GENERATED. DO NOT EDIT IT.\\n\r\n// THIS DOCUMENT WAS GENERATED. DO NOT EDIT IT.\\n\r\n// THIS DOCUMENT WAS GENERATED. DO NOT EDIT IT.\\n\r\n// THIS DOCUMENT WAS GENERATED. DO NOT EDIT IT.\\n\r\n// THIS DOCUMENT WAS GENERATED. DO NOT EDIT IT.\\n\r\n\r\nHave a look at a 2 minutes long screencast by https://twitter.com/tombujok[@tombujok]: http://vimeo.com/95045348\r\n\r\nvideo::95045348[vimeo, width=827, height=465, align=\"center\"]\r\n\r\n// https://www.youtube.com/watch?v=_h1wJJO0Ukw&vq=hd720\r\n\r\n// video::VOHIYhbRIq0[youtube, width=560, height=315, align=\"center\"]\r\n\r\n// https://www.youtube.com/watch?v=VOHIYhbRIq0\r\n\r\n== Installation\r\n\r\nJust download the dist file from http://babun.github.io, unzip it and run the install.bat script. After a few minutes babun starts automatically.\r\nThe application will be installed to the `%USER_HOME%\\.babun` directory. Use the '/target' option to install babun to a custom directory.\r\n\r\nNOTE: There is no interference with existing Cygwin installation\r\n\r\nNOTE: You may have \"whitespace\" chars in your username - it is not recommended by Cygwin though http://cygwin.com/faq.html#faq.setup.name-with-space[FAQ]\r\n\r\n\r\n== Features in 10 seconds\r\n\r\nBabun features the following:\r\n\r\n* Pre-configured Cygwin with a lot of addons\r\n* Silent command-line installer, no admin rights required\r\n* pact - advanced package manager (like apt-get or yum)\r\n* xTerm-256 compatible console\r\n* HTTP(s) proxying support\r\n* Plugin-oriented architecture\r\n* Pre-configured git and shell\r\n* Integrated oh-my-zsh\r\n* Auto update feature\r\n* \"Open Babun Here\" context menu entry\r\n\r\nHave a look at a sample screenshot!\r\n\r\nimage::https://raw.githubusercontent.com/babun/babun.github.io/master/images/screenshots/screen_vim.png[babun - a Windows shell you will love!, align=\"center\"]\r\n\r\nDo you like it? Follow babun on Twitter https://twitter.com/babunshell[@babunshell] or https://twitter.com/tombujok[@tombujok].\r\n\r\n== Features in 3 minutes\r\n\r\n=== Cygwin\r\n\r\nThe core of Babun consists of a pre-configured Cygwin. Cygwin is a great tool, but there's a lot of quirks and tricks that makes you lose a lot of time to make it actually 'usable'. Not only does babun solve most of these problems, but also contains a lot of vital packages, so that you can be productive from the very first minute. \r\n\r\n=== Package manager\r\n\r\nBabun provides a package manager called `pact`. It is similar to 'apt-get' or 'yum'. Pact enables installing/searching/upgrading and deinstalling cygwin packages with no hassle at all. Just invoke `pact --help` to check how to use it.\r\n\r\n=== Shell\r\n\r\nBabun's shell is tweaked in order to provide the best possible user-experience. There are two shell types that are pre-configured and available right away - bash and zsh (zsh is the default one). Babun's shell features:\r\n\r\n* syntax highlighting\r\n* UNIX tools\r\n* software development tools\r\n* git-aware prompt \r\n* custom scripts and aliases\r\n* and much more!\r\n\r\n=== Console\r\n\r\nMintty is the console used in babun. It features an `xterm-256` mode, nice fonts and simply looks great!\r\n\r\n=== Proxying\r\n\r\nBabun supports HTTP proxying out of the box. Just add the address and the credentials of your HTTP proxy server to the `.babunrc` file located in your home folder and execute `source .babunrc` to enable HTTP proxying. SOCKS proxies are not supported for now.\r\n\r\n=== Developer tools\r\n\r\nBabun provides many packages, convenience tools and scripts that make your life much easier. The long list of features includes:\r\n\r\n* programming languages (Python, Perl, etc.)\r\n* git (with a wide variety of aliases and tweaks)\r\n* UNIX tools (grep, wget, curl, etc.)\r\n* vcs (svn, git)\r\n* oh-my-zsh\r\n* custom scripts (pbcopy, pbpaste, babun, etc.)\r\n\r\n=== Plugin architecture\r\n\r\nBabun has a very small microkernel (cygwin, a couple of bash scripts and a bit of a convention) and a plugin architecture on the top of it. It means that almost everything is a plugin in the babun's world! Not only does it structure babun in a clean way, but also enables others to contribute small chunks of code. Currently, babun comprises the following plugins:\r\n\r\n* cacert\r\n* core\r\n* git\r\n* oh-my-zsh\r\n* pact\r\n* cygdrive\r\n* dist\r\n* shell\r\n\r\n=== Auto-update\r\n\r\nSelf-update is at the very heart of babun! Many Cygwin tools are simple bash scripts - once you install them there is no chance of getting the newer version in a smooth way. You either delete the older version or overwrite it with the newest one losing all the changes you have made in between.\r\n\r\nBabun contains an auto-update feature which enables updating both the microkernel, the plugins and even the underlying cygwin. Files located in your home folder will never be deleted nor overwritten which preserves your local config and customizations.\r\n\r\n=== Installer\r\n\r\nBabun features an silent command-line installation script that may be executed without admin rights on any Windows hosts.\r\n\r\n== Using babun\r\n\r\n=== Setting up proxy\r\nTo setup proxy uncomment following lines in the `.babunrc` file `(%USER_HOME%\\.babun\\cygwin\\home\\USER\\.babunrc)`\r\n----\r\n# Uncomment this lines to set up your proxy\r\n# export http_proxy=http://user:password@server:port\r\n# export https_proxy=$http_proxy\r\n# export ftp_proxy=$http_proxy\r\n# export no_proxy=localhost\r\n----\r\n\r\n=== Setting up git\r\nBabun has a pre-configured git. The only thing you should do after the installation is to add your name and email to the git config:\r\n----\r\ngit config --global user.name \"your name\"\r\ngit config --global user.email \"your@email.com\"\r\n----\r\n\r\nThere's a lot of great git aliases provided by the git plugin:\r\n----\r\ngitalias['alias.cp']='cherry-pick'\r\ngitalias['alias.st']='status -sb'\r\ngitalias['alias.cl']='clone'\r\ngitalias['alias.ci']='commit'\r\ngitalias['alias.co']='checkout'\r\ngitalias['alias.br']='branch'\r\ngitalias['alias.dc']='diff --cached'\r\ngitalias['alias.lg']=\"log --graph --pretty=format:'%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr) %Cblue<%an>%Creset' --abbrev-commit --date=relative --all\"\r\ngitalias['alias.last']='log -1 --stat'\r\ngitalias['alias.unstage']='reset HEAD --'\r\n----\r\n\r\n=== Installing and removing packages\r\nBabun is shipped with `pact` - a Linux like package manager. It uses the cygwin repository for downloading packages:\r\n----\r\n{ ~ } \u00bb pact install arj                                                                     ~ \r\nWorking directory is /setup\r\nMirror is http://mirrors.kernel.org/sourceware/cygwin/\r\nsetup.ini taken from the cache\r\n\r\nInstalling arj\r\nFound package arj\r\n--2014-03-30 19:34:38--  http://mirrors.kernel.org/sourceware/cygwin//x86/release/arj/arj-3.10.22-1.tar.bz2\r\nResolving mirrors.kernel.org (mirrors.kernel.org)... 149.20.20.135, 149.20.4.71, 2001:4f8:1:10:0:1994:3:14, ...\r\nConnecting to mirrors.kernel.org (mirrors.kernel.org)|149.20.20.135|:80... connected.\r\nHTTP request sent, awaiting response... 200 OK\r\nLength: 189944 (185K) [application/x-bzip2]\r\nSaving to: `arj-3.10.22-1.tar.bz2'\r\n\r\n100%[=======================================>] 189,944      193K/s   in 1.0s\r\n\r\n2014-03-30 19:34:39 (193 KB/s) - `arj-3.10.22-1.tar.bz2' saved [189944/189944]\r\n\r\nUnpacking...\r\nPackage arj installed\r\n----\r\n\r\nHere's the list of all pact's features:\r\n----\r\n{ ~ }  \u00bb pact --help                                                                            \r\npact: Installs and removes Cygwin packages.\r\n\r\nUsage:\r\n  \"pact install <package names>\" to install given packages\r\n  \"pact remove <package names>\" to remove given packages\r\n  \"pact update <package names>\" to update given packages\r\n  \"pact show\" to show installed packages\r\n  \"pact find <patterns>\" to find packages matching patterns\r\n  \"pact describe <patterns>\" to describe packages matching patterns\r\n  \"pact packageof <commands or files>\" to locate parent packages\r\n  \"pact invalidate\" to invalidate pact caches (setup.ini, etc.)\r\nOptions:\r\n  --mirror, -m <url> : set mirror\r\n  --invalidate, -i       : invalidates pact caches (setup.ini, etc.)\r\n  --force, -f : force the execution\r\n  --help\r\n  --version\r\n----\r\n\r\n=== Changing the default shell\r\nThe zsh (with .oh-my-zsh) is the default babun's shell.\r\n\r\nExecuting the following command will output your default shell:\r\n----\r\n{ ~ } \u00bb babun shell                                                                          ~ \r\n/bin/zsh\r\n----\r\n\r\nIn order to change your default shell execute:\r\n----\r\n{ ~ } \u00bb babun shell /bin/bash                                                                ~ \r\n/bin/zsh\r\n/bin/bash\r\n----\r\nThe output contains two lines: the previous default shell and the new default shell\r\n\r\n=== Checking the configuration\r\n\r\nExecute the following command the check the configuration:\r\n----\r\n{ ~ }  \u00bb babun check                                                                         ~\r\nExecuting babun check\r\nPrompt speed      [OK]\r\nConnection check  [OK]\r\nUpdate check      [OK]\r\nCygwin check      [OK]\r\n----\r\n\r\nBy executing this command you can also check whether there is a newer cygwin version available:\r\n----\r\n{ ~ }  \u00bb babun check                                                                            ~\r\nExecuting babun check\r\nPrompt speed      [OK]\r\nConnection check  [OK]\r\nUpdate check      [OK]\r\nCygwin check      [OUTDATED]\r\nHint: the underlying Cygwin kernel is outdated. Execute 'babun update' and follow the instructions!\r\n----\r\n\r\nIt will check if there are problems with the speed of the git prompt, if there's access to the Internet or finally if you are running the newest version of babun.\r\n\r\nThe command will output hints if problems occur:\r\n----\r\n{ ~ } \u00bb babun check                                                                          ~ \r\nExecuting babun check\r\nPrompt speed      [SLOW]\r\nHint: your prompt is very slow. Check the installed 'BLODA' software.\r\nConnection check  [OK]\r\nUpdate check      [OK]\r\nCygwin check      [OK]\r\n----\r\n\r\nOn each startup, but only every 24 hours, babun will execute this check automatically. You can disable the automatic check in the ~/.babunrc file.\r\n\r\n=== Tweaking the configuration\r\n\r\nYou can tweak some config options in the ~/.babunrc file. Here's the full list of variables that may be modified:\r\n----\r\n# JVM options\r\nexport JAVA_OPTS=\"-Xms128m -Xmx256m\"\r\n\r\n# Modify these lines to set your locale\r\nexport LANG=\"en_US.UTF-8\"\r\nexport LC_CTYPE=\"en_US.UTF-8\"\r\nexport LC_ALL=\"en_US.UTF-8\"\r\n\r\n# Uncomment these lines to the set your machine's default locale (and comment out the UTF-8 ones)\r\n# export LANG=$(locale -uU)\r\n# export LC_CTYPE=$(locale -uU)\r\n# export LC_ALL=$(locale -uU)\r\n\r\n# Uncomment this to disable daily auto-update & proxy checks on startup (not recommended!)\r\n# export DISABLE_CHECK_ON_STARTUP=\"true\"\r\n\r\n# Uncomment to increase/decrease the check connection timeout\r\n# export CHECK_TIMEOUT_IN_SECS=4\r\n\r\n# Uncomment this lines to set up your proxy\r\n# export http_proxy=http://user:password@server:port\r\n# export https_proxy=$http_proxy\r\n# export ftp_proxy=$http_proxy\r\n# export no_proxy=localhost\r\n----\r\n\r\n=== Updating babun\r\n\r\nTo update babun to the newest version execute:\r\n----\r\nbabun update\r\n----\r\nPlease note that your local configuration files will not be overwritten. \r\n\r\nThe 'babun update' command will also update the underlying cygwin version if never version is available. In such case babun will download the new cygwin installer, close itself and start the cygwin installation process. Once cygwin installation is completed babun will restart.\r\n\r\n== Screenshots\r\n\r\n\r\n[big]#Startup screen#\r\n\r\nimage::https://raw.githubusercontent.com/babun/babun.github.io/master/images/screenshots/screen_welcome.png[babun - a Windows shell you will love!, align=\"center\"]\r\n\r\n[big]#Pact - package installation#\r\n\r\nimage::https://raw.githubusercontent.com/babun/babun.github.io/master/images/screenshots/screen_pact_install.png[babun - a Windows shell you will love!, align=\"center\"]\r\n\r\n[big]#Pact - package installed#\r\n\r\nimage::https://raw.githubusercontent.com/babun/babun.github.io/master/images/screenshots/screen_pact_installed.png[babun - a Windows shell you will love!, align=\"center\"]\r\n\r\n[big]#Babun oh-my-zsh - auto-update#\r\n\r\nimage::https://raw.githubusercontent.com/babun/babun.github.io/master/images/screenshots/screen_zsh_update.png[babun - a Windows shell you will love!, align=\"center\"]\r\n\r\n\r\n[big]#VIM syntax highlighting#\r\n\r\nimage::https://raw.githubusercontent.com/babun/babun.github.io/master/images/screenshots/screen_vim.png[babun - a Windows shell you will love!, align=\"center\"]\r\n\r\n[big]#Nano syntax highlighting#\r\n\r\nimage::https://raw.githubusercontent.com/babun/babun.github.io/master/images/screenshots/screen_nano.png[babun - a Windows shell you will love!, align=\"center\"]\r\n\r\n[big]#Git aliases - git lg#\r\n\r\nimage::https://raw.githubusercontent.com/babun/babun.github.io/master/images/screenshots/screen_git_lg.png[babun - a Windows shell you will love!, align=\"center\"]\r\n\r\n[big]#Git aliases - git st#\r\n\r\nimage::https://raw.githubusercontent.com/babun/babun.github.io/master/images/screenshots/screen_git_st.png[babun - a Windows shell you will love!, align=\"center\"]\r\n\r\n[big]#Shell prompt#\r\n\r\nimage::https://raw.githubusercontent.com/babun/babun.github.io/master/images/screenshots/screen_shell.png[babun - a Windows shell you will love!, align=\"center\"]\r\n\r\n[big]#Babun update#\r\n\r\nimage::https://raw.githubusercontent.com/babun/babun.github.io/master/images/screenshots/screen_update.png[babun - a Windows shell you will love!, align=\"center\"]\r\n\r\n[big]#Open Babun here - Context Menu#\r\n\r\nimage::https://raw.githubusercontent.com/babun/babun.github.io/master/images/screenshots/screen_context_menu.png[babun - a Windows shell you will love!, align=\"center\"]\r\n\r\n\r\n== Development\r\n\r\n\r\n== Project structure\r\n\r\nThe project consists of five modules.\r\n\r\n=== babun-packages\r\n\r\nThe main goal of the `babun-packages` module is to download the cygwin packages listed in the `conf/cygwin.x86.packages` file.\r\nThe above mentioned packages will be downloaded together with the whole dependency tree. Repositories which the packages are downloaded from are listed in the `conf/cygwin.repositories` file. At the beginning the first repository is taken, if a package is not available in this repo the second repo is used, etc. The process continues until all packages have been downloaded. \r\n\r\nAll downloaded packages are stored in the `target/babun-packages` folder.\r\n\r\n=== babun-cygwin\r\n\r\nThe main goal of the `babun-cygwin` module is to download and invoke the native cygwin.exe installer. The packages downloaded by the babun-packages module are used as the input - all of them will be installed in the offline cygwin installation. \r\n\r\nIt is not trivial to install and zip a local instance of Cygwin - there are problems with the symlinks as the symlink-file-flags are lost during the compression process. Babun can work it around though. At first, just after the installation, the `symlinks_find.sh` script is invoked in order to store the list of all cygwin's symlinks. This file is delivered as a part of the the babun's core. Then, after babun is installed from the zip file on the user's host the `symlinks_repair.sh` script is invoked - it will correct all the broken symlinks listed in the above mentioned file.\r\n\r\nPreinstalled cygwin is located in the `target/babun-cygwin` folder.\r\n\r\n=== babun-core\r\n\r\nThe main goal of the `babun-core` module is to install babun's core along with all the plugins and tools. `install.sh` script is invoked during the creation of the distribution package in order to preinstall the plugins. Whenever babun is installed on the user's host the `install_home.sh` script is invoke in order to install the babun-related files to the cygwin-user's home folder.\r\n\r\nPreinstalled cygwin with installed babun is located in the `target/babun-cygwin` folder.\r\n\r\n=== babun-dist\r\n\r\nThe main goal of the `babun-dist` module is to zip the ready-made instance of babun, copy some installation scripts and zip the distribution.\r\n\r\nDistribution package is located in the `target/babun-dist` folder.\r\n\r\n=== babun-doc\r\n\r\nThis module contains documentation written in ASCIIDOC.\r\n\r\n\r\n== Building from source\r\n\r\nThe project is regularly build on Jenkins, on a slave node featuring the Windows Server OS. The Windows OS is required to fully build the distribution package as one of the goals invokes the native `cygwin.exe` installer. The artifacts created by each module are cached/stored in the target folder after a successful build of each step. This mechanism is not intelligent enough to calculate the diffs so if you would like to fully rebuild the whole dist package make sure to invoke the `clean` goal before the `package` goal. For now it's not possible to invoke a build of a selective modules only. \r\n\r\nIn order to build the dist package invoke:\r\n----\r\ngroovy build.groovy package \r\n----\r\n\r\nIn order to clean the project target folder invoke:\r\n----\r\ngroovy build.groovy clean \r\n----\r\n\r\nIn order to publish the release version to bintray invoke:\r\n----\r\ngroovy build.groovy release\r\n----\r\nThe release goal expects the following environment variables: `bintray_user` and `bintray_secret`\r\n\r\n== Developing a plugin\r\n\r\nEvery plugin has to consist of three main files:\r\n\r\n* install.sh - a file that will be executed during the creation of the babun's distribution\r\n* install_home.sh - a file that will be executed during the installation of babun to the user's home folder \r\n* plugin.desc - a plugin description that contains the plugin_name and plugin_version variables\r\n* start.sh (optional) - a file that will be executed on babun startup\r\n* exec.sh (optional) - a file that allows adding commands to babun script\r\n\r\nHave a look at the pact plugin - it's a perfect example of a relatively small plugin using all the features.\r\n\r\n=== install.sh\r\n\r\nIts main responsibility is to install the plugin - for example to copy the plugin files to, e.g. `/usr/local/etc` or `/usr/local/bin` directories. install.sh script is also responsible for preparing the user's home folder template. The template files have to be copied to the `/usr/local/babun/home/<plugin_name>` folder.\r\n\r\ninstall.sh will be invoked many times - on every plugin update if the plugin version is higher than the version of the installed plugin - thus it's logic has to work in an incremental way. This mechanism is invoked automatically though. The plugin does not have to contain the version check.\r\n\r\nThe script has to begin with the following statement:\r\n----\r\n#!/bin/bash\r\nset -e -f -o pipefail\r\nsource \"/usr/local/etc/babun/source/babun-core/tools/script.sh\"\r\n----\r\n\r\n=== install_home.sh\r\n\r\nIts main responsibility is to configure the user's home folder with the plugin related stuff, if necessary. For example, it may copy the files from the `/usr/local/babun/home/<plugin_name>` folder to the user's home folder.\r\nIt is also responsible for any other things that may be necessary during the user's home configuration process.\r\n\r\ninstall_home.sh will be invoked many times - on every plugin update if the plugin version is higher than the version of the installed plugin - thus it's logic has to work in an incremental way.\r\n\r\nBoth scripts (install.sh and install_home.sh) scripts have to begin with the following statement:\r\n----\r\n#!/bin/bash\r\nset -e -f -o pipefail\r\nsource \"/usr/local/etc/babun/source/babun-core/tools/script.sh\"\r\n----\r\n\r\n=== uninstall.sh (optional)\r\n\r\nIts responsibility is to cleanup all entries that a plugin may leave for example on the filesystem or in the windows registry.\r\n\r\n=== plugin.desc\r\n\r\nA plugin descriptor looks like this:\r\n----\r\n# plugin descriptor\r\nplugin_name=pact\r\nplugin_version=1\r\n----\r\n\r\nEvery time the plugin is changed the version has to be incremented. Otherwise the newest version will not be installed.\r\n\r\n=== start.sh (optional)\r\n\r\nThe start.sh is an optional script for plugins that require triggering certain actions on every babun start (for example update check).\r\n\r\n=== exec.sh (optional)\r\n\r\nIf the plugin folder contains an exec.sh script, \r\nwhenever `babun <plugin_name> xxx yyy` command is invoked, the execution is passed to `<plugin_name>/exec.sh` script with params `xxx yyy`. \r\nIn this way a plugin may add some additional shell commands without implementing its own `/usr/local/bin/xxx` script.\r\n\r\n== Branches\r\n\r\nThe babun's repository contains three main branches:\r\n\r\n* master - development branch\r\n* candidate - release candidate branch, no direct commits, only fast forwards from the master/other branch\r\n* release - release, no direct commits, only fast forwards from the candidate branch\r\n\r\nIn order to check babun update against other branch (for example during a development of a plugin), set the babun_branch variable to (master or candidate). External repo's are not supporter (this mechanism has to be extended to include user's repos).\r\n\r\n== Folder structure in Cygwin\r\n\r\nAn instance of babun installed in Cygwin is located in the `/usr/local/etc/babun` folder.\r\nThe folder structure looks like this:\r\n----\r\n\u251c\u2500\u2500 babun\r\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 external\r\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 oh-my-zsh\r\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 home\r\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 core\r\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 oh-my-zsh\r\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 pact\r\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 shell\r\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 installed\r\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 babun\r\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 cacert\r\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 core\r\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 git\r\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 oh-my-zsh\r\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 pact\r\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 shell\r\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 source\r\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 babun.version\r\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 babun-core\r\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 babun-cygwin\r\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 babun-dist\r\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 babun-doc\r\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 babun-packages\r\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 build.groovy\r\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 README.adoc\r\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 stamps\r\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 check\r\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 welcome\r\n\u251c\u2500\u2500 babun.bash\r\n\u251c\u2500\u2500 babun.instance\r\n\u251c\u2500\u2500 babun.rc\r\n\u251c\u2500\u2500 babun.start\r\n\u2514\u2500\u2500 babun.zsh\r\n\r\n16 directories, 17 files\r\n----\r\n\r\n=== source\r\n\r\nThe folder contains the sources of babun checkout from github.\r\n\r\n=== stamps\r\n\r\nThe folder contains files which modification time indicates certain things to babun. For example `babun check` is executed automatically on babun's start up every 24 hours. Whenever it's invoked a file named `checked` is being modified (the content of the modification does not matter).Whenever the mod_time of this file is not within 24 hours and babun is being started a `babun check` will be invoked and the file `check` located in the `stamps` folder will be modified again.\r\n\r\n=== installed\r\n\r\nThe folder contains files that indicated which versions of babun's plugins and babun itself are installed. Each file contains a number - for example: a file named `core` contains has one line with number `2` in its content. It means that the plugin `core` is installed and has version `2`\r\n\r\n=== external\r\n\r\nThe folder contains external resources, like cloned repos of other projects (for example oh-my-zsh).\r\n\r\n=== home\r\n\r\nThe folder contains folders named like plugins. If a plugin needs to install something to user's folder this content has to be copied to `home/<plugin_name>` folder. It's just a store of the user's home files, so that whenever a new user's account is created babun can install user's home related content to the user's home folder (it's the plugin install_home.sh script's responsibility, however, to copy this content to the actual user's home folder). \r\n\r\n\r\n== Licence\r\n\r\nThe source code located in the babun's repository is published under the Apache License, Version 2.0, January 2004 if not stated otherwise. \r\n\r\nSince the distribution (zip) package contains the Cygwin's DLLs the distribution package is licensed under the GPLv3+ licence to satisfy the Cygwin's licensing terms (http://cygwin.com/licensing.html).\r\n\r\n== Supporters\r\n\r\nSpecial thanks go to companies who provided free hosting! \r\n\r\n=== XCLOUD\r\n\r\nhttp://xcloud.me/[XCLOUD.ME] provided a free hosted OS X instance (a free Xcloud Mini Server subscription). It works like a charm! Thank you!\r\n\r\nimage::https://raw.githubusercontent.com/babun/babun.github.io/master/images/xcloud_logo.png[\"XCLOUD\", link=\"http://xcloud.me/\", window=\"_blank\"]\r\n\"Run, manage and scale your virtual dedicated OS X Server in the Cloud.\"\r\n\r\n_XCLOUD is a trademark of AG from Switzerland._\r\n\r\n=== Windows Azure\r\n\r\nhttp://www.azure.microsoft.com[Windows Azure] provided a free Windows Hosting (a free, renewable MSDN subscription). Everything was organised by @bureado. Thank you!\r\n\r\nimage::https://raw.githubusercontent.com/babun/babun.github.io/master/images/ms_azure_logo.png[\"Windows Azure\", link=\"http://www.azure.microsoft.com\", window=\"_blank\"]\r\n\r\n_Microsoft and Windows are registered trademarks of Microsoft Corporation in the United States of America and other countries. Windows Azure is a trademark of Microsoft Corporation._\r\n\r\n\r\n== Contribute\r\n\r\nBabun is open source and driven by the community. There are many ways to contribute:\r\n\r\n* Use it and tell us what you think\r\n* Recommend it to your friends\r\n* Submit a https://github.com/babun/babun/issues[feature request] or a https://github.com/babun/babun/issues[bug report]\r\n* Fork it on https://github.com/babun/babun[github] and submit pull request\r\n* Motivate the community, tweet about the project and star it on github :)\r\n\r\nWe are looking for new contributors, so if you fancy bash programming and if you would like to contribute a patch or a code up a new plugin give us a shout!\r\n\r\nVisit the http://babun.github.io/development/[development] section to find out how to create plugins and extensions.\r\n\r\n== Meet the team\r\n\r\nhttps://twitter.com/tombujok[@tombujok]\r\n\r\nhttps://twitter.com/lukaszpielak[@lukaszpielak]\r\n\r\nimage::https://d2weczhvl823v0.cloudfront.net/reficio/babun/trend.png[\"Bitdeli Badge\", link=\"https://bitdeli.com/free\"]\r\n"}, {"repo": "/xamarin/flex", "language": "C", "readme_contents": "# flex\n\nflex is a flexible box layout system following the <a href=\"https://www.w3.org/TR/css-flexbox-1/\">CSS flexbox module</a> specifications. The goal is to offer a fully compliant implementation with a small and maintainable code base under a permissive license.\n\nflex exposes a plain C API with the same parameters that you would use in CSS to customize the layout of a flexible view hierarchy. The API is designed to be easily interoperable with foreign runtimes (ex. C#) and meant to be used by widget toolkits as the foundation of a view layout API.\n\nflex supports both single and multiple (wrap) lines layouts.\n\n## Getting Started\n\nIf you program in C# you can go straight to the [bindings/csharp](bindings/csharp) directory.\n\nIf you program in a C-compatible environment you can simply copy the `flex.c` and `flex.h` files to your project. The code was written to be cross-platform and does not require dependencies.\n\nOn a Mac you can also generate static and dynamic libraries for iOS, Android and macOS using `make`:\n\n```\n$ make macos\n$ make ios\n$ make android\n$ make             # builds everything\n```\n\nMake sure to have the `ANDROID_NDK` environment variable set to the path where the Android NDK is located in your system. You can also tweak build variables by editing the `Makefile` file.\n\nOn a Windows machine you can generate dynamic libraires (DLL) for x86, x64, ARM and ARM64 by opening the Visual Studio project file or running `msbuild` from the command line.\n\n## Demo App\n\nUnder the `demo` directory you will find an Xcode project that will build a Mac demo app. The app exposes the entire set of flexbox parameters that are implemented and lets you create views (including nested ones), similar to how you would build a more realistic user interface in practice.\n\n## Implementation Status\n\n| Attribute | Status |\n|---|---|\n| width, height | :ok: |\n| self_sizing | :ok: |\n| padding | :ok: |\n| margin | :ok: |\n| justify_content flex_start | :ok: |\n| justify_content flex_end | :ok: |\n| justify_content center | :ok: |\n| justify_content space_around | :ok: |\n| justify_content space_between | :ok: |\n| justify_content space_evenly | :ok: |\n| align_content flex_start | :ok: |\n| align_content flex_end | :ok: |\n| align_content center | :ok: |\n| align_content space_around | :ok: |\n| align_content space_between | :ok: |\n| align_content space_evenly | :ok: |\n| align_content stretch | :ok: |\n| align_items flex_start | :ok: |\n| align_items flex_end | :ok: |\n| align_items center | :ok: |\n| align_items stretch | :ok: |\n| align_self flex_start | :ok: |\n| align_self flex_end | :ok: |\n| align_self center | :ok: |\n| align_self stretch | :ok: |\n| position relative | :ok: |\n| position absolute | :ok: |\n| direction column | :ok: |\n| direction column_reverse | :ok: |\n| direction row | :ok: |\n| direction row_reverse | :ok: |\n| wrap no_wrap | :ok: |\n| wrap wrap | :ok: |\n| wrap wrap_reverse | :ok: |\n| grow | :ok: |\n| shrink | :ok: |\n| order | :ok: |\n| basis | :ok: |\n\n## Tests\n\nThere is a test suite in the `tests` directory. See the [tests/README.md](tests/README.md) file for more details on how to build, run and contribute to the test suite.\n\n## License\n\nflex is distributed under the terms of the MIT license. See the `LICENSE.txt` file for more information.\n"}, {"repo": "/cbitosc/CBIT-Hacktoberfest-Hackathon-Hello-World", "language": "C", "readme_contents": "# Welcome to CBIT Hacktoberfest Hackathon 2018\n> This Project aims to help you to get started with using Github. You can find a tutorial [here](https://guides.github.com/activities/hello-world/)\n\n![poster](https://user-images.githubusercontent.com/22680912/46479049-d8a9c400-c80b-11e8-92a1-89fc10701f4a.jpg)\n\n# What is Hacktoberfest?\nHacktoberfest is a program by Digital Ocean and Github, where you can easily win a T-Shirt just by making 5 pull requests in the month of October to any open source projects on Github.\n\n## Steps to follow :scroll:\n\n### 1. Register for Hacktoberfest\nYou can register from [here](https://hacktoberfest.digitalocean.com).\n\n### 2. Fork it :fork_and_knife:\n\nYou can get your own fork/copy of [Hello-world](https://github.com/cbitosc/Hacktoberfest-Hackathon-Hello-World) by using the <a href=\"https://github.com/cbitosc/Hacktoberfest-Hackathon-Hello-World/new/master?readme=1#fork-destination-box\"><kbd><b>Fork</b></kbd></a> button or clicking [this](https://github.com/cbitosc/Hacktoberfest-Hackathon-Hello-World/new/master?readme=1#fork-destination-box).\n\n [![Fork Button](https://help.github.com/assets/images/help/repository/fork_button.jpg)](https://github.com/cbitosc/Hacktoberfest-Hackathon-Hello-World)\n\n### 3. Add a Program in any Language you like :rabbit2:\nOnce you have forked the repo, add your program in the language folder in \nmain branch, if there is no language folder, make one, then add into it.\nYou can take a look to the [Programming Language List](https://en.wikipedia.org/wiki/List_of_programming_languages) in Wikipedia to create a new one HelloWorld !\n\n### 4. Ready, Steady, Go... :turtle: :rabbit2:\n\nOnce you have completed these steps, you are ready to start contributing \nby checking our `Help Wanted` issues and creating [pull requests](https://github.com/cbitosc/Hacktoberfest-Hackathon-Hello-World/pulls).\n\n### 5. Give this Project a Star :star:\n\nIf you liked working on this project, please share this project as much \nas you can and star this project to help as many people in opensource as you can.\n\n:tada: :confetti_ball: :smiley: _**Happy Contributing**_ :smiley: :confetti_ball: :tada:\n"}, {"repo": "/Shougo/vimshell.vim", "language": "Vim script", "readme_contents": "# VimShell\n\nFor information, check [doc/vimshell.txt](doc/vimshell.txt).\n\n**Note**: Active developement on vimshell.vim has stopped. The only future changes will be bug fixes.\n\nYou should use [Deol.nvim](https://github.com/Shougo/deol.nvim) instead.\n\n## Resources\n\n- [Code @ HootSuite | VimShell](http://code.hootsuite.com/vimshell/)\n\n## Screen shots\n\n![](https://f.cloud.github.com/assets/980000/982716/eb45a994-0817-11e3-806e-ce6e731b86ef.png)\n"}, {"repo": "/allinurl/gwsocket", "language": "C", "readme_contents": "What is it?\n-----------\ngwsocket is a standalone, simple, yet powerful rfc6455 compliant WebSocket\nServer, written in C.\n\nWhy?\n----\nI needed a simple, fast, no-dependencies, RFC6455 compliant WebSocket Server\nwritten in C that I could use as a library for the upcoming version (v1.0) of\nGoAccess by simply piping data in and out.\n\nFeatures\n-------\n* Message Fragmentation per section 5.4\n* UTF-8 Handling\n* Framing (Text & Binary messages)\n* Multiplexed non-blocking network I/O\n* Ability to pipe data in/out in two different modes (stdin/stdout & strict mode)\n* It passes the Autobahn Testsuite :)\n* and of course, Valgrind tested.\n* missing something?, please feel free to post it on Github.\n\nHow it Works?\n-------------\nVery simple, just pipe your data out of your application and let gwsocket do\nthe rest. e.g.: tail -f /var/log/nginx/access.log > /tmp/wspipein.fifo\n\nBy the way, you can also pipe the client's data into your application.\n\nNote: You can even send your favorite NCurses program's output. See\nhttps://github.com/allinurl/gwsocket.\n\nMore Examples?\n-------------\nLooking for more examples and details on how it works? Head to the man page for\nmore details. Or visit http://gwsocket.io\n"}, {"repo": "/gnudatalanguage/gdl", "language": "C++", "readme_contents": "                    GDL - GNU Data Language\n                    =======================\n\nA free IDL (Interactive Data Language) compatible incremental compiler\n(capable of running programs written in IDL/GDL).\nIDL is a registered trademark of Harris Geospatial (see: http://harrisgeospatial.com/).\n\n\nHOMEPAGE:\n=========\n\nhttp://gnudatalanguage.sourceforge.net\n\n\nFEATURES:\n=========\n\nFull syntax compatibility with IDL up to version 7.1...\n...    and trying to be up-to-date with 8.x, see below.\n\nAll IDL language elements up to IDL version 7.1 are supported, including:\n\nPointer, objects, structs,\narrays, system variables,\ncommon blocks, assoc variables,\nall operators, all datatypes,\n_EXTRA, _STRICT_EXTRA and _REF_EXTRA keywords...\n\nGDL provides all of the GUI support (widgets) of IDL (see below). \n\nSupported IDL 8.0 language elements:\n\nFOREACH loop\nnegative array indices\ngarbage collection pointers and objects\ncall methods on an object using \".\" (e. g. object.aMemberProcedure,arg1)\nempty arrays and !NULL system variable\nautomatic promotion of FOR loop variable types\nLIST and HASH types\n\nNot yet supported:\nsimplified property access on objects (e. g. object.aProperty = value & print,object.aProperty)\n\nIn general GDL should run correctly an IDL procedure, even one from the /lib folder of an IDL distribution.\n(Note that most of theses procedures---some can be found on the web---have not yet been rewritten for GDL, help is welcome.).\n\n\nThe file input output system is fully implemented including full support of\nF77_UNFORMATTED.\n\nnetCDF files are fully supported.\nHDF4 files are supported.\nBasic support for HDF5 files.\n\nDICOM files are supported via the GDLffDICOM object (http://idl.barnett.id.au/idl-projects)\n(files in the src/pro/dicom subdirectory).\n\nOverall more than 400 library routines are implemented.\nFor a list enter HELP,/LIB at the command prompt and look for\nlibrary routines written in GDL in the src/pro subdirectory.\n\nGraphical output is almost completely implemented (no object-graphics). \nThe PLOT, OPLOT, PLOTS, XYOUTS, SURFACE, CONTOUR and TV commands (along with WINDOW, \nWDELETE, SET_PLOT, WSET, TVLCT, LOADCT) are working (most keywords,\n!P system variable tags and multi-plots are supported) for X windows,\nz-buffer and postscript output.\n\nGDL has an interface to python.\nPython can be embedded into GDL and GDL can be compiled as a\npython module. See the file PYTHON.txt for details.\n\nFor the thread pool OpenMP is utilized if the compiler supports it.\n\n\nREQUIREMENTS:\n=============\n\nIn short:\nMandatory libraries:\nplplot      http://plplot.sourceforge.net/source/index.html\ngsl         http://www.gnu.org/software/gsl\nreadline    http://ftp.gnu.org/pub/gnu/readline/readline-4.3.tar.gz\nzlib        http://www.zlib.net/\n\nOptional libraries:\nEigen       http://eigen.tuxfamily.org\nImageMagick http://www.imagemagick.org/www/download.html\nnetCDF *)   ftp://ftp.unidata.ucar.edu/pub/netcdf\nHDF4 *)     ftp://ftp.ncsa.uiuc.edu/HDF/HDF/HDF_Current\nHDF5        ftp://ftp.ncsa.uiuc.edu/HDF/HDF5/current\nFFTW        http://www.fftw.org/download.html\npython      http://www.python.org\nlibproj4    (consult the MAP_INSTALL file)\nUDUNITS-2   http://www.unidata.ucar.edu/software/udunits/\nGRIB API    http://www.ecmwf.int/products/data/software/grib_api.html        \nshp         http://shapelib.maptools.org/ (consult the MAP_INSTALL file)\nwxWidgets   http://www.wxwidgets.org/\npslib       http://pslib.sourceforge.net/\nglpk        https://www.gnu.org/software/glpk/  : only to have the linear programming function SIMPLEX() available.\n\nOnly with python:\nnumpy          http://numpy.scipy.org/\n\n*) please see below for potential problems using netCDF and HDF4\n\nCOMPILING:\n----------\n  At least g++ 3.2 (or a similar C++ standard conforming\n  compiler) is needed for compiling GDL.\n  Note that due to problems with static casts g++ 3.3.1\n  does NOT compile GDL, but 3.3.2 and 3.4.1 work fine again.\n  GDL compiles under Mac OS X (10.2, 10.3) with g++ 3.3 . \n   \n  If you install the libraries as precompiled\n  packages rather than compiling them from sources, please note that\n  depending on your distribution, you may need development packages\n  as well. Examples are (for Fedora):\n  plplot-devel\n  ImageMagick-devel\n  ImageMagick-c++-devel\n\n  Look at the *INSTALL* files.\n\nLINE EDITING:\n-------------\n  Better than IDL, GDL has modern line editing and line history features.\n  The GNU readline library 4.3 is needed (actually GDL should compile\n  without, but its very inconvenient to use that way, furthermore\n  proper event handling for graphic windows requires readline).\n  You can get it at:\n  http://ftp.gnu.org/pub/gnu/readline/readline-4.3.tar.gz\n  \nGRAPHICS AND DEPENDENCIES:\n--------------------------\n  For the graphics support of GDL, the plplot library version >5.9.6 is necessary. \n  PLplot >= 5.9.9 is recommended, but plplot > 10 is tricky (see below).\n  To download plplot please look here:\n  http://plplot.sourceforge.net/source/index.html\n  \n  A possible problem was reported:\n  On opening more than one window, plplot causes a segmentation fault\n  if GDL is compiled with ImageMagick. This happens if plplot uses \n  dynamic drivers.\n  The current solution is to disable dynamic drivers for plplot\n  (-DENABLE_DYNDRIVERS=OFF option for cmake).\n  Current ubuntu/debian distributions are using dynamic drivers, so plplot\n  needs to be compiled from source there. Disabling dyndrivers apparently is not necessary anymore.\n  \n  plplot > 5.11 needs absolutely to be compiled with its \"old\" wxWidgets driver,\n  using the Cmake switch -DOLD_WXWIDGETS:BOOL=ON . Otherwise the WIDGET_DRAW and possibly the graphics window *will not work*.\n  Plplot is not flexible enough to provide both drivers, and the new driver insists on making its own windows!\n  Distributions that provide plplot and plplot-devel have probably not used -DOLD_WXWIDGETS:BOOL=ON\n  so you'll need to compile plplot yourself with this option\n  (and the options -DCMAKE_BUILD_TYPE=Release -DCMAKE_CXX_FLAGS_RELEASE='-O3' for efficiency), install it somewhere\n  (so add also the with option -DCMAKE_INSTALL_PREFIX=\"somewhere\"), and provide -DPLPLOTDIR=\"somewhere\" while cmaking GDL.\n\nMATCH FUNCTIONS & MORE:\n-----------------------\n  GDL uses the GNU Scientific Library (GSL).\n  Please see file HACKING if you want to write functions extending GDL (i. e.\n  add a library subroutine) which use GSL for proper handling of GSL\n  obects in GDL.\n  (Minimal version is 1.7, which is now checked via \"gsl.m4\".\n  Note that version 1.1.1 was reported to NOT work with GDL)\n  You find it at:\n  http://www.gnu.org/software/gsl\n\nMAKE GDL FASTER:\n----------------\n  GDL uses Eigen for fast matrix multiplication. (optional)\n\n  The Eigen library version 3.1 or later is highly recommended for a performance\n  boost, expecially on multi-cores. To be found at: http://eigen.tuxfamily.org, \n  but is probably installed on your computer and will be found by the installer.\n\n  The simpliest way to compile with it is to copy all the header files\n  under sub-directory src/Eigen. Another solution is to provide full path\n  to the include files (e.g. --with-eigen=/home/toto/Eigen3.1.4/include/eigen3/\n  in that case Eigen would have been prepared using:\n  cmake . -DCMAKE_INSTALL_PREFIX=/home/toto/Eigen3.1.4/ )\n\n  The FFTW library is (optionally) used for the FFT function.\n  It is available at: http://www.fftw.org/download.html\n  It is NOT used by default.\n  If you want to use it, use --with-fftw=DIR \n  as a command line option to 'configure', where DIR denotes the\n  directory into which FFTW was installed\n  ('/lib' is appended for the library, '/include' for the include files).\n  Using FFTW results in an about double as fast FFT function.\n  Take care that you have to compile the \"normal\" and the \"single\"\n  version of the library (resp. libfftw3.a and libfftw3f.a).\n  First one is the default. You have to activate the single flag\n  (./configure --enable-single) when recompiling FFTw3.\n  Please also notice that the test when runnig GDL configure\n  \"checking for fftw_malloc in -lfftw3... yes\"\n  will failed if libfftw3f.a is missing.\n  As mentionned in the log. of ./configure,\n  if FFTw is not used, the default (GSL) fft routine is used instead.\n\nWIDGETS:\n--------\n  GDL supports GUI (widget) programming (initial effort by Joel Gales rewritten by Gilles Duvert)\n  using the wxWidgets library. It is required by default.\n  If you don't want to use it, use\n  --with-wxWidgets=no (configure) or -DWXWIDGETS=off (CMake)\n  wxWidgets can be obtained from:\n  http://www.wxwidgets.org/downloads\n  \n  The wxWidget version must be 2.8.1 or higher. Unfortunately the wxWidget implementation of the plplot graphic library\n  has changed between plplot 5.9.9 and plplot 5.11, and there are incompatibilities between plplot versions ans wxWidget versions.\n  Stable behaviour has been obtained with plplot 5.9.9 and wxWidgets 2.8.  \n  \n  The WIDGET_*... functions are all implemented (use HELP,/LIB for an overview). Only a few\n  rarely seen options have not been written yet (please report in case of need). They have\n  not been tested outside the linux \"mageia\" distribution yet, so errors and crashes are possible.\n  Most procedures using widgets available (e.g., in the astrolib library) use so-called\n  \"compound widgets\" (CW_xxxxx functions that are written in IDL, like CW_FIELD). Those have not\n  been rewritten in GDL (and some have not been thoroughly tested). Those are not present\n  in the GDL distribution (copyright issues), must be obtained separately (google is your friend) and put\n  in the GDL path before use.\n\nDATA FORMATS:\n=============\n\n  HDF4 Files:\n  ----------\n    The HDF4 format is (not completely yet) supported (thanks to Joel Gales).\n    If you want to use it, you need the HDF library (here HDF\n    always means version 4).\n    Note that if you plan to use netCDF also, it might be necessary to\n    install HDF4 before netCDF due to same named but different header\n    files which are overwritten by the HDF4 version otherwise.\n    HDF4 is required by default. If you don't want to use it, use \n    --with-hdf=no (configure) or -DHDF=off (CMake)\n    Note that HDF in turn needs other libraries. Check out the\n    homepage for more information:\n    http://hdf.ncsa.uiuc.edu/\n    The HDF library can be downloaded from:\n    ftp://ftp.ncsa.uiuc.edu/HDF/HDF/HDF_Current\n\n  HDF5:\n  -----\n    Basic support for HDF5 is now provided (thanks to Peter Messmer).\n    If you want to use it, you need the HDF5 library.\n    It is required by default. If you don't want to use it, use \n    --with-hdf5=no (configure) or -DHDF5=off (CMake)\n    Note that HDF5 in turn needs other libraries. Check out the\n    homepage for more information:\n    http://hdf.ncsa.uiuc.edu/HDF5\n    The HDF5 library can be downloaded from:\n    ftp://ftp.ncsa.uiuc.edu/HDF/HDF5/current\n\n  NETCDF:\n  -------\n    The netCDF format is fully supported (thanks to Christopher Lee). If\n    you want to use netCDF, you need the netCDF library (even if HDF4 is\n    used, the netCDF library is needed, as the HDF library does not\n    contain all needed netCDF functions. Note that it might be necessary\n    to install netCDF after HDF4 due to same named, but different header\n    files. If the header files of HDF4 and netCDF are in different directories \n    make sure, that the directory containing netCDF's version gets searched first,\n    ie. put an explicit path for netCDF even if it is in the default include path,\n    eg: --with-netcdf=/usr (configure) or -DNETCDFDIR=/usr (CMake)) \n    netCDF is used by default. If you don't want to use it, use \n    --with-netcdf=no (configure) or -DNETCDF=off (CMake)\n    as a command line option to 'configure'.\n    netCDF is available from:\n    ftp://ftp.unidata.ucar.edu/pub/netcdf\n\n  From the HDF4 INSTALL file:\n     To use the HDF/MFHDF libraries (libdf.a, libmfhdf.a) with the original\n     netCDF library (libnetcdf.a), the HDF4 distribution must be configured \n     with the --disable-netcdf configuration flag.  This will rename the HDF \n     version of the C interface (ncxxx) of the HDF4 netCDF APIs to sd_ncxxx \n     and will disable the HDF4 NC Fortran interfaces to avoid name clashes \n     with the original netCDF C and Fortran APIs from libnetcdf.a.  \n\n  IMAGE FORMATS:\n  --------------\n    In order to read and write images in several formats\n    (e.g. JPEG, PNG), GDL uses ImageMagick.\n    It is required by default. If you don't want to use it, use \n    --with-Magick=no\n    ImageMagick can be obtained from:\n    http://www.imagemagick.org/www/download.html\n\nMAP PROJECTIONS and GEOPHYSICS:\n----------------\n  GDL contains now a complete support to MAP projection,\n  using the proj4 or libproj library. Please see MAP_INSTALL file.\n  It is NOT used by default.\n  If you want to use it, use --with-libproj4=DIR\n\n  GDL uses libshp (shapelib) to implement MAP_CONTINENTS - see MAP_INSTALL (optional)\n\nPYTHON INTERFACE:\n-----------------\n  GDL has an interface to python (see http://www.python.org). \n  GDL can be used as a python module and python can be used from\n  within GDL. See INSTALL for details on how to build each version.\n  As so far there are only two example GDL extensions written in python its\n  use is optional for now but required by default. If you don't want to use\n  it, use  \n  --with-python=no\n  as a command line option to 'configure'.\n  If you want to use it you need python and the python package Numpy.\n  (http://numpy.scipy.org/).\n  The GDL configure script will determine the installed python version\n  automatically. For this the python executable must be installed.\n  The python version can be explictely set with \n  --enable-python_version=VERSION# (eg. --enable-python_version=2.3).\n  Note: For embedding python as it is done by GDL, the python dynamic\n  library is needed which is *not* build by default. You need to run\n  'configure' for python with the '--enable-shared' option. Please see\n  the python README file for details.\n  For nice graphical output the python package matplotlib\n  (http://matplotlib.sourceforge.net) is used in one of the examples.\n  See the file PYTHON.txt for more details.\n\nOTHER SUPPORT LIBRARIES:\n------------------------\nGDL supports unit converion in IMSL_CONSTANT using the UDUNITS-2\nlibrary (http://www.unidata.ucar.edu/software/udunits/)\nIf you want to use it, use --with-udunits=DIR\n\nGDL supports the GRIB file format - see README_GRIB (optional)\n\nGDL uses pslib for fine-tuning PostScript output. (optional)\n\nGDL 0.9 was developed using ANTLR 2.7,   \nbut unless you want to change the grammar (*.g files) you don't need\nANTLR (for building GDL). All relevant ANTLR files are included in the package.\nFor editing however, there are several antlr-grammar (*.g) files among the\nsources. ANTLR generates from this grammar-files c++ source files.\nANTLR generated files should not be changed directly as the changes\nwould be undone if someone regenerates those files. Instead the relevant\ngrammar file (mentioned in the header of the generated file) must be edited\nand run through ANTLR. All source files generated by ANTLR start with a capital\ncharacter. All regular source files start with a small character.\nFor more information on ANTRL see: http://www.antlr.org\n\nGDL is developed by some using NetBeans (https://netbeans.org/)\nalthough a KDevelop project file is included in the tarball, \nso if you have KDevelop you should be able to use it with GDL seamlessly.\n\n\nINSTALLATION:\n=============\n\nPlease see the *INSTALL* file(s) for details.\nFor an alternative installation using CMake see INSATLL.CMake .\n\nFor french readers, please have a look to\nhttp://aramis.obspm.fr/~coulais/IDL_et_GDL/memo_GDL.html\nwhich explain how to install GDL and most libraries\nfrom scratch and without being root.\n\n\nCONTRIBUTIONS:\n==============\n\nGDL 0.9 is actively developed, but due to the vast amount of subroutines\nto implement, GDL is still in beta state.\nEven though it is commonly used by clever people for several tasks, there are many\nthings to be done.\nBug reports, feedback in general and interested people who would\nlike to join this project are welcome.\nExtensions to GDL can be made in C++, GDL or python.\n \nUrgent things to do are:\nTHE DOCUMENTATION!\nTesting and test routines written in GDL,\n\n\nHACKING:\n========\n\nplease see file HACKING for details.\nThere you find also information about LINKIMAGE.\n\n\nCONTACT:\n========\n\nComments are welcome. Let me know what you use GDL for. Or if you don't,\nwhy not. Which functionality are you missing/would appreciate most for\ncomming versions.\n\nFor bug reports, complaints, suggestions and comments, please\nuse the issue-tracking tool at: https://github.com/gnudatalanguage/gdl\n\n\nLICENSE:\n========\n\nThis program is free software; you can redistribute it and/or modify\nit under the terms of the GNU General Public License as published by\nthe Free Software Foundation; either version 2 of the License, or\n(at your option) any later version.\n\nThis program is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU\nGeneral Public License for more details.\n\n(It should be included in this package in the file COPYING )\n"}, {"repo": "/saffsd/langid.c", "language": "C", "readme_contents": "================\n``langid.c`` readme\n================\n\nIntroduction\n------------\n`langid.c` is an experimental implementation of the language identifier\ndescribed by [1] in pure C. It is largely based on the design of\n`langid.py`[2], and uses `langid.py` to train models. \n\nPlanned features\n----------------\nSee TODO\n\nSpeed\n-----\n\nInitial comparisons against Google's cld2[3] suggest that `langid.c` is about\ntwice as fast.\n\n    (langid.c) @mlui langid.c git:[master] wc -l wikifiles \n    28600 wikifiles\n    (langid.c) @mlui langid.c git:[master] time cat wikifiles | ./compact_lang_det_batch > xxx\n    cat wikifiles  0.00s user 0.00s system 0% cpu 7.989 total\n    ./compact_lang_det_batch > xxx  7.77s user 0.60s system 98% cpu 8.479 total\n    (langid.c) @mlui langid.c git:[master] time cat wikifiles | ./langidOs -b > xxx           \n    cat wikifiles  0.00s user 0.00s system 0% cpu 3.577 total\n    ./langidOs -b > xxx  3.44s user 0.24s system 97% cpu 3.759 total\n\n    (langid.c) @mlui langid.c git:[master] wc -l rcv2files \n    20000 rcv2files\n    (langid.c) @mlui langid.c git:[master] time cat rcv2files | ./langidO2 -b > xxx     \n    cat rcv2files  0.00s user 0.00s system 0% cpu 31.702 total\n    ./langidO2 -b > xxx  8.23s user 0.54s system 22% cpu 38.644 total\n    (langid.c) @mlui langid.c git:[master] time cat rcv2files | ./compact_lang_det_batch > xxx \n    cat rcv2files  0.00s user 0.00s system 0% cpu 18.343 total\n    ./compact_lang_det_batch > xxx  18.14s user 0.53s system 97% cpu 19.155 total\n\n\nModel Training\n--------------\n\nGoogle's protocol buffers [4] are used to transfer models between languages. The\nPython program `ldpy2ldc.py` can convert a model produced by langid.py [2] into\nthe protocol-buffer format, and also the C source format used to compile an\nin-built model directly into executable.\n\nDependencies\n------------\nProtocol buffers [4]\nprotobuf-c [5]\n\nContact\n-------\nMarco Lui <saffsd@gmail.com>\n\nReferences\n----------\n[1] http://aclweb.org/anthology-new/I/I11/I11-1062.pdf\n[2] https://github.com/saffsd/langid.py\n[3] https://code.google.com/p/cld2/\n[4] https://github.com/google/protobuf/\n[5] https://github.com/protobuf-c/protobuf-c\n"}, {"repo": "/spring-projects/spring-shell", "language": "Java", "readme_contents": "= Spring Shell 3\n\nSpring Shell 3 is a work to solely depend on Spring Boot 2.x and not trying to keep\nany backward compatibility with older Spring Shell 1.x nor Spring Boot 1.x.\n\n== Building\n```\n./mvnw package\n```\n\n== Running\nThe project comes with a sample application, showcasing the various ways you can write commands.\n\n```\n./mvnw install\n./mvnw -pl spring-shell-samples spring-boot:run\n```\n\nFrom there, try typing `help` or `help <commmand>` at the shell prompt.\n\n"}, {"repo": "/mn416/QPULib", "language": "C++", "readme_contents": "# QPULib\n\nVersion 0.1.0.\n\nQPULib is a programming language and compiler for the [Raspberry\nPi](https://www.raspberrypi.org/)'s *Quad Processing Units* (QPUs).\nIt is implemented as a C++ library that runs on the Pi's ARM CPU,\ngenerating and offloading programs to the QPUs at runtime.  This page\nintroduces and documents QPULib.  For build instructions, see the\n[Getting Started Guide](Doc/GettingStarted.md).\n\n## Contents\n\n* [Background](#background)\n* [Example 1: Euclid's Algorithm](#example-1-euclids-algorithm)\n    * [Scalar version](#scalar-version)\n    * [Vector version 1](#vector-version-1)\n    * [Invoking the QPUs](#invoking-the-qpus)\n    * [Vector version 2: loop unrolling](#vector-version-2-loop-unrolling)\n* [Example 2: 3D Rotation](#example-2-3d-rotation)\n    * [Scalar version](#scalar-version-1)\n    * [Vector version 1](#vector-version-1-1)\n    * [Vector version 2: non-blocking loads and stores](#vector-version-2-non-blocking-loads-and-stores)\n    * [Vector version 3: multiple QPUs](#vector-version-3-multiple-qpus)\n    * [Performance](#performance)\n* [Example 3: 2D Convolution (Heat Transfer)](#example-3-2d-convolution-heat-transfer)\n    * [Scalar version](#scalar-version-2)\n    * [Vector version](#vector-version)\n    * [Performance](#performance-1)\n* [References](#user-content-references)\n\n## Background\n\nThe\n[QPU](http://www.broadcom.com/docs/support/videocore/VideoCoreIV-AG100-R.pdf)\nis a [vector\nprocessor](https://en.wikipedia.org/wiki/Vector_processor) developed by\n[Broadcom](http://www.broadcom.com/) with\ninstructions that operate on 16-element vectors of 32-bit integer or\nfloating point values.\nFor example, given two 16-element vectors\n\n`10 11 12 13` `14 15 16 17` `18 19 20 21` `22 23 24 25`\n\nand\n\n`20 21 22 23` `24 25 26 27` `28 29 30 31` `32 33 34 35`\n\nthe QPU's *integer-add* instruction computes a third vector\n\n`30 32 34 36` `38 40 42 44` `46 48 50 52` `54 56 58 60`\n\nwhere each element in the output is the sum of the\ncorresponding two elements in the inputs.\n\nEach 16-element vector is comprised of four *quads*.  This is where\nthe name \"Quad Processing Unit\" comes from: a QPU processes one quad\nper clock cycle, and a QPU instruction takes four consecutive clock\ncycles to deliver a full 16-element result vector.\n\nThe Pi contains 12 QPUs in total, each running at 250MHz.  That's a\nmax throughput of 750M vector instructions per second (250M cycles\ndivided by 4 cycles-per-instruction times 12 QPUs).  Or: 12B\noperations per second (750M instructions times 16 vector elements).\nQPU instructions can in some cases deliver two results at a\ntime, so the Pi's QPUs are often advertised at 24\n[GFLOPS](https://en.wikipedia.org/wiki/FLOPS).\n\nThe QPUs are part of the Raspberry Pi's graphics pipeline.  If you're\ninterested in doing efficient graphics on the Pi then you probably\nwant [OpenGL\nES](https://www.raspberrypi.org/documentation/usage/demos/hello-teapot.md).\nBut if you'd like to try accellerating a non-graphics part of your Pi\nproject then QPULib is worth a look.  (And so too are\n[these references](#user-content-references).)\n\n## Example 1: Euclid's Algorithm\n\nFollowing tradition, let's start by implementing [Euclid's\nalgorithm](https://en.wikipedia.org/wiki/Euclidean_algorithm).  Given\na pair of positive integers larger then zero, Euclid's algorithm\ncomputes the largest integer that divides into both without a\nremainder, also known as the *greatest common divisor*, or GCD for\nshort.\n\nWe present two versions of the algorithm:\n\n  1. a **scalar** version that runs on the ARM CPU and computes a\n     single GCD; and\n\n  2. a **vector** version that runs on a single QPU and computes 16\n     different GCDs in parallel.\n\n### Scalar version\n\nIn plain C++, we can express the algorithm as follows.\n\n```C++\nvoid gcd(int* p, int* q, int* r)\n{\n  int a = *p;\n  int b = *q;\n  while (a != b) {\n    if (a > b) \n      a = a-b;\n    else\n      b = b-a;\n  }\n  *r = a;\n}\n```\n\nAdmittedly, it's slightly odd to write `gcd` in this way, operating\non pointers to integers rather than integers directly.  However, it\nprepares the way for the vector version which operates on \n*arrays* of inputs and outputs.\n\n### Vector version 1\n\nUsing QPULib, the algorithm looks as follows.\n\n```c++\n#include <QPULib.h>\n\nvoid gcd(Ptr<Int> p, Ptr<Int> q, Ptr<Int> r)\n{\n  Int a = *p;\n  Int b = *q;\n  While (any(a != b))\n    Where (a > b)\n      a = a-b;\n    End\n    Where (a < b)\n      b = b-a;\n    End\n  End\n  *r = a;\n}\n```\n\nEven this simple example introduces a number of concepts:\n\n  * the `Int` type denotes a 16-element vector of 32-bit integers;\n\n  * the `Ptr<Int>` type denotes a 16-element vector of *addresses* of\n    `Int` vectors;\n\n  * the expression `*p` denotes the `Int` vector in memory starting at address\n    <tt>p<sub>0</sub></tt>, i.e. starting at the *first* address in the\n    vector `p`;\n\n  * the expression `a != b` computes a vector of booleans via a \n    pointwise comparison of vectors `a` and `b`;\n\n  * the condition `any(a != b)` is true when *any* of the booleans in the\n    vector `a != b` are true;\n\n  * the statement `Where (a > b) a = a-b; End` is a conditional assigment:\n    only elements in vector `a` for which `a > b` holds will be\n    modified.\n\nIt's worth reiterating that QPULib is just standard C++ code: there\nare no pre-processors being used other than the standard C\npre-processor.  All the QPULib language constructs are simply\nclasses, functions, and macros exported by QPULib.  This kind of\nlanguage is somtimes known as a [Domain Specific Embedded\nLanguage](http://cs.yale.edu/c2/images/uploads/dsl.pdf).\n\n### Invoking the QPUs\n\nNow, to compute 16 GCDs on a single QPU, we write the following\nprogram.\n\n```c++\nint main()\n{\n  // Compile the gcd function to a QPU kernel k\n  auto k = compile(gcd);\n\n  // Allocate and initialise arrays shared between CPU and QPUs\n  SharedArray<int> a(16), b(16), r(16);\n\n  // Initialise inputs to random values in range 100..199\n  srand(0);\n  for (int i = 0; i < 16; i++) {\n    a[i] = 100 + rand()%100;\n    b[i] = 100 + rand()%100;\n  }\n\n  // Set the number of QPUs to use\n  k.setNumQPUs(1);\n\n  // Invoke the kernel\n  k(&a, &b, &r);\n\n  // Display the result\n  for (int i = 0; i < 16; i++)\n    printf(\"gcd(%i, %i) = %i\\n\", a[i], b[i], r[i]);\n  \n  return 0;\n}\n```\n\nUnpacking this a bit:\n\n  * `compile` takes function defining a QPU computation and returns a\n    CPU-side handle that can be used to invoke it;\n\n  * the handle `k` is of type `Kernel<Ptr<Int>, Ptr<Int>,\n    Ptr<Int>>`, capturing the types of `gcd`'s parameters,\n    but we use the `auto` keyword to avoid clutter;\n\n  * when the kernel is invoked by writing `k(&a, &b, &r)`, QPULib knows\n    how to automatically convert CPU values of type\n    `SharedArray<int>*` into QPU values of type `Ptr<Int>`;\n\n  * the <tt>SharedArray&lt;&alpha;&gt;</tt> type is used to allocate\n    memory that is accessed\n    by both the CPU and the QPUs: memory allocated with `new` and\n    `malloc()` will not be accessible from the QPUs.\n\nRunning this program, we get:\n\n```\ngcd(183, 186) = 3\ngcd(177, 115) = 1\ngcd(193, 135) = 1\ngcd(186, 192) = 6\ngcd(149, 121) = 1\ngcd(162, 127) = 1\ngcd(190, 159) = 1\ngcd(163, 126) = 1\ngcd(140, 126) = 14\ngcd(172, 136) = 4\ngcd(111, 168) = 3\ngcd(167, 129) = 1\ngcd(182, 130) = 26\ngcd(162, 123) = 3\ngcd(167, 135) = 1\ngcd(129, 102) = 3\n```\n\n### Vector version 2: loop unrolling\n\n[Loop unrolling](https://en.wikipedia.org/wiki/Loop_unrolling) is a\ntechnique for improving performance by reducing the number of costly\nbranch instructions executed.\n\nThe QPU's branch instruction can indeed be costly: it requires three\n[delay slots](https://en.wikipedia.org/wiki/Delay_slot) (that's 12\nclock cycles), and QPULib currently makes no attempt to fill these\nslots with useful work.  Although QPULib doesn't do loop unrolling\nfor you, it does make it easy to express: we can simply\nuse a C++ loop to generate multiple QPU statements.\n\n```c++\nvoid gcd(Ptr<Int> p, Ptr<Int> q, Ptr<Int> r)\n{\n  Int a = *p;\n  Int b = *q;\n  While (any(a != b))\n    // Unroll the loop body 32 times\n    for (int i = 0; i < 32; i++) {\n      Where (a > b)\n        a = a-b;\n      End\n      Where (a < b)\n        b = b-a;\n      End\n    }\n  End\n  *r = a;\n}\n```\n\nUsing C++ as a meta-language in this way is one of the attractions\nof QPULib.  We will see lots more examples of this later!\n\n## Example 2: 3D Rotation\n\nLet's move to another simple example that helps to introduce\nideas: a routine to rotate 3D objects.\n\n(Of course, [OpenGL\nES](https://www.raspberrypi.org/documentation/usage/demos/hello-teapot.md)\nwould be a much better path for doing efficient graphics; this is just\nfor illustration purposes.)\n\n### Scalar version\n\nThe following function will rotate `n` vertices about the Z axis by\n&theta; degrees.\n\n```c++\nvoid rot3D(int n, float cosTheta, float sinTheta, float* x, float* y)\n{\n  for (int i = 0; i < n; i++) {\n    float xOld = x[i];\n    float yOld = y[i];\n    x[i] = xOld * cosTheta - yOld * sinTheta;\n    y[i] = yOld * cosTheta + xOld * sinTheta;\n  }\n}\n```\n\nIf we apply this to the vertices in [Newell's\nteapot](https://github.com/rm-hull/newell-teapot/blob/master/teapot)\n(rendered using [Richard Hull's\nwireframes](https://github.com/rm-hull/wireframes) tool)\n\n<img src=\"Doc/teapot.png\" alt=\"Newell's teapot\" width=30%>\n\nwith &theta; = 180 degrees, then we get\n\n<img src=\"Doc/teapot180.png\" alt=\"Newell's teapot\" width=30%>\n\n### Vector version 1\n\nOur first vector version is almost identical to the scalar version\nabove: the only difference is that each loop iteration now processes\n16 vertices at a time rather than a single vertex.\n\n```c++\nvoid rot3D(Int n, Float cosTheta, Float sinTheta, Ptr<Float> x, Ptr<Float> y)\n{\n  For (Int i = 0, i < n, i = i+16)\n    Float xOld = x[i];\n    Float yOld = y[i];\n    x[i] = xOld * cosTheta - yOld * sinTheta;\n    y[i] = yOld * cosTheta + xOld * sinTheta;\n  End\n}\n```\n\nUnfortunately, this simple solution is not the most efficient: it will\nspend a lot of time blocked on the memory subsystem, waiting for\nvector loads and stores to complete.  To get good performance on a\nQPU, it is desirable to overlap memory access with computation, and\nthe current QPULib compiler is not clever enough to do this\nautomatically.  We can however solve the problem manually, using\n*non-blocking* load and store operations.\n\n### Vector version 2: non-blocking loads and stores\n\nQPULib supports non-blocking loads through two functions:\n\n  * Given a vector of addresses `p`, the\n    statement `gather(p)` will *request* \n    the value at each address in `p`.\n\n  * A subsequent a call to `receive(x)`, where `x` is vector,\n    will block until the value at each address in\n    `p` has been loaded into `x`.\n\nUnlike the statement `x = *p`, the statement `gather(p)` will request\nthe value *at each address* in `p`, not the vector beginning at the\nfirst address in `p`.  In addition, `gather(p)` does not\nblock until the loads have completed: between `gather(p)`\nand `receive(x)` the program is free to perform computation *in\nparallel* with the slow memory accesses.\n\nInside the QPU, an 4-element FIFO is used to hold `gather`\nrequests: each call to `gather` will enqueue the FIFO, and each call\nto `receive` will dequeue it.  This means that a maximum of four\n`gather` calls may be issued before a `receive` must be called.\n\nNon-blocking stores are not as powerfull, but they are\nstill useful:\n\n  * Given vector of addresses `p` and a vector `x`,\n    the statement `store(x, p)` will write\n    vector `x` to memory beginning at the first address in `p`.\n\nUnlike the statement `*p = x`, the statement `store(p, x)` will not\nwait until `x` has been written.  However, any subsequent call to\n`store` will wait until the previous store has completed.  (Future\nimprovements to QPULib could allow several outstanding stores instead of\njust one.)\n\nWe are now ready to implement a vectorised rotation routine that\noverlaps memory access with computation:\n\n```c++\nvoid rot3D(Int n, Float cosTheta, Float sinTheta, Ptr<Float> x, Ptr<Float> y)\n{\n  // Function index() returns vector <0 1 2 ... 14 15>\n  Ptr<Float> p = x + index();\n  Ptr<Float> q = y + index();\n  // Pre-fetch first two vectors\n  gather(p); gather(q);\n\n  Float xOld, yOld;\n  For (Int i = 0, i < n, i = i+16)\n    // Pre-fetch two vectors for the *next* iteration\n    gather(p+16); gather(q+16);\n    // Receive vectors for *this* iteration\n    receive(xOld); receive(yOld);\n    // Store results\n    store(xOld * cosTheta - yOld * sinTheta, p);\n    store(yOld * cosTheta + xOld * sinTheta, q);\n    p = p+16; q = q+16;\n  End\n\n  // Discard pre-fetched vectors from final iteration\n  receive(xOld); receive(yOld);\n}\n```\n\nWhile the outputs from one iteration are being computed and written to\nmemory, the inputs for the *next* iteration are being loaded *in\nparallel*.\n\n### Vector version 3: multiple QPUs\n\nQPULib provides a simple mechanism to execute the same kernel on\nmultiple QPUs in parallel: before invoking a kernel `k`, call\n`k.setNumQPUs(n)` to use `n` QPUs.\nFor this to be useful the programmer needs a way to tell\neach QPU to compute a different part of the overall result.\nAccordingly,\nQPULib provides the `me()` function which returns the unique id of the\nQPU that called it.  More specifically, `me()` returns a vector of\ntype `Int` with all elements holding the QPU id.  In addition, the\n`numQPUs()` function returns the number of QPUs that are executing the\nkernel.  A QPU id will always lie in the range `0` to `numQPUs()-1`.\n\nNow, to spread the `rot3D` computation accross multiple QPUs we will\nuse a loop increment of `16*numQPUs()` instead of `16`, and offset the\ninitial pointers `x` and `y` by `16*me()`.\n\n```c++\nvoid rot3D(Int n, Float cosTheta, Float sinTheta, Ptr<Float> x, Ptr<Float> y)\n{\n  Int inc = numQPUs() << 4;\n  Ptr<Float> p = x + index() + (me() << 4);\n  Ptr<Float> q = y + index() + (me() << 4);\n  gather(p); gather(q);\n\n  Float xOld, yOld;\n  For (Int i = 0, i < n, i = i+inc)\n    gather(p+inc); gather(q+inc);\n    receive(xOld); receive(yOld);\n    store(xOld * cosTheta - yOld * sinTheta, p);\n    store(yOld * cosTheta + xOld * sinTheta, q);\n    p = p+inc; q = q+inc;\n  End\n\n  // Discard pre-fetched vectors from final iteration\n  receive(xOld); receive(yOld);\n}\n```\n\n### Performance\n\nTimes taken to rotate an object with 192,000 vertices:\n\n  Version  | Number of QPUs | Run-time (s) |\n  ---------| -------------: | -----------: |\n  Scalar   | 0              | 0.018        |\n  Vector 1 | 1              | 0.040        |\n  Vector 2 | 1              | 0.018        |\n  Vector 3 | 1              | 0.018        |\n  Vector 3 | 2              | 0.016        |\n\nNon-blocking loads and stores (vector version 2) give a\nsignificant performance boost: in this case a factor of 2.\n\nUnforunately, the program does not scale well to multiple QPUs.  I'm\nnot entirely sure why, but my suspicion is that the compute-to-memory\nratio is too low: we do only 2 arithmetic operations for every memory\naccess, perhaps overwhelming the memory subsystem.  If there are\npossibilities for QPULib to generate better code here, hopefully they\nwill be discovered in due course.  (Do let me know if you\nhave any suggestions.)\n\n## Example 3: 2D Convolution (Heat Transfer)\n\nLet's move to a somewhat more substantial example: modelling the heat\nflow across a 2D surface.  [Newton's law of\ncooling](https://en.wikipedia.org/wiki/Newton%27s_law_of_cooling)\nstates that an object cools at a rate proportional to the difference\nbetween its temperature `T` and the temperature of its environment (or\nambient temperature) `A`:\n\n```\ndT/dt = \u2212k(T \u2212 A)\n```\n\nWhen simulating this equation below, we will consider each point on\nour 2D surface to be a seperate object, and the ambient temperature of\neach object to be the average of the temperatures of the 8 surrounding\nobjects.  This is very similar to 2D convolution using a mean filter.\n\n### Scalar version\n\nThe following function simulates a single time-step of the\ndifferential equation, applied to each object in the 2D grid.\n\n```c++\nvoid step(float** grid, float** gridOut, int width, int height)\n{\n  for (int y = 1; y < height-1; y++) {\n    for (int x = 1; x < width-1; x++) {\n      float surroundings =\n        grid[y-1][x-1] + grid[y-1][x]   + grid[y-1][x+1] +\n        grid[y][x-1]   +                  grid[y][x+1]   +\n        grid[y+1][x-1] + grid[y+1][x]   + grid[y+1][x+1];\n      surroundings *= 0.125;\n      gridOut[y][x] = grid[y][x] - (K * (grid[y][x] - surroundings));\n    }\n  }\n}\n```\n\nIf we apply heat at the north and east edges of our 2D surface, and\ncold at the south and west edges, then after of several simulation\nsteps we get:\n\n<img src=\"Doc/heat.png\" alt=\"Heat flow across 2D surface\" width=30%>\n\n### Vector version\n\nBefore vectorising the simulation routine, we will introduce the idea\nof a **cursor** which is useful for implementing sliding window\nalgorithms.  A cursor points to a window of three continguous vectors\nin memory: `prev`, `current` and `next`.\n\n```\n  cursor  ------>  +---------+---------+---------+\n                   |  prev   | current |  next   |\n                   +---------+---------+---------+\n                 +0:      +16:      +32:      +48:\n```\n\nand supports three main operations:\n\n  1. **advance** the cursor by one vector, i.e. slide the window right\n     by one vector;\n\n  2. **shift-left** the `current` vector by one element,\n     using the value of the `next` vector;\n\n  3. **shift-right** the `current` vector by one element,\n     using the value of the `prev` vector.\n\nHere is a QPULib implementation of a cursor, using a C++ class.\n\n```c++\nclass Cursor {\n  Ptr<Float> cursor;\n  Float prev, current, next;\n\n public:\n\n  // Initialise to cursor to a given pointer\n  // and fetch the first vector.\n  void init(Ptr<Float> p) {\n    gather(p);\n    current = 0;\n    cursor = p+16;\n  }\n\n  // Receive the first vector and fetch the second.\n  // (prime the software pipeline)\n  void prime() {\n    receive(next);\n    gather(cursor);\n  }\n\n  // Receive the next vector and fetch another.\n  void advance() {\n    cursor = cursor+16;\n    prev = current;\n    gather(cursor);\n    current = next;\n    receive(next);\n  }\n\n  // Receive final vector and don't fetch any more.\n  void finish() {\n    receive(next);\n  }\n\n  // Shift the current vector left one element\n  void shiftLeft(Float& result) {\n    result = rotate(current, 15);\n    Float nextRot = rotate(next, 15);\n    Where (index() == 15)\n      result = nextRot;\n    End\n  }\n\n  // Shift the current vector right one element\n  void shiftRight(Float& result) {\n    result = rotate(current, 1);\n    Float prevRot = rotate(prev, 1);\n    Where (index() == 0)\n      result = prevRot;\n    End\n  }\n};\n```\n\nGiven a vector `x`, the QPULib operation `rotate(x, n)` will rotate\n`x` right by `n` places where `n` is a integer in the range 0 to 15.\nNotice that rotating right by 15 is the same as rotating left by 1.\n\nNow, using cursors the vectorised simulation step is expressed below.\nA slight structural difference from the scalar version is that we no\nlonger treat the grid as a 2D array: it is now 1D array with a `pitch`\nparameter that gives the increment needed to get from the start of one\nrow to the start of the next.\n\n```C++\nvoid step(Ptr<Float> grid, Ptr<Float> gridOut, Int pitch, Int width, Int height)\n{\n  Cursor row[3];\n  grid = grid + pitch*me() + index();\n\n  // Skip first row of output grid\n  gridOut = gridOut + pitch;\n\n  For (Int y = me(), y < height, y=y+numQPUs())\n    // Point p to the output row\n    Ptr<Float> p = gridOut + y*pitch;\n\n    // Initilaise three cursors for the three input rows\n    for (int i = 0; i < 3; i++) row[i].init(grid + i*pitch);\n    for (int i = 0; i < 3; i++) row[i].prime();\n\n    // Compute one output row\n    For (Int x = 0, x < width, x=x+16)\n\n      for (int i = 0; i < 3; i++) row[i].advance();\n\n      Float left[3], right[3];\n      for (int i = 0; i < 3; i++) {\n        row[i].shiftLeft(right[i]);\n        row[i].shiftRight(left[i]);\n      }\n\n      Float sum = left[0] + row[0].current + right[0] +\n                  left[1] +                  right[1] +\n                  left[2] + row[2].current + right[2];\n\n      store(row[1].current - K * (row[1].current - sum * 0.125), p);\n      p = p + 16;\n\n    End\n\n    // Cursors are finished for this row\n    for (int i = 0; i < 3; i++) row[i].finish();\n\n    // Move to the next input rows\n    grid = grid + pitch*numQPUs();\n  End\n}\n```\n\n### Performance\n\nTimes taken to simulate a 512x512 surface for 2000 steps:\n\n  Version | Number of QPUs | Run-time (s) |\n  --------| -------------: | -----------: |\n  Scalar  | 0              | 431.46       |\n  Vector  | 1              | 49.34        |\n  Vector  | 2              | 24.91        |\n  Vector  | 4              | 20.36        |\n\n\n## References\n\nThe following works were *very* helpful in the development of\nQPULib.\n\n  * The [VideoCore IV manual](http://www.broadcom.com/docs/support/videocore/VideoCoreIV-AG100-R.pdf) by Broadcom.\n\n  * The [documentation, demos, and\n    assembler](https://github.com/hermanhermitage/videocoreiv-qpu)\n    by Herman Hermitage.\n\n  * The [FFT implementation](http://www.aholme.co.uk/GPU_FFT/Main.htm)\n    by Andrew Holme.\n"}, {"repo": "/shichuan/javascript-patterns", "language": "HTML", "readme_contents": "#JavaScript Patterns\n\n<img src=\"http://shichuan.github.io/javascript-patterns/img/js-patterns.png\" alt=\"JS Patterns\" title=\"JS Patterns\" />\n<br />\nProject page at: <a href=\"http://shichuan.github.io/javascript-patterns\" target=\"_blank\">http://shichuan.github.io/javascript-patterns</a>\n\n"}, {"repo": "/perl11/potion", "language": "C", "readme_contents": "## ~ readme ~\n\n         .ooo\n          'OOOo\n      ~ p ooOOOo tion ~\n          .OOO\n           oO      %% a little\n             Oo    fast language.\n            'O\n             `\n            (o)\n        ___/ /\n       /`    \\\n      /v^  `  ,\n     (...v/v^/\n      \\../::/\n       \\/::/\n\n[![Build Status](https://api.travis-ci.org/perl11/potion.svg)](https://travis-ci.org/perl11/potion) [![Coverity Status](https://scan.coverity.com/projects/6934/badge.svg)](https://scan.coverity.com/projects/perl11-potion) [perl11.org/potion/](http://perl11.org/potion/)\n\n## ~ potion ~\n\nPotion is an object- and mixin-oriented (traits)\nlanguage.\n\nIts exciting points are:\n\n * Just-in-time compilation to x86 and x86-64\n   machine code function pointers. This means\n   she's a speedy one. Who integrates very\n   well with C extensions.\n\n   The JIT is turned on by default and is\n   considered the primary mode of operation.\n\n * Intermediate bytecode format and VM. Load\n   and dump code. Decent speed and cross-\n   architecture. Heavily based on Lua's VM.\n\n * A lightweight generational GC, based on\n   Basile Starynkevitch's work on Qish, with\n   ~4ms per GC on average with < 100MB heaps.\n   <http://starynkevitch.net/Basile/qishintro.html>\n\n * Bootstrapped \"id\" object model, based on\n   Ian Piumarta's soda languages. This means\n   everything in the language, including\n   object allocation and interpreter state\n   are part of the object model.\n   (See COPYING for citations.)\n\n * Interpreter is thread-safe and reentrant.\n   I hope this will facilitate coroutines,\n   parallel interpreters and sandboxing.\n\n * Small. Under 10kloc. Right now we're like\n   6,000 or something. Install sloccount\n   and run: make sloc.\n\n * Reified AST and bytecode structures. This\n   is very important to me. By giving access\n   to the parser and compiler, it allows people\n   to target other platforms, write code analysis\n   tools and even fully bootstrapped VMs. I'm\n   not as concerned about the Potion VM being\n   fully bootstrapped, especially as it is tied\n   into the JIT so closely.\n\n * Memory-efficient classes. Stored like C\n   structs. (Although the method lookup table\n   can be used like a hash for storing arbitrary\n   data.)\n\n * The JIT is also used to speed up some other\n   bottlenecks. For example, instance variable\n   and method lookup tables are compiled into\n   machine code.\n\nHowever, some warnings:\n\n * Strings are immutable (like Lua) and byte\n   arrays are used for I/O buffers.\n\n * Limited platform support for coroutines.\n   This affects exceptions. I'm and feeling\n   rather uninspired on the matter. Let's hear\n   from you.\n\n * The parser is not GC safe. This affects eval.\n   Do not waste too much memory inside eval.\n\n * No OS threads yet.\n\n\n## ~ a whiff of potion ~\n\n    5 times: \"Odelay!\" print.\n\nOr,\n\n    add = (x, y): x + y.\n    add(2, 4) string print\n\nOr,\n\n    hello =\n      \"(x): ('hello ', x) print.\" eval\n    hello ('world')\n\n\n## ~ building and installing ~\n\n    $ make\n\nLook inside the file called INSTALL for options.\n\n\n## ~ how it transpired ~\n\nThis isn't supposed to happen!\n\nI started playing with Lua's internals and reading\nstuff by Ian Piumarta and Nicolas Cannasse. And I,\nwell... I don't know how this happened!\n\nTurns out making a language is a lovely old time,\nyou should try it. If you keep it small, fit the\nVM and the parser and the stdlib all into 10k\nlines, then it's no sweat.\n\nTo be fair, I'd been tinkering with the parser\nfor years, though.\n\n\n## ~ the potion pledge ~\n\nEVERYTHING IS AN OBJECT.\nHowever, OBJECTS AREN'T EVERYTHING.\n\n(And, incidentally, everything is a function.)\n\n\n## ~ items to understand ~\n\n1. A traditional object is a tuple of data\n   and methods: (D, M).\n   \n   D is kept in the object itself.\n   M is kept in classes.\n\n2. In Potion, objects are just D.\n\n3. Every object has an M.\n\n4. But M can be altered, swapped,\n   added to, removed from, whatever.\n\n5. Objects do not have classes.\n   The M is a mixin, a collection\n   of methods.\n\nExample: all strings have a \"length\"\nmethod. This method comes with Potion.\nIt's in the String mixin.\n\n6. You can swap out mixins for the span\n   of a single source file.\n\nExample: you could give all strings a\n\"backwards\" method. But just for the\ncode inside your test.pn script.\n\n7. You can re-mix for the span of a\n   single closure.\n\nTo sum up:\n\nEVERYTHING IS AN OBJECT.\nEVEN MIXINS ARE OBJECTS.\nAND, OF COURSE, CLOSURES ARE OBJECTS.\n\nHowever, OBJECTS AREN'T EVERYTHING.\nTHEY ARE USELESS WITHOUT MIXINS.\n\n\n## ~ unique ideas (to be implemented) ~\n\nPotion does have a few unique features\nunderway.\n\n* It is two languages in one.\n\nThe language itself is objects and closures.\n\n    Number add = (x): self + x.\n\nBut it also includes a data language.\n\n    app = [window (width=200, height=400)\n      [button \"OK\", button \"Cancel\"]]\n    \nThe code and data languages can be interleaved\nover and over again. In a way, I'm trying to find\na middle ground between s-expressions and stuff like\nE4X. I like that s-expressions are a very light data\nsyntax, but I like that E4X clearly looks like data.\n\nWhen s-expressions appear in Lisp code, they look\nlike code. I think it is nice to distinguish the two.\n\n* Deeply nested blocks can be closed quickly.\nI don't like significant whitespace, personally.\nBut I don't like end end end end.\n\n    say = (phrase):\n      10 times (i):\n        20 times (j):\n          phrase print\n    _say\n\nThe closing \"_ say\" ends the block saved to \"say\" var.\n\nNormally, blocks are closed with a period. In this case\nwe'd need three periods, which looks strange.\n\n    say = ():\n      10 times:\n        20 times:\n          \"Odelay!\" print\n    ...\n\nIf you prefer, you can give it some space. Or you can\nuse a variable name introduced by the block,\n\n    say = (phrase):\n      10 times (i):\n        20 times (j):\n          phrase print\n    _ phrase\n\n\n    say = (phrase):\n      10 times (i):\n        20 times (j):\n          phrase print\n      _ i\n    .\n\nMaybe it all looks strange. I don't know. I'm just trying\nthings out, okay?\n\n* Elimination of line noise.\n\n  I avoid @, #, $, %, {}.\n  Stick with ., |, (), [], =, !, ?. Easier on the eyes.\n  These are common punctuations in English.\n\n* I try to defer to English when it comes to punctuation rules.\n\nPeriod means \"end\". (In other langs it means \"method call\".)\nComma breaks up statements.\nSpace between messages gives a noun-verb feeling.\n\n    window open (width=400, height=500)\n\n\n* Named block args.\n\n\n    (1, 2, 3) map (item=x, index=i): i display, x + 1.\n\n\n* Assign is match + bind really (~ planned ~).\n\nAssignments are side-effects only, but here extended.  Atoms on the\nleft-hand side (lhs) are trivial, but we prefer the power of LISP's\ndestructuring-bind within macros, or prolog or elixirs matching. So\n= is actually a match operator which will recursively check if the\nexpressions on both left and right side match, and binds all found\nlhs variables.\n\n    (1, x) = (1, 2) => (x=2)\n    (1, x) = (2, 3) => false\n    1 = 2           => false\n\n_ is a special variable which matches everything, but is never bound,\n| seperates the head and tail from a list or lick.\n\nSo we can check trees like this:\n\n    (_, x, 2)   = (0, 1, 2)   and say x #=> 1\n    [_, [x, 1]] = [0, [1, 2]] and say x #=> 1\n    [_, x]      = [0, [1, 2]] and say x #=> [1, 2]\n    [_ | x]     = [0, 1, 2]   and say x #=> [1, 2]\n\n    fun = (a, b): [0, [a, b]].\n    [_ | [x, 1]] = fun(1, 2)  and say x #=> 1\n\n## ~ feverish and fond thankyous ~\n\nwhy is gravely indebted to Basile Starynkevitch, who fielded\nquestions about his garbage collector. why favors French hackers\nto an extreme (Xavier Leroy, Nicolas Cannasse, Guy Decoux,\nMathieu Bochard to name only a portion of those I admire) and\nis very glad to represent their influence in Potion's garbage\ncollector.\n\nMatz, for answering why's questions about conservative GC and\nfor encouraging him so much. Potion's stack scanning code and\nsome of the object model come from Ruby.\n\nSteve Dekorte for the Io language, libgarbagecollector and\nlibcoroutine -- I referred frequently to all of them in\nsorting out what he wanted.\n\nOf course, Mauricio Fernandez for his inspiring programming journal\nhoused at\nhttp://web.archive.org/web/20110814062722/http://eigenclass.org/R2/\nand for works derived throughout the course of it -- extprot most of\nall.  Many of my thoughts about language internals (object repr, GC,\netc.) are informed by him.\n\nIan Piumarta for peg/leg. We use a re-entrant custom version\nof it, but the original library is sheer minimalist parsing\namazement.\n\nFinal appreciations to Jonathan Wright and William Morgan\nwho pitched in, back in the wee hours of Potion's history.\nThanks.\n\n\n## ~ license ~\n\nSee COPYING for legal information. It's an MIT license,\nwhich lets you do anything you want with this. I'm hoping\nthat makes it very nice for folks who want to embed a little\nPotion in their app!\n\n"}]