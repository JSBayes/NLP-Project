{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goals\n",
    "\n",
    " 1) Construct a web scraper capable of gathering data from github repositories. Data collected should include the main programing language used in that repository, and the contents of that repository’s readme file.\n",
    "\n",
    " 2) Use natural language processing to develop a model to predict each repositories programming language based on the contents of that repository’s readme file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "import nltk\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#import acquire as a # produces output sometimes\n",
    "import prepare as p\n",
    "import explore as e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acqusition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calles functions in acquire.py to scrape git hub repositories and create a dictionary containing the repo url,\n",
    "# language, and readme contents of each folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calls functions in prepare.py. Functions convert the dictionaries in the json file into a data frame. \n",
    "# Then add two columns to the data frame, applying basic cleaning algorithms to the readme contents. \n",
    "# Stemming is then applied to one of those columns. Lemmatize is applied to the other.\n",
    "# Functions also drop rows that did not produce usable data\n",
    "df = p.prep_readme()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>readme_contents</th>\n",
       "      <th>repo</th>\n",
       "      <th>readme_contents_stemmed</th>\n",
       "      <th>readme_contents_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CSS</td>\n",
       "      <td># Welcome\\n\\n&gt; **Warning**: this book is **not...</td>\n",
       "      <td>/nakov/Practical-Cryptography-for-Developers-Book</td>\n",
       "      <td>welcom warn book finish still work chapter com...</td>\n",
       "      <td>welcome warning book finished still working ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Java</td>\n",
       "      <td># Monorepo of Deeplearning4j\\n\\nWelcome to the...</td>\n",
       "      <td>/eclipse/deeplearning4j</td>\n",
       "      <td>monorepo deeplearn j welcom new monorepo deepl...</td>\n",
       "      <td>monorepo deeplearning j welcome new monorepo d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Java</td>\n",
       "      <td># H2O\\n\\n[![Join the chat at https://gitter.im...</td>\n",
       "      <td>/h2oai/h2o-3</td>\n",
       "      <td>h join chat http gitter im h oai h http badg g...</td>\n",
       "      <td>h join chat http gitter im h oai h http badge ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C++</td>\n",
       "      <td>&lt;div align=\"center\"&gt;\\n  &lt;img src=\"https://www....</td>\n",
       "      <td>/tensorflow/tensorflow</td>\n",
       "      <td>div align center img src http www tensorflow o...</td>\n",
       "      <td>div align center img src http www tensorflow o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C++</td>\n",
       "      <td>gRPC - An RPC library and framework\\n=========...</td>\n",
       "      <td>/grpc/grpc</td>\n",
       "      <td>grpc rpc librari framework grpc modern open so...</td>\n",
       "      <td>grpc rpc library framework grpc modern open so...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language                                    readme_contents  \\\n",
       "0      CSS  # Welcome\\n\\n> **Warning**: this book is **not...   \n",
       "1     Java  # Monorepo of Deeplearning4j\\n\\nWelcome to the...   \n",
       "2     Java  # H2O\\n\\n[![Join the chat at https://gitter.im...   \n",
       "3      C++  <div align=\"center\">\\n  <img src=\"https://www....   \n",
       "4      C++  gRPC - An RPC library and framework\\n=========...   \n",
       "\n",
       "                                                repo  \\\n",
       "0  /nakov/Practical-Cryptography-for-Developers-Book   \n",
       "1                            /eclipse/deeplearning4j   \n",
       "2                                       /h2oai/h2o-3   \n",
       "3                             /tensorflow/tensorflow   \n",
       "4                                         /grpc/grpc   \n",
       "\n",
       "                             readme_contents_stemmed  \\\n",
       "0  welcom warn book finish still work chapter com...   \n",
       "1  monorepo deeplearn j welcom new monorepo deepl...   \n",
       "2  h join chat http gitter im h oai h http badg g...   \n",
       "3  div align center img src http www tensorflow o...   \n",
       "4  grpc rpc librari framework grpc modern open so...   \n",
       "\n",
       "                          readme_contents_lemmatized  \n",
       "0  welcome warning book finished still working ch...  \n",
       "1  monorepo deeplearning j welcome new monorepo d...  \n",
       "2  h join chat http gitter im h oai h http badge ...  \n",
       "3  div align center img src http www tensorflow o...  \n",
       "4  grpc rpc library framework grpc modern open so...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First peek at prepared data.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping repo column. The goal is to predict language using readme contents so repo it is not useful\n",
    "df.drop(columns='repo',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping readme_contents. The column was there for comparison to insure prepre functions worked as expected.\n",
    "# It is no longer needed.\n",
    "df.drop(columns='readme_contents',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>readme_contents_stemmed</th>\n",
       "      <th>readme_contents_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CSS</td>\n",
       "      <td>welcom warn book finish still work chapter com...</td>\n",
       "      <td>welcome warning book finished still working ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Java</td>\n",
       "      <td>monorepo deeplearn j welcom new monorepo deepl...</td>\n",
       "      <td>monorepo deeplearning j welcome new monorepo d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Java</td>\n",
       "      <td>h join chat http gitter im h oai h http badg g...</td>\n",
       "      <td>h join chat http gitter im h oai h http badge ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C++</td>\n",
       "      <td>div align center img src http www tensorflow o...</td>\n",
       "      <td>div align center img src http www tensorflow o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C++</td>\n",
       "      <td>grpc rpc librari framework grpc modern open so...</td>\n",
       "      <td>grpc rpc library framework grpc modern open so...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language                            readme_contents_stemmed  \\\n",
       "0      CSS  welcom warn book finish still work chapter com...   \n",
       "1     Java  monorepo deeplearn j welcom new monorepo deepl...   \n",
       "2     Java  h join chat http gitter im h oai h http badg g...   \n",
       "3      C++  div align center img src http www tensorflow o...   \n",
       "4      C++  grpc rpc librari framework grpc modern open so...   \n",
       "\n",
       "                          readme_contents_lemmatized  \n",
       "0  welcome warning book finished still working ch...  \n",
       "1  monorepo deeplearning j welcome new monorepo d...  \n",
       "2  h join chat http gitter im h oai h http badge ...  \n",
       "3  div align center img src http www tensorflow o...  \n",
       "4  grpc rpc library framework grpc modern open so...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Dictionary\n",
    "\n",
    "# 1) language - main programing language used by the repository add how this was determined\n",
    "\n",
    "2) readme_contents_stemmed - contents of readme file cleaned and stemed\n",
    "\n",
    "3) readme_contents_lemmatized - contents of readme file cleaned and lemmatized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### looking at initial data statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C++</th>\n",
       "      <td>20</td>\n",
       "      <td>0.190476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HTML</th>\n",
       "      <td>20</td>\n",
       "      <td>0.190476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Python</th>\n",
       "      <td>15</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shell</th>\n",
       "      <td>10</td>\n",
       "      <td>0.095238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Java</th>\n",
       "      <td>10</td>\n",
       "      <td>0.095238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JavaScript</th>\n",
       "      <td>10</td>\n",
       "      <td>0.095238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>10</td>\n",
       "      <td>0.095238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSS</th>\n",
       "      <td>10</td>\n",
       "      <td>0.095238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            number   percent\n",
       "C++             20  0.190476\n",
       "HTML            20  0.190476\n",
       "Python          15  0.142857\n",
       "Shell           10  0.095238\n",
       "Java            10  0.095238\n",
       "JavaScript      10  0.095238\n",
       "C               10  0.095238\n",
       "CSS             10  0.095238"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shows the number and percent of repositories that represent each language\n",
    "labels = pd.concat([df.language.value_counts(),\n",
    "                    df.language.value_counts(normalize=True)], axis=1)\n",
    "labels.columns = ['number', 'percent']\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gets a list of words tied to each language\n",
    "CPP_words = e.word_soup(' '.join(df[df.language == 'C++'].readme_contents_lemmatized))\n",
    "HTML_words = e.word_soup(' '.join(df[df.language == 'HTML'].readme_contents_lemmatized))\n",
    "Python_words = e.word_soup(' '.join(df[df.language == 'Python'].readme_contents_lemmatized))\n",
    "CSS_words = e.word_soup(' '.join(df[df.language == 'CSS'].readme_contents_lemmatized))\n",
    "C_words = e.word_soup(' '.join(df[df.language == 'C'].readme_contents_lemmatized))\n",
    "Java_words = e.word_soup(' '.join(df[df.language == 'Java'].readme_contents_lemmatized))\n",
    "JavaScript_words = e.word_soup(' '.join(df[df.language == 'JavaScript'].readme_contents_lemmatized))\n",
    "Shell_words = e.word_soup(' '.join(df[df.language == 'Shell'].readme_contents_lemmatized))\n",
    "all_words = e.word_soup(' '.join(df.readme_contents_lemmatized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gets frequency of each word tied to each language\n",
    "CPP_freq = pd.Series(CPP_words).value_counts()\n",
    "HTML_freq = pd.Series(HTML_words).value_counts()\n",
    "Python_freq = pd.Series(Python_words).value_counts()\n",
    "CSS_freq = pd.Series(CSS_words).value_counts()\n",
    "C_freq = pd.Series(C_words).value_counts()\n",
    "Java_freq = pd.Series(Java_words).value_counts()\n",
    "JavaScript_freq = pd.Series(JavaScript_words).value_counts()\n",
    "Shell_freq = pd.Series(Shell_words).value_counts()\n",
    "all_freq = pd.Series(all_words).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a data frame that shows the frequency of each word across each language\n",
    "word_counts = (pd.concat([all_freq,CPP_freq,HTML_freq,Python_freq,CSS_freq,C_freq,Java_freq,JavaScript_freq,Shell_freq], axis=1, sort=True)\n",
    "                .set_axis(['all', 'C++', 'HTML', 'Python', 'CSS', 'C', 'Java', 'JavaScript', 'Shell'], axis=1, inplace=False)\n",
    "                .fillna(0)\n",
    "                .apply(lambda s: s.astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all</th>\n",
       "      <th>C++</th>\n",
       "      <th>HTML</th>\n",
       "      <th>Python</th>\n",
       "      <th>CSS</th>\n",
       "      <th>C</th>\n",
       "      <th>Java</th>\n",
       "      <th>JavaScript</th>\n",
       "      <th>Shell</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aa</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaa</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaaaaelftksuqmcc</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaaaaxrstlmaqobyzgaaaafis</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaaaikleqvqi</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           all  C++  HTML  Python  CSS  C  Java  JavaScript  \\\n",
       "aa                          14    1     3       0    0  0     0          10   \n",
       "aaa                          5    0     0       0    0  0     0           1   \n",
       "aaaaaelftksuqmcc             1    1     0       0    0  0     0           0   \n",
       "aaaaaxrstlmaqobyzgaaaafis    1    1     0       0    0  0     0           0   \n",
       "aaaaikleqvqi                 1    1     0       0    0  0     0           0   \n",
       "\n",
       "                           Shell  \n",
       "aa                             0  \n",
       "aaa                            4  \n",
       "aaaaaelftksuqmcc               0  \n",
       "aaaaaxrstlmaqobyzgaaaafis      0  \n",
       "aaaaikleqvqi                   0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all</th>\n",
       "      <th>C++</th>\n",
       "      <th>HTML</th>\n",
       "      <th>Python</th>\n",
       "      <th>CSS</th>\n",
       "      <th>C</th>\n",
       "      <th>Java</th>\n",
       "      <th>JavaScript</th>\n",
       "      <th>Shell</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>http</th>\n",
       "      <td>4434</td>\n",
       "      <td>710</td>\n",
       "      <td>421</td>\n",
       "      <td>1385</td>\n",
       "      <td>258</td>\n",
       "      <td>136</td>\n",
       "      <td>357</td>\n",
       "      <td>855</td>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>com</th>\n",
       "      <td>2926</td>\n",
       "      <td>418</td>\n",
       "      <td>290</td>\n",
       "      <td>955</td>\n",
       "      <td>193</td>\n",
       "      <td>45</td>\n",
       "      <td>220</td>\n",
       "      <td>615</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>github</th>\n",
       "      <td>1538</td>\n",
       "      <td>244</td>\n",
       "      <td>80</td>\n",
       "      <td>613</td>\n",
       "      <td>149</td>\n",
       "      <td>34</td>\n",
       "      <td>177</td>\n",
       "      <td>112</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>python</th>\n",
       "      <td>1189</td>\n",
       "      <td>73</td>\n",
       "      <td>85</td>\n",
       "      <td>550</td>\n",
       "      <td>53</td>\n",
       "      <td>63</td>\n",
       "      <td>48</td>\n",
       "      <td>43</td>\n",
       "      <td>274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>org</th>\n",
       "      <td>714</td>\n",
       "      <td>177</td>\n",
       "      <td>79</td>\n",
       "      <td>261</td>\n",
       "      <td>27</td>\n",
       "      <td>42</td>\n",
       "      <td>75</td>\n",
       "      <td>27</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>www</th>\n",
       "      <td>693</td>\n",
       "      <td>63</td>\n",
       "      <td>123</td>\n",
       "      <td>193</td>\n",
       "      <td>34</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "      <td>188</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>657</td>\n",
       "      <td>60</td>\n",
       "      <td>74</td>\n",
       "      <td>128</td>\n",
       "      <td>15</td>\n",
       "      <td>52</td>\n",
       "      <td>77</td>\n",
       "      <td>162</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>href</th>\n",
       "      <td>602</td>\n",
       "      <td>31</td>\n",
       "      <td>402</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>md</th>\n",
       "      <td>600</td>\n",
       "      <td>51</td>\n",
       "      <td>185</td>\n",
       "      <td>43</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>61</td>\n",
       "      <td>179</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x</th>\n",
       "      <td>513</td>\n",
       "      <td>31</td>\n",
       "      <td>15</td>\n",
       "      <td>294</td>\n",
       "      <td>20</td>\n",
       "      <td>22</td>\n",
       "      <td>50</td>\n",
       "      <td>16</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         all  C++  HTML  Python  CSS    C  Java  JavaScript  Shell\n",
       "http    4434  710   421    1385  258  136   357         855    312\n",
       "com     2926  418   290     955  193   45   220         615    190\n",
       "github  1538  244    80     613  149   34   177         112    129\n",
       "python  1189   73    85     550   53   63    48          43    274\n",
       "org      714  177    79     261   27   42    75          27     26\n",
       "www      693   63   123     193   34    7    31         188     54\n",
       "c        657   60    74     128   15   52    77         162     89\n",
       "href     602   31   402     107    3    0    24          34      1\n",
       "md       600   51   185      43   12   15    61         179     54\n",
       "x        513   31    15     294   20   22    50          16     65"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shows the 10 most frequently occuring words\n",
    "word_counts.sort_values(by='all', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shows words that are unique to each language\n",
    "Shell_unique = word_counts[(word_counts['C++'] == 0) & (word_counts['HTML'] == 0) &(word_counts['Python'] == 0) & (word_counts['CSS'] == 0) & (word_counts['C'] == 0) & (word_counts['Java'] == 0) & (word_counts['JavaScript'] == 0)].sort_values(by='Shell', ascending=False)\n",
    "CPP_unique = word_counts[(word_counts['Shell'] == 0) & (word_counts['HTML'] == 0) &(word_counts['Python'] == 0) & (word_counts['CSS'] == 0) & (word_counts['C'] == 0) & (word_counts['Java'] == 0) & (word_counts['JavaScript'] == 0)].sort_values(by='C++', ascending=False)\n",
    "HTML_unique = word_counts[(word_counts['C++'] == 0) & (word_counts['Shell'] == 0) &(word_counts['Python'] == 0) & (word_counts['CSS'] == 0) & (word_counts['C'] == 0) & (word_counts['Java'] == 0) & (word_counts['JavaScript'] == 0)].sort_values(by='HTML', ascending=False)\n",
    "Python_unique = word_counts[(word_counts['C++'] == 0) & (word_counts['HTML'] == 0) &(word_counts['Shell'] == 0) & (word_counts['CSS'] == 0) & (word_counts['C'] == 0) & (word_counts['Java'] == 0) & (word_counts['JavaScript'] == 0)].sort_values(by='Python', ascending=False)\n",
    "CSS_unique = word_counts[(word_counts['C++'] == 0) & (word_counts['HTML'] == 0) &(word_counts['Python'] == 0) & (word_counts['Shell'] == 0) & (word_counts['C'] == 0) & (word_counts['Java'] == 0) & (word_counts['JavaScript'] == 0)].sort_values(by='CSS', ascending=False)\n",
    "C_unique = word_counts[(word_counts['C++'] == 0) & (word_counts['HTML'] == 0) &(word_counts['Python'] == 0) & (word_counts['CSS'] == 0) & (word_counts['Shell'] == 0) & (word_counts['Java'] == 0) & (word_counts['JavaScript'] == 0)].sort_values(by='C', ascending=False)\n",
    "Java_unique = word_counts[(word_counts['C++'] == 0) & (word_counts['HTML'] == 0) &(word_counts['Python'] == 0) & (word_counts['CSS'] == 0) & (word_counts['C'] == 0) & (word_counts['Shell'] == 0) & (word_counts['JavaScript'] == 0)].sort_values(by='Java', ascending=False)\n",
    "JavaScript_unique = word_counts[(word_counts['C++'] == 0) & (word_counts['HTML'] == 0) &(word_counts['Python'] == 0) & (word_counts['CSS'] == 0) & (word_counts['C'] == 0) & (word_counts['Java'] == 0) & (word_counts['Shell'] == 0)].sort_values(by='JavaScript', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idea create list of stop words that are all values except unique-to-language words from train group then\n",
    "# try to predict test group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking at bigrams\n",
    "# shows bigrams for data set\n",
    "Shell_bigrams = pd.Series(nltk.ngrams(Shell_words, 2))\n",
    "CPP_bigrams = pd.Series(nltk.ngrams(CPP_words, 2))\n",
    "HTML_bigrams = pd.Series(nltk.ngrams(HTML_words, 2))\n",
    "Python_bigrams = pd.Series(nltk.ngrams(Python_words, 2))\n",
    "CSS_bigrams = pd.Series(nltk.ngrams(CSS_words, 2))\n",
    "C_bigrams = pd.Series(nltk.ngrams(C_words, 2))\n",
    "Java_bigrams = pd.Series(nltk.ngrams(Java_words, 2))\n",
    "JavaScript_bigrams = pd.Series(nltk.ngrams(JavaScript_words, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Idea Vectorize using bigrams...ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Idea Could try looking at frequency of bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Shell_bigrams_freq = pd.Series(Shell_bigrams).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(github, com)          103\n",
       "(http, github)         102\n",
       "(http, www)             52\n",
       "(passenger, docker)     48\n",
       "(pyenv, virtualenv)     45\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Shell_bigrams_freq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decided to drop readme_contents_stemmed. Limmitizing is reputed to the most accurate and because the data set is\n",
    "# small the trade of in quicker computation time is negligable. There is also insufficient time to explore the \n",
    "# stem option any further.\n",
    "df.drop(columns='readme_contents_stemmed',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>readme_contents_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CSS</td>\n",
       "      <td>welcome warning book finished still working ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Java</td>\n",
       "      <td>monorepo deeplearning j welcome new monorepo d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Java</td>\n",
       "      <td>h join chat http gitter im h oai h http badge ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C++</td>\n",
       "      <td>div align center img src http www tensorflow o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C++</td>\n",
       "      <td>grpc rpc library framework grpc modern open so...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language                         readme_contents_lemmatized\n",
       "0      CSS  welcome warning book finished still working ch...\n",
       "1     Java  monorepo deeplearning j welcome new monorepo d...\n",
       "2     Java  h join chat http gitter im h oai h http badge ...\n",
       "3      C++  div align center img src http www tensorflow o...\n",
       "4      C++  grpc rpc library framework grpc modern open so..."
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random forest classifier on training set: 0.69\n",
      "Accuracy of random forest classifier on training set: 0.29\n"
     ]
    }
   ],
   "source": [
    "# Create baseline model\n",
    "\n",
    "# vectorize stemmed readme contents and assign X any y veriables\n",
    "tfidf = TfidfVectorizer()\n",
    "X = tfidf.fit_transform(df.readme_contents_lemmatized)\n",
    "y = df.language\n",
    "\n",
    "# Split Data into test and train\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size = .2, random_state = 123)\n",
    "    \n",
    "# Create Random Forest object and fit it to the data\n",
    "rf = RandomForestClassifier(bootstrap=True, \n",
    "                            class_weight=None, \n",
    "                            criterion='gini',\n",
    "                            min_samples_leaf=3,\n",
    "                            n_estimators=100,\n",
    "                            max_depth=3, \n",
    "                            random_state=123)\n",
    "        \n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# print accuracy for train and test data sets\n",
    "print('Accuracy of random forest classifier on training set: {:.2f}'\n",
    "      .format(rf.score(X_train, y_train)))\n",
    "print('Accuracy of random forest classifier on training set: {:.2f}'\n",
    "     .format(rf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because there are 8 total languages we would expect an accuracy rating of .13 (rounded).\n",
    "\n",
    "The Baseline model performed better than chance at .29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random forest classifier on training set: 0.39\n",
      "Accuracy of random forest classifier on training set: 0.29\n"
     ]
    }
   ],
   "source": [
    "# Try baseline model using bigrams\n",
    "\n",
    "# vectorize stemmed readme contents and assign X any y veriables\n",
    "tfidf = TfidfVectorizer(ngram_range=(2, 2))\n",
    "X = tfidf.fit_transform(df.readme_contents_lemmatized)\n",
    "y = df.language\n",
    "\n",
    "# Split Data into test and train\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size = .2, random_state = 123)\n",
    "    \n",
    "# Create Random Forest object and fit it to the data\n",
    "rf = RandomForestClassifier(bootstrap=True, \n",
    "                            class_weight=None, \n",
    "                            criterion='gini',\n",
    "                            min_samples_leaf=3,\n",
    "                            n_estimators=100,\n",
    "                            max_depth=3, \n",
    "                            random_state=123)\n",
    "        \n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# print accuracy for train and test data sets\n",
    "print('Accuracy of random forest classifier on training set: {:.2f}'\n",
    "      .format(rf.score(X_train, y_train)))\n",
    "print('Accuracy of random forest classifier on training set: {:.2f}'\n",
    "     .format(rf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy of model does not improve with the use of bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random forest classifier on training set: 0.33\n",
      "Accuracy of random forest classifier on training set: 0.38\n"
     ]
    }
   ],
   "source": [
    "# Try baseline model using trigrams\n",
    "\n",
    "# vectorize stemmed readme contents and assign X any y veriables\n",
    "tfidf = TfidfVectorizer(ngram_range=(3, 3))\n",
    "X = tfidf.fit_transform(df.readme_contents_lemmatized)\n",
    "y = df.language\n",
    "\n",
    "# Split Data into test and train\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size = .2, random_state = 123)\n",
    "    \n",
    "# Create Random Forest object and fit it to the data\n",
    "rf = RandomForestClassifier(bootstrap=True, \n",
    "                            class_weight=None, \n",
    "                            criterion='gini',\n",
    "                            min_samples_leaf=3,\n",
    "                            n_estimators=100,\n",
    "                            max_depth=3, \n",
    "                            random_state=123)\n",
    "        \n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# print accuracy for train and test data sets\n",
    "print('Accuracy of random forest classifier on training set: {:.2f}'\n",
    "      .format(rf.score(X_train, y_train)))\n",
    "print('Accuracy of random forest classifier on training set: {:.2f}'\n",
    "     .format(rf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy of model impoves to .38 using trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random forest classifier on training set: 0.35\n",
      "Accuracy of random forest classifier on training set: 0.33\n"
     ]
    }
   ],
   "source": [
    "# Try baseline model using Tetragrams\n",
    "\n",
    "# vectorize stemmed readme contents and assign X any y veriables\n",
    "tfidf = TfidfVectorizer(ngram_range=(4, 4))\n",
    "X = tfidf.fit_transform(df.readme_contents_lemmatized)\n",
    "y = df.language\n",
    "\n",
    "# Split Data into test and train\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size = .2, random_state = 123)\n",
    "    \n",
    "# Create Random Forest object and fit it to the data\n",
    "rf = RandomForestClassifier(bootstrap=True, \n",
    "                            class_weight=None, \n",
    "                            criterion='gini',\n",
    "                            min_samples_leaf=3,\n",
    "                            n_estimators=100,\n",
    "                            max_depth=3, \n",
    "                            random_state=123)\n",
    "        \n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# print accuracy for train and test data sets\n",
    "print('Accuracy of random forest classifier on training set: {:.2f}'\n",
    "      .format(rf.score(X_train, y_train)))\n",
    "print('Accuracy of random forest classifier on training set: {:.2f}'\n",
    "     .format(rf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random forest classifier on training set: 0.35\n",
      "Accuracy of random forest classifier on training set: 0.33\n"
     ]
    }
   ],
   "source": [
    "# Try baseline model using the two most accurate grams (trigrams and tetragrams)\n",
    "\n",
    "# vectorize stemmed readme contents and assign X any y veriables\n",
    "tfidf = TfidfVectorizer(ngram_range=(4, 4))\n",
    "X = tfidf.fit_transform(df.readme_contents_lemmatized)\n",
    "y = df.language\n",
    "\n",
    "# Split Data into test and train\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size = .2, random_state = 123)\n",
    "    \n",
    "# Create Random Forest object and fit it to the data\n",
    "rf = RandomForestClassifier(bootstrap=True, \n",
    "                            class_weight=None, \n",
    "                            criterion='gini',\n",
    "                            min_samples_leaf=3,\n",
    "                            n_estimators=100,\n",
    "                            max_depth=3, \n",
    "                            random_state=123)\n",
    "        \n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# print accuracy for train and test data sets\n",
    "print('Accuracy of random forest classifier on training set: {:.2f}'\n",
    "      .format(rf.score(X_train, y_train)))\n",
    "print('Accuracy of random forest classifier on training set: {:.2f}'\n",
    "     .format(rf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model using only tetragrams has shown the best result .38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model using go-words\n",
    "\n",
    "# Split Data into test and train\n",
    "train, test = train_test_split(df, stratify=df.language, train_size = .8, random_state = 999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of words tied to each language in train\n",
    "CPP_words = e.word_soup(' '.join(train[train.language == 'C++'].readme_contents_lemmatized))\n",
    "HTML_words = e.word_soup(' '.join(train[train.language == 'HTML'].readme_contents_lemmatized))\n",
    "Python_words = e.word_soup(' '.join(train[train.language == 'Python'].readme_contents_lemmatized))\n",
    "CSS_words = e.word_soup(' '.join(train[train.language == 'CSS'].readme_contents_lemmatized))\n",
    "C_words = e.word_soup(' '.join(train[train.language == 'C'].readme_contents_lemmatized))\n",
    "Java_words = e.word_soup(' '.join(train[train.language == 'Java'].readme_contents_lemmatized))\n",
    "JavaScript_words = e.word_soup(' '.join(train[train.language == 'JavaScript'].readme_contents_lemmatized))\n",
    "Shell_words = e.word_soup(' '.join(train[train.language == 'Shell'].readme_contents_lemmatized))\n",
    "all_words = e.word_soup(' '.join(train.readme_contents_lemmatized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gets frequency of each word tied to each language in train\n",
    "CPP_freq = pd.Series(CPP_words).value_counts()\n",
    "HTML_freq = pd.Series(HTML_words).value_counts()\n",
    "Python_freq = pd.Series(Python_words).value_counts()\n",
    "CSS_freq = pd.Series(CSS_words).value_counts()\n",
    "C_freq = pd.Series(C_words).value_counts()\n",
    "Java_freq = pd.Series(Java_words).value_counts()\n",
    "JavaScript_freq = pd.Series(JavaScript_words).value_counts()\n",
    "Shell_freq = pd.Series(Shell_words).value_counts()\n",
    "all_freq = pd.Series(all_words).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a data frame that shows the frequency of each word across each language in train\n",
    "word_counts = (pd.concat([all_freq,CPP_freq,HTML_freq,Python_freq,CSS_freq,C_freq,Java_freq,JavaScript_freq,Shell_freq], axis=1, sort=True)\n",
    "                .set_axis(['all', 'C++', 'HTML', 'Python', 'CSS', 'C', 'Java', 'JavaScript', 'Shell'], axis=1, inplace=False)\n",
    "                .fillna(0)\n",
    "                .apply(lambda s: s.astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all</th>\n",
       "      <th>C++</th>\n",
       "      <th>HTML</th>\n",
       "      <th>Python</th>\n",
       "      <th>CSS</th>\n",
       "      <th>C</th>\n",
       "      <th>Java</th>\n",
       "      <th>JavaScript</th>\n",
       "      <th>Shell</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aa</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaa</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aab</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aac</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaction</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         all  C++  HTML  Python  CSS  C  Java  JavaScript  Shell\n",
       "aa        13    1     3       0    0  0     0           9      0\n",
       "aaa        5    0     0       0    0  0     0           1      4\n",
       "aab        1    0     0       0    1  0     0           0      0\n",
       "aac        1    0     0       0    0  0     0           1      0\n",
       "aaction    1    0     0       0    0  1     0           0      0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shows words that are unique to each language in train\n",
    "Shell_unique = word_counts[(word_counts['C++'] == 0) & (word_counts['HTML'] == 0) &(word_counts['Python'] == 0) & (word_counts['CSS'] == 0) & (word_counts['C'] == 0) & (word_counts['Java'] == 0) & (word_counts['JavaScript'] == 0)].sort_values(by='Shell', ascending=False)\n",
    "CPP_unique = word_counts[(word_counts['Shell'] == 0) & (word_counts['HTML'] == 0) &(word_counts['Python'] == 0) & (word_counts['CSS'] == 0) & (word_counts['C'] == 0) & (word_counts['Java'] == 0) & (word_counts['JavaScript'] == 0)].sort_values(by='C++', ascending=False)\n",
    "HTML_unique = word_counts[(word_counts['C++'] == 0) & (word_counts['Shell'] == 0) &(word_counts['Python'] == 0) & (word_counts['CSS'] == 0) & (word_counts['C'] == 0) & (word_counts['Java'] == 0) & (word_counts['JavaScript'] == 0)].sort_values(by='HTML', ascending=False)\n",
    "Python_unique = word_counts[(word_counts['C++'] == 0) & (word_counts['HTML'] == 0) &(word_counts['Shell'] == 0) & (word_counts['CSS'] == 0) & (word_counts['C'] == 0) & (word_counts['Java'] == 0) & (word_counts['JavaScript'] == 0)].sort_values(by='Python', ascending=False)\n",
    "CSS_unique = word_counts[(word_counts['C++'] == 0) & (word_counts['HTML'] == 0) &(word_counts['Python'] == 0) & (word_counts['Shell'] == 0) & (word_counts['C'] == 0) & (word_counts['Java'] == 0) & (word_counts['JavaScript'] == 0)].sort_values(by='CSS', ascending=False)\n",
    "C_unique = word_counts[(word_counts['C++'] == 0) & (word_counts['HTML'] == 0) &(word_counts['Python'] == 0) & (word_counts['CSS'] == 0) & (word_counts['Shell'] == 0) & (word_counts['Java'] == 0) & (word_counts['JavaScript'] == 0)].sort_values(by='C', ascending=False)\n",
    "Java_unique = word_counts[(word_counts['C++'] == 0) & (word_counts['HTML'] == 0) &(word_counts['Python'] == 0) & (word_counts['CSS'] == 0) & (word_counts['C'] == 0) & (word_counts['Shell'] == 0) & (word_counts['JavaScript'] == 0)].sort_values(by='Java', ascending=False)\n",
    "JavaScript_unique = word_counts[(word_counts['C++'] == 0) & (word_counts['HTML'] == 0) &(word_counts['Python'] == 0) & (word_counts['CSS'] == 0) & (word_counts['C'] == 0) & (word_counts['Java'] == 0) & (word_counts['Shell'] == 0)].sort_values(by='JavaScript', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join all words that are unique to one language together in one list\n",
    "go_words = set(Shell_unique.index).union(set(CPP_unique.index)).union(set(HTML_unique.index)).union(set(Python_unique.index)).union(set(CSS_unique.index)).union(set(C_unique.index)).union(set(Java_unique.index)).union(set(JavaScript_unique.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function removes words that are not in go_words\n",
    "def one_language_words(text):\n",
    "    \n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    " \n",
    "    words = re.sub(r'[^\\w\\s]', '', text).split()\n",
    "    \n",
    "    return ' '.join([word for word in words if word in go_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'readme_contents_lemmatized'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-d8138c9d1694>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# in train data apply one_language_words to readme_contents_lemmitized in a new column and drop the old column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'readme_unique'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadme_contents_lemmatized\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mone_language_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'readme_contents_lemmatized'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5065\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5066\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5067\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5069\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'readme_contents_lemmatized'"
     ]
    }
   ],
   "source": [
    "# in train data apply one_language_words to readme_contents_lemmitized in a new column and drop the old column \n",
    "train['readme_unique'] = train.readme_contents_lemmatized.apply(one_language_words)\n",
    "train.drop(columns = 'readme_contents_lemmatized',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.readme_unique[train.readme_unique==' '].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'readme_contents_lemmatized'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-3089e7a44bb4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# in test data apply one_language_words to readme_contents_lemmitized in a new column and drop the old column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'readme_unique'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadme_contents_lemmatized\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mone_language_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'readme_contents_lemmatized'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5065\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5066\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5067\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5069\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'readme_contents_lemmatized'"
     ]
    }
   ],
   "source": [
    "# in test data apply one_language_words to readme_contents_lemmitized in a new column and drop the old column \n",
    "test['readme_unique'] = test.readme_contents_lemmatized.apply(one_language_words)\n",
    "test.drop(columns = 'readme_contents_lemmatized',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.readme_unique[test.readme_unique==' '].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test.readme_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test.language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<21x617 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 722 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on training set: 0.31\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Number of features of the model must match the input. Model n_features is 6253 and input n_features is 617 ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-4a0c12c83144>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m      .format(clf.score(X_train, y_train)))\n\u001b[1;32m     22\u001b[0m print('Accuracy of Decision Tree classifier on test set: {:.2f}'\n\u001b[0;32m---> 23\u001b[0;31m      .format(clf.score(X_test, y_test)))\n\u001b[0m",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    355\u001b[0m         \"\"\"\n\u001b[1;32m    356\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    428\u001b[0m         \"\"\"\n\u001b[1;32m    429\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tree_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    400\u001b[0m                              \u001b[0;34m\"match the input. Model n_features is %s and \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m                              \u001b[0;34m\"input n_features is %s \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m                              % (self.n_features_, n_features))\n\u001b[0m\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Number of features of the model must match the input. Model n_features is 6253 and input n_features is 617 "
     ]
    }
   ],
   "source": [
    "# Try model using unique to language words\n",
    "\n",
    "# vectorize stemmed readme contents and assign X any y veriables\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "# split test and train into x and y test and train\n",
    "X_train = tfidf.fit_transform(train.readme_unique)\n",
    "y_train = train.language\n",
    "\n",
    "X_test = tfidf.fit_transform(test.readme_unique)\n",
    "y_test= test.language\n",
    "\n",
    "# create clasifier object and fit to data\n",
    "clf = DecisionTreeClassifier(criterion='gini', max_depth=3, random_state=123)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'\n",
    "     .format(clf.score(X_train, y_train)))\n",
    "print('Accuracy of Decision Tree classifier on test set: {:.2f}'\n",
    "     .format(clf.score(X_test, y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try model using unique to language words\n",
    "\n",
    "# vectorize stemmed readme contents and assign X any y veriables\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "# split test and train into x and y test and train\n",
    "X_train = tfidf.fit_transform(train.readme_unique)\n",
    "y_train = train.language\n",
    "\n",
    "X_test = tfidf.fit_transform(test.readme_unique)\n",
    "y_test= test.language\n",
    "\n",
    "# Create Random Forest object and fit it to the data\n",
    "rf = RandomForestClassifier(bootstrap=True, \n",
    "                            class_weight=None, \n",
    "                            criterion='gini',\n",
    "                            min_samples_leaf=3,\n",
    "                            n_estimators=100,\n",
    "                            max_depth=3, \n",
    "                            random_state=123)\n",
    "        \n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# print accuracy for train and test data sets\n",
    "print('Accuracy of random forest classifier on training set: {:.2f}'\n",
    "      .format(rf.score(X_train, y_train)))\n",
    "print('Accuracy of random forest classifier on test set: {:.2f}'\n",
    "      .format(rf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # vectorize stemmed readme contents and assign X any y veriables\n",
    "# tfidf = TfidfVectorizer()\n",
    "# X_train = tfidf.fit_transform(train.readme_unique)\n",
    "# y_train = train.language"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
