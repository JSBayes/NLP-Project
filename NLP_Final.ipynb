{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goals\n",
    "\n",
    " 1) Construct a web scraper capable of gathering data from github repositories. Data collected should include the main programing language used in that repository, and the contents of that repository’s readme file.\n",
    "\n",
    " 2) Use natural language processing to develop a model to predict each repositories programming language based on the contents of that repository’s readme file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "import nltk\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import acquire as a # produces output sometimes\n",
    "import prepare as p\n",
    "import explore as e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acqusition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calles functions in acquire.py to scrape git hub repositories and create a dictionary containing the repo url,\n",
    "# language, and readme contents of each folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calls functions in prepare.py. Functions convert the dictionaries in the json file into a data frame. \n",
    "# Then add two columns to the data frame, applying basic cleaning algorithms to the readme contents. \n",
    "# Stemming is then applied to one of those columns. Lemmatize is applied to the other.\n",
    "# Functions also drop rows that did not produce usable data\n",
    "df = p.prep_readme()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>readme_contents</th>\n",
       "      <th>repo</th>\n",
       "      <th>readme_contents_stemmed</th>\n",
       "      <th>readme_contents_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CSS</td>\n",
       "      <td># Welcome\\n\\n&gt; **Warning**: this book is **not...</td>\n",
       "      <td>/nakov/Practical-Cryptography-for-Developers-Book</td>\n",
       "      <td>welcom warn book finish still work chapter com...</td>\n",
       "      <td>welcome warning book finished still working ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Java</td>\n",
       "      <td># Monorepo of Deeplearning4j\\n\\nWelcome to the...</td>\n",
       "      <td>/eclipse/deeplearning4j</td>\n",
       "      <td>monorepo deeplearn j welcom new monorepo deepl...</td>\n",
       "      <td>monorepo deeplearning j welcome new monorepo d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Java</td>\n",
       "      <td># H2O\\n\\n[![Join the chat at https://gitter.im...</td>\n",
       "      <td>/h2oai/h2o-3</td>\n",
       "      <td>h join chat http gitter im h oai h http badg g...</td>\n",
       "      <td>h join chat http gitter im h oai h http badge ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C++</td>\n",
       "      <td>&lt;div align=\"center\"&gt;\\n  &lt;img src=\"https://www....</td>\n",
       "      <td>/tensorflow/tensorflow</td>\n",
       "      <td>div align center img src http www tensorflow o...</td>\n",
       "      <td>div align center img src http www tensorflow o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C++</td>\n",
       "      <td>gRPC - An RPC library and framework\\n=========...</td>\n",
       "      <td>/grpc/grpc</td>\n",
       "      <td>grpc rpc librari framework grpc modern open so...</td>\n",
       "      <td>grpc rpc library framework grpc modern open so...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language                                    readme_contents  \\\n",
       "0      CSS  # Welcome\\n\\n> **Warning**: this book is **not...   \n",
       "1     Java  # Monorepo of Deeplearning4j\\n\\nWelcome to the...   \n",
       "2     Java  # H2O\\n\\n[![Join the chat at https://gitter.im...   \n",
       "3      C++  <div align=\"center\">\\n  <img src=\"https://www....   \n",
       "4      C++  gRPC - An RPC library and framework\\n=========...   \n",
       "\n",
       "                                                repo  \\\n",
       "0  /nakov/Practical-Cryptography-for-Developers-Book   \n",
       "1                            /eclipse/deeplearning4j   \n",
       "2                                       /h2oai/h2o-3   \n",
       "3                             /tensorflow/tensorflow   \n",
       "4                                         /grpc/grpc   \n",
       "\n",
       "                             readme_contents_stemmed  \\\n",
       "0  welcom warn book finish still work chapter com...   \n",
       "1  monorepo deeplearn j welcom new monorepo deepl...   \n",
       "2  h join chat http gitter im h oai h http badg g...   \n",
       "3  div align center img src http www tensorflow o...   \n",
       "4  grpc rpc librari framework grpc modern open so...   \n",
       "\n",
       "                          readme_contents_lemmatized  \n",
       "0  welcome warning book finished still working ch...  \n",
       "1  monorepo deeplearning j welcome new monorepo d...  \n",
       "2  h join chat http gitter im h oai h http badge ...  \n",
       "3  div align center img src http www tensorflow o...  \n",
       "4  grpc rpc library framework grpc modern open so...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First peek at prepared data.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping repo column. The goal is to predict language using readme contents so repo it is not useful\n",
    "df.drop(columns='repo',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping readme_contents. The column was there for comparison to insure prepre functions worked as expected.\n",
    "# It is no longer needed.\n",
    "df.drop(columns='readme_contents',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>readme_contents_stemmed</th>\n",
       "      <th>readme_contents_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CSS</td>\n",
       "      <td>welcom warn book finish still work chapter com...</td>\n",
       "      <td>welcome warning book finished still working ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Java</td>\n",
       "      <td>monorepo deeplearn j welcom new monorepo deepl...</td>\n",
       "      <td>monorepo deeplearning j welcome new monorepo d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Java</td>\n",
       "      <td>h join chat http gitter im h oai h http badg g...</td>\n",
       "      <td>h join chat http gitter im h oai h http badge ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C++</td>\n",
       "      <td>div align center img src http www tensorflow o...</td>\n",
       "      <td>div align center img src http www tensorflow o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C++</td>\n",
       "      <td>grpc rpc librari framework grpc modern open so...</td>\n",
       "      <td>grpc rpc library framework grpc modern open so...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language                            readme_contents_stemmed  \\\n",
       "0      CSS  welcom warn book finish still work chapter com...   \n",
       "1     Java  monorepo deeplearn j welcom new monorepo deepl...   \n",
       "2     Java  h join chat http gitter im h oai h http badg g...   \n",
       "3      C++  div align center img src http www tensorflow o...   \n",
       "4      C++  grpc rpc librari framework grpc modern open so...   \n",
       "\n",
       "                          readme_contents_lemmatized  \n",
       "0  welcome warning book finished still working ch...  \n",
       "1  monorepo deeplearning j welcome new monorepo d...  \n",
       "2  h join chat http gitter im h oai h http badge ...  \n",
       "3  div align center img src http www tensorflow o...  \n",
       "4  grpc rpc library framework grpc modern open so...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Dictionary\n",
    "\n",
    "# 1) language - main programing language used by the repository add how this was determined\n",
    "\n",
    "2) readme_contents_stemmed - contents of readme file cleaned and stemed\n",
    "\n",
    "3) readme_contents_lemmatized - contents of readme file cleaned and lemmatized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### looking at initial data statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C++</th>\n",
       "      <td>20</td>\n",
       "      <td>0.190476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HTML</th>\n",
       "      <td>20</td>\n",
       "      <td>0.190476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Python</th>\n",
       "      <td>15</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Java</th>\n",
       "      <td>10</td>\n",
       "      <td>0.095238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JavaScript</th>\n",
       "      <td>10</td>\n",
       "      <td>0.095238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>10</td>\n",
       "      <td>0.095238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shell</th>\n",
       "      <td>10</td>\n",
       "      <td>0.095238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSS</th>\n",
       "      <td>10</td>\n",
       "      <td>0.095238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            number   percent\n",
       "C++             20  0.190476\n",
       "HTML            20  0.190476\n",
       "Python          15  0.142857\n",
       "Java            10  0.095238\n",
       "JavaScript      10  0.095238\n",
       "C               10  0.095238\n",
       "Shell           10  0.095238\n",
       "CSS             10  0.095238"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shows the number and percent of repositories that represent each language\n",
    "labels = pd.concat([df.language.value_counts(),\n",
    "                    df.language.value_counts(normalize=True)], axis=1)\n",
    "labels.columns = ['number', 'percent']\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gets a list of words tied to each language\n",
    "CPP_words = e.word_soup(' '.join(df[df.language == 'C++'].readme_contents_lemmatized))\n",
    "HTML_words = e.word_soup(' '.join(df[df.language == 'HTML'].readme_contents_lemmatized))\n",
    "Python_words = e.word_soup(' '.join(df[df.language == 'Python'].readme_contents_lemmatized))\n",
    "CSS_words = e.word_soup(' '.join(df[df.language == 'CSS'].readme_contents_lemmatized))\n",
    "C_words = e.word_soup(' '.join(df[df.language == 'C'].readme_contents_lemmatized))\n",
    "Java_words = e.word_soup(' '.join(df[df.language == 'Java'].readme_contents_lemmatized))\n",
    "JavaScript_words = e.word_soup(' '.join(df[df.language == 'JavaScript'].readme_contents_lemmatized))\n",
    "Shell_words = e.word_soup(' '.join(df[df.language == 'Shell'].readme_contents_lemmatized))\n",
    "all_words = e.word_soup(' '.join(df.readme_contents_lemmatized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gets frequency of each word tied to each language\n",
    "CPP_freq = pd.Series(CPP_words).value_counts()\n",
    "HTML_freq = pd.Series(HTML_words).value_counts()\n",
    "Python_freq = pd.Series(Python_words).value_counts()\n",
    "CSS_freq = pd.Series(CSS_words).value_counts()\n",
    "C_freq = pd.Series(C_words).value_counts()\n",
    "Java_freq = pd.Series(Java_words).value_counts()\n",
    "JavaScript_freq = pd.Series(JavaScript_words).value_counts()\n",
    "Shell_freq = pd.Series(Shell_words).value_counts()\n",
    "all_freq = pd.Series(all_words).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a data frame that shows the frequency of each word across each language\n",
    "word_counts = (pd.concat([all_freq,CPP_freq,HTML_freq,Python_freq,CSS_freq,C_freq,Java_freq,JavaScript_freq,Shell_freq], axis=1, sort=True)\n",
    "                .set_axis(['all', 'C++', 'HTML', 'Python', 'CSS', 'C', 'Java', 'JavaScript', 'Shell'], axis=1, inplace=False)\n",
    "                .fillna(0)\n",
    "                .apply(lambda s: s.astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all</th>\n",
       "      <th>C++</th>\n",
       "      <th>HTML</th>\n",
       "      <th>Python</th>\n",
       "      <th>CSS</th>\n",
       "      <th>C</th>\n",
       "      <th>Java</th>\n",
       "      <th>JavaScript</th>\n",
       "      <th>Shell</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aa</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaa</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaaaaelftksuqmcc</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaaaaxrstlmaqobyzgaaaafis</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaaaikleqvqi</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           all  C++  HTML  Python  CSS  C  Java  JavaScript  \\\n",
       "aa                          14    1     3       0    0  0     0          10   \n",
       "aaa                          5    0     0       0    0  0     0           1   \n",
       "aaaaaelftksuqmcc             1    1     0       0    0  0     0           0   \n",
       "aaaaaxrstlmaqobyzgaaaafis    1    1     0       0    0  0     0           0   \n",
       "aaaaikleqvqi                 1    1     0       0    0  0     0           0   \n",
       "\n",
       "                           Shell  \n",
       "aa                             0  \n",
       "aaa                            4  \n",
       "aaaaaelftksuqmcc               0  \n",
       "aaaaaxrstlmaqobyzgaaaafis      0  \n",
       "aaaaikleqvqi                   0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all</th>\n",
       "      <th>C++</th>\n",
       "      <th>HTML</th>\n",
       "      <th>Python</th>\n",
       "      <th>CSS</th>\n",
       "      <th>C</th>\n",
       "      <th>Java</th>\n",
       "      <th>JavaScript</th>\n",
       "      <th>Shell</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>http</th>\n",
       "      <td>4434</td>\n",
       "      <td>710</td>\n",
       "      <td>421</td>\n",
       "      <td>1385</td>\n",
       "      <td>258</td>\n",
       "      <td>136</td>\n",
       "      <td>357</td>\n",
       "      <td>855</td>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>com</th>\n",
       "      <td>2926</td>\n",
       "      <td>418</td>\n",
       "      <td>290</td>\n",
       "      <td>955</td>\n",
       "      <td>193</td>\n",
       "      <td>45</td>\n",
       "      <td>220</td>\n",
       "      <td>615</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>github</th>\n",
       "      <td>1538</td>\n",
       "      <td>244</td>\n",
       "      <td>80</td>\n",
       "      <td>613</td>\n",
       "      <td>149</td>\n",
       "      <td>34</td>\n",
       "      <td>177</td>\n",
       "      <td>112</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>python</th>\n",
       "      <td>1189</td>\n",
       "      <td>73</td>\n",
       "      <td>85</td>\n",
       "      <td>550</td>\n",
       "      <td>53</td>\n",
       "      <td>63</td>\n",
       "      <td>48</td>\n",
       "      <td>43</td>\n",
       "      <td>274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>org</th>\n",
       "      <td>714</td>\n",
       "      <td>177</td>\n",
       "      <td>79</td>\n",
       "      <td>261</td>\n",
       "      <td>27</td>\n",
       "      <td>42</td>\n",
       "      <td>75</td>\n",
       "      <td>27</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>www</th>\n",
       "      <td>693</td>\n",
       "      <td>63</td>\n",
       "      <td>123</td>\n",
       "      <td>193</td>\n",
       "      <td>34</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "      <td>188</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>657</td>\n",
       "      <td>60</td>\n",
       "      <td>74</td>\n",
       "      <td>128</td>\n",
       "      <td>15</td>\n",
       "      <td>52</td>\n",
       "      <td>77</td>\n",
       "      <td>162</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>href</th>\n",
       "      <td>602</td>\n",
       "      <td>31</td>\n",
       "      <td>402</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>md</th>\n",
       "      <td>600</td>\n",
       "      <td>51</td>\n",
       "      <td>185</td>\n",
       "      <td>43</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>61</td>\n",
       "      <td>179</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x</th>\n",
       "      <td>513</td>\n",
       "      <td>31</td>\n",
       "      <td>15</td>\n",
       "      <td>294</td>\n",
       "      <td>20</td>\n",
       "      <td>22</td>\n",
       "      <td>50</td>\n",
       "      <td>16</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         all  C++  HTML  Python  CSS    C  Java  JavaScript  Shell\n",
       "http    4434  710   421    1385  258  136   357         855    312\n",
       "com     2926  418   290     955  193   45   220         615    190\n",
       "github  1538  244    80     613  149   34   177         112    129\n",
       "python  1189   73    85     550   53   63    48          43    274\n",
       "org      714  177    79     261   27   42    75          27     26\n",
       "www      693   63   123     193   34    7    31         188     54\n",
       "c        657   60    74     128   15   52    77         162     89\n",
       "href     602   31   402     107    3    0    24          34      1\n",
       "md       600   51   185      43   12   15    61         179     54\n",
       "x        513   31    15     294   20   22    50          16     65"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shows the 10 most frequently occuring words\n",
    "word_counts.sort_values(by='all', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shows words that are unique to each language\n",
    "Shell_unique = word_counts[(word_counts['C++'] == 0) & (word_counts['HTML'] == 0) &(word_counts['Python'] == 0) & (word_counts['CSS'] == 0) & (word_counts['C'] == 0) & (word_counts['Java'] == 0) & (word_counts['JavaScript'] == 0)].sort_values(by='Shell', ascending=False)\n",
    "CPP_unique = word_counts[(word_counts['Shell'] == 0) & (word_counts['HTML'] == 0) &(word_counts['Python'] == 0) & (word_counts['CSS'] == 0) & (word_counts['C'] == 0) & (word_counts['Java'] == 0) & (word_counts['JavaScript'] == 0)].sort_values(by='C++', ascending=False)\n",
    "HTML_unique = word_counts[(word_counts['C++'] == 0) & (word_counts['Shell'] == 0) &(word_counts['Python'] == 0) & (word_counts['CSS'] == 0) & (word_counts['C'] == 0) & (word_counts['Java'] == 0) & (word_counts['JavaScript'] == 0)].sort_values(by='HTML', ascending=False)\n",
    "Python_unique = word_counts[(word_counts['C++'] == 0) & (word_counts['HTML'] == 0) &(word_counts['Shell'] == 0) & (word_counts['CSS'] == 0) & (word_counts['C'] == 0) & (word_counts['Java'] == 0) & (word_counts['JavaScript'] == 0)].sort_values(by='Python', ascending=False)\n",
    "CSS_unique = word_counts[(word_counts['C++'] == 0) & (word_counts['HTML'] == 0) &(word_counts['Python'] == 0) & (word_counts['Shell'] == 0) & (word_counts['C'] == 0) & (word_counts['Java'] == 0) & (word_counts['JavaScript'] == 0)].sort_values(by='CSS', ascending=False)\n",
    "C_unique = word_counts[(word_counts['C++'] == 0) & (word_counts['HTML'] == 0) &(word_counts['Python'] == 0) & (word_counts['CSS'] == 0) & (word_counts['Shell'] == 0) & (word_counts['Java'] == 0) & (word_counts['JavaScript'] == 0)].sort_values(by='C', ascending=False)\n",
    "Java_unique = word_counts[(word_counts['C++'] == 0) & (word_counts['HTML'] == 0) &(word_counts['Python'] == 0) & (word_counts['CSS'] == 0) & (word_counts['C'] == 0) & (word_counts['Shell'] == 0) & (word_counts['JavaScript'] == 0)].sort_values(by='Java', ascending=False)\n",
    "JavaScript_unique = word_counts[(word_counts['C++'] == 0) & (word_counts['HTML'] == 0) &(word_counts['Python'] == 0) & (word_counts['CSS'] == 0) & (word_counts['C'] == 0) & (word_counts['Java'] == 0) & (word_counts['Shell'] == 0)].sort_values(by='JavaScript', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idea create list of stop words that are all values except unique-to-language words from train group then\n",
    "# try to predict test group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking at bigrams\n",
    "# shows bigrams for data set\n",
    "Shell_bigrams = pd.Series(nltk.ngrams(Shell_words, 2))\n",
    "CPP_bigrams = pd.Series(nltk.ngrams(CPP_words, 2))\n",
    "HTML_bigrams = pd.Series(nltk.ngrams(HTML_words, 2))\n",
    "Python_bigrams = pd.Series(nltk.ngrams(Python_words, 2))\n",
    "CSS_bigrams = pd.Series(nltk.ngrams(CSS_words, 2))\n",
    "C_bigrams = pd.Series(nltk.ngrams(C_words, 2))\n",
    "Java_bigrams = pd.Series(nltk.ngrams(Java_words, 2))\n",
    "JavaScript_bigrams = pd.Series(nltk.ngrams(JavaScript_words, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Idea Vectorize using bigrams...ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Idea Could try looking at frequency of bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Shell_bigrams_freq = pd.Series(Shell_bigrams).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(github, com)          103\n",
       "(http, github)         102\n",
       "(http, www)             52\n",
       "(passenger, docker)     48\n",
       "(pyenv, virtualenv)     45\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Shell_bigrams_freq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decided to drop readme_contents_stemmed. Limmitizing is reputed to the most accurate and because the data set is\n",
    "# small the trade of in quicker computation time is negligable. There is also insufficient time to explore the \n",
    "# stem option any further.\n",
    "df.drop(columns='readme_contents_stemmed',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>readme_contents_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CSS</td>\n",
       "      <td>welcome warning book finished still working ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Java</td>\n",
       "      <td>monorepo deeplearning j welcome new monorepo d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Java</td>\n",
       "      <td>h join chat http gitter im h oai h http badge ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C++</td>\n",
       "      <td>div align center img src http www tensorflow o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C++</td>\n",
       "      <td>grpc rpc library framework grpc modern open so...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language                         readme_contents_lemmatized\n",
       "0      CSS  welcome warning book finished still working ch...\n",
       "1     Java  monorepo deeplearning j welcome new monorepo d...\n",
       "2     Java  h join chat http gitter im h oai h http badge ...\n",
       "3      C++  div align center img src http www tensorflow o...\n",
       "4      C++  grpc rpc library framework grpc modern open so..."
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random forest classifier on training set: 0.69\n",
      "Accuracy of random forest classifier on training set: 0.29\n"
     ]
    }
   ],
   "source": [
    "# Create baseline model\n",
    "\n",
    "# vectorize stemmed readme contents and assign X any y veriables\n",
    "tfidf = TfidfVectorizer()\n",
    "X = tfidf.fit_transform(df.readme_contents_lemmatized)\n",
    "y = df.language\n",
    "\n",
    "# Split Data into test and train\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size = .2, random_state = 123)\n",
    "    \n",
    "# Create Random Forest object and fit it to the data\n",
    "rf = RandomForestClassifier(bootstrap=True, \n",
    "                            class_weight=None, \n",
    "                            criterion='gini',\n",
    "                            min_samples_leaf=3,\n",
    "                            n_estimators=100,\n",
    "                            max_depth=3, \n",
    "                            random_state=123)\n",
    "        \n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# print accuracy for train and test data sets\n",
    "print('Accuracy of random forest classifier on training set: {:.2f}'\n",
    "      .format(rf.score(X_train, y_train)))\n",
    "print('Accuracy of random forest classifier on training set: {:.2f}'\n",
    "     .format(rf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because there are 8 total languages we would expect an accuracy rating of .13 (rounded).\n",
    "\n",
    "The Baseline model performed better than chance at .29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random forest classifier on training set: 0.39\n",
      "Accuracy of random forest classifier on training set: 0.29\n"
     ]
    }
   ],
   "source": [
    "# Try baseline model using bigrams\n",
    "\n",
    "# vectorize stemmed readme contents and assign X any y veriables\n",
    "tfidf = TfidfVectorizer(ngram_range=(2, 2))\n",
    "X = tfidf.fit_transform(df.readme_contents_lemmatized)\n",
    "y = df.language\n",
    "\n",
    "# Split Data into test and train\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size = .2, random_state = 123)\n",
    "    \n",
    "# Create Random Forest object and fit it to the data\n",
    "rf = RandomForestClassifier(bootstrap=True, \n",
    "                            class_weight=None, \n",
    "                            criterion='gini',\n",
    "                            min_samples_leaf=3,\n",
    "                            n_estimators=100,\n",
    "                            max_depth=3, \n",
    "                            random_state=123)\n",
    "        \n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# print accuracy for train and test data sets\n",
    "print('Accuracy of random forest classifier on training set: {:.2f}'\n",
    "      .format(rf.score(X_train, y_train)))\n",
    "print('Accuracy of random forest classifier on training set: {:.2f}'\n",
    "     .format(rf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy of model does not improve with the use of bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random forest classifier on training set: 0.33\n",
      "Accuracy of random forest classifier on training set: 0.38\n"
     ]
    }
   ],
   "source": [
    "# Try baseline model using trigrams\n",
    "\n",
    "# vectorize stemmed readme contents and assign X any y veriables\n",
    "tfidf = TfidfVectorizer(ngram_range=(3, 3))\n",
    "X = tfidf.fit_transform(df.readme_contents_lemmatized)\n",
    "y = df.language\n",
    "\n",
    "# Split Data into test and train\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size = .2, random_state = 123)\n",
    "    \n",
    "# Create Random Forest object and fit it to the data\n",
    "rf = RandomForestClassifier(bootstrap=True, \n",
    "                            class_weight=None, \n",
    "                            criterion='gini',\n",
    "                            min_samples_leaf=3,\n",
    "                            n_estimators=100,\n",
    "                            max_depth=3, \n",
    "                            random_state=123)\n",
    "        \n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# print accuracy for train and test data sets\n",
    "print('Accuracy of random forest classifier on training set: {:.2f}'\n",
    "      .format(rf.score(X_train, y_train)))\n",
    "print('Accuracy of random forest classifier on training set: {:.2f}'\n",
    "     .format(rf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy of model impoves to .38 using trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random forest classifier on training set: 0.35\n",
      "Accuracy of random forest classifier on training set: 0.33\n"
     ]
    }
   ],
   "source": [
    "# Try baseline model using Tetragrams\n",
    "\n",
    "# vectorize stemmed readme contents and assign X any y veriables\n",
    "tfidf = TfidfVectorizer(ngram_range=(4, 4))\n",
    "X = tfidf.fit_transform(df.readme_contents_lemmatized)\n",
    "y = df.language\n",
    "\n",
    "# Split Data into test and train\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size = .2, random_state = 123)\n",
    "    \n",
    "# Create Random Forest object and fit it to the data\n",
    "rf = RandomForestClassifier(bootstrap=True, \n",
    "                            class_weight=None, \n",
    "                            criterion='gini',\n",
    "                            min_samples_leaf=3,\n",
    "                            n_estimators=100,\n",
    "                            max_depth=3, \n",
    "                            random_state=123)\n",
    "        \n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# print accuracy for train and test data sets\n",
    "print('Accuracy of random forest classifier on training set: {:.2f}'\n",
    "      .format(rf.score(X_train, y_train)))\n",
    "print('Accuracy of random forest classifier on training set: {:.2f}'\n",
    "     .format(rf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random forest classifier on training set: 0.35\n",
      "Accuracy of random forest classifier on training set: 0.33\n"
     ]
    }
   ],
   "source": [
    "# Try baseline model using the two most accurate grams (trigrams and tetragrams)\n",
    "\n",
    "# vectorize stemmed readme contents and assign X any y veriables\n",
    "tfidf = TfidfVectorizer(ngram_range=(4, 4))\n",
    "X = tfidf.fit_transform(df.readme_contents_lemmatized)\n",
    "y = df.language\n",
    "\n",
    "# Split Data into test and train\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size = .2, random_state = 123)\n",
    "    \n",
    "# Create Random Forest object and fit it to the data\n",
    "rf = RandomForestClassifier(bootstrap=True, \n",
    "                            class_weight=None, \n",
    "                            criterion='gini',\n",
    "                            min_samples_leaf=3,\n",
    "                            n_estimators=100,\n",
    "                            max_depth=3, \n",
    "                            random_state=123)\n",
    "        \n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# print accuracy for train and test data sets\n",
    "print('Accuracy of random forest classifier on training set: {:.2f}'\n",
    "      .format(rf.score(X_train, y_train)))\n",
    "print('Accuracy of random forest classifier on training set: {:.2f}'\n",
    "     .format(rf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model using only tetragrams has shown the best result .38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model using go-words\n",
    "\n",
    "# Split Data into test and train\n",
    "train, test = train_test_split(df, stratify=df.language, train_size = .8, random_state = 999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of words tied to each language in train\n",
    "CPP_words = e.word_soup(' '.join(train[train.language == 'C++'].readme_contents_lemmatized))\n",
    "HTML_words = e.word_soup(' '.join(train[train.language == 'HTML'].readme_contents_lemmatized))\n",
    "Python_words = e.word_soup(' '.join(train[train.language == 'Python'].readme_contents_lemmatized))\n",
    "CSS_words = e.word_soup(' '.join(train[train.language == 'CSS'].readme_contents_lemmatized))\n",
    "C_words = e.word_soup(' '.join(train[train.language == 'C'].readme_contents_lemmatized))\n",
    "Java_words = e.word_soup(' '.join(train[train.language == 'Java'].readme_contents_lemmatized))\n",
    "JavaScript_words = e.word_soup(' '.join(train[train.language == 'JavaScript'].readme_contents_lemmatized))\n",
    "Shell_words = e.word_soup(' '.join(train[train.language == 'Shell'].readme_contents_lemmatized))\n",
    "all_words = e.word_soup(' '.join(train.readme_contents_lemmatized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gets frequency of each word tied to each language in train\n",
    "CPP_freq = pd.Series(CPP_words).value_counts()\n",
    "HTML_freq = pd.Series(HTML_words).value_counts()\n",
    "Python_freq = pd.Series(Python_words).value_counts()\n",
    "CSS_freq = pd.Series(CSS_words).value_counts()\n",
    "C_freq = pd.Series(C_words).value_counts()\n",
    "Java_freq = pd.Series(Java_words).value_counts()\n",
    "JavaScript_freq = pd.Series(JavaScript_words).value_counts()\n",
    "Shell_freq = pd.Series(Shell_words).value_counts()\n",
    "all_freq = pd.Series(all_words).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a data frame that shows the frequency of each word across each language\n",
    "word_counts = (pd.concat([all_freq,CPP_freq,HTML_freq,Python_freq,CSS_freq,C_freq,Java_freq,JavaScript_freq,Shell_freq], axis=1, sort=True)\n",
    "                .set_axis(['all', 'C++', 'HTML', 'Python', 'CSS', 'C', 'Java', 'JavaScript', 'Shell'], axis=1, inplace=False)\n",
    "                .fillna(0)\n",
    "                .apply(lambda s: s.astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shows words that are unique to each language\n",
    "Shell_unique = word_counts[(word_counts['C++'] == 0) & (word_counts['HTML'] == 0) &(word_counts['Python'] == 0) & (word_counts['CSS'] == 0) & (word_counts['C'] == 0) & (word_counts['Java'] == 0) & (word_counts['JavaScript'] == 0)].sort_values(by='Shell', ascending=False)\n",
    "CPP_unique = word_counts[(word_counts['Shell'] == 0) & (word_counts['HTML'] == 0) &(word_counts['Python'] == 0) & (word_counts['CSS'] == 0) & (word_counts['C'] == 0) & (word_counts['Java'] == 0) & (word_counts['JavaScript'] == 0)].sort_values(by='C++', ascending=False)\n",
    "HTML_unique = word_counts[(word_counts['C++'] == 0) & (word_counts['Shell'] == 0) &(word_counts['Python'] == 0) & (word_counts['CSS'] == 0) & (word_counts['C'] == 0) & (word_counts['Java'] == 0) & (word_counts['JavaScript'] == 0)].sort_values(by='HTML', ascending=False)\n",
    "Python_unique = word_counts[(word_counts['C++'] == 0) & (word_counts['HTML'] == 0) &(word_counts['Shell'] == 0) & (word_counts['CSS'] == 0) & (word_counts['C'] == 0) & (word_counts['Java'] == 0) & (word_counts['JavaScript'] == 0)].sort_values(by='Python', ascending=False)\n",
    "CSS_unique = word_counts[(word_counts['C++'] == 0) & (word_counts['HTML'] == 0) &(word_counts['Python'] == 0) & (word_counts['Shell'] == 0) & (word_counts['C'] == 0) & (word_counts['Java'] == 0) & (word_counts['JavaScript'] == 0)].sort_values(by='CSS', ascending=False)\n",
    "C_unique = word_counts[(word_counts['C++'] == 0) & (word_counts['HTML'] == 0) &(word_counts['Python'] == 0) & (word_counts['CSS'] == 0) & (word_counts['Shell'] == 0) & (word_counts['Java'] == 0) & (word_counts['JavaScript'] == 0)].sort_values(by='C', ascending=False)\n",
    "Java_unique = word_counts[(word_counts['C++'] == 0) & (word_counts['HTML'] == 0) &(word_counts['Python'] == 0) & (word_counts['CSS'] == 0) & (word_counts['C'] == 0) & (word_counts['Shell'] == 0) & (word_counts['JavaScript'] == 0)].sort_values(by='Java', ascending=False)\n",
    "JavaScript_unique = word_counts[(word_counts['C++'] == 0) & (word_counts['HTML'] == 0) &(word_counts['Python'] == 0) & (word_counts['CSS'] == 0) & (word_counts['C'] == 0) & (word_counts['Java'] == 0) & (word_counts['Shell'] == 0)].sort_values(by='JavaScript', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "go_words = set(Shell_unique.index).union(set(CPP_unique.index))\n",
    "\n",
    "#go_words.union(set(CPP_unique.index))# + set(HTML_unique.index) + set(Python_unique.index) + set(CSS_unique.index) + set(C_unique.index) + set(Java_unique.index) + set(JavaScript_unique.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'architected',\n",
       " 'mro',\n",
       " 'intrusive',\n",
       " 'chintala',\n",
       " 'nyan',\n",
       " 'grpcio',\n",
       " 'forecast',\n",
       " 'oes',\n",
       " 'mnt',\n",
       " 'bulid',\n",
       " 'synsyn',\n",
       " 'tox',\n",
       " 'pass',\n",
       " 'taifeng',\n",
       " 'identity',\n",
       " 'assumes',\n",
       " 'kec',\n",
       " 'inference',\n",
       " 'dag',\n",
       " 'fnv',\n",
       " 'skim',\n",
       " 'bq',\n",
       " 'hide',\n",
       " 'airblade',\n",
       " 'twine',\n",
       " 'buildstatus',\n",
       " 'grateful',\n",
       " 'println',\n",
       " 'accelerates',\n",
       " 'softsign',\n",
       " 'terio',\n",
       " 'publicly',\n",
       " 'illinois',\n",
       " 'nfi',\n",
       " 'digest',\n",
       " 'affecting',\n",
       " 'restfulsoaprpc',\n",
       " 'rack',\n",
       " 'thcunn',\n",
       " 'pleap',\n",
       " 'inspecting',\n",
       " 'jui',\n",
       " 'classmethod',\n",
       " 'mecached',\n",
       " 'gregory',\n",
       " 'selectable',\n",
       " 'fp',\n",
       " 'elifefly',\n",
       " 'mutating',\n",
       " 'sslhttp',\n",
       " 'bradbury',\n",
       " 'sealed',\n",
       " 'ordered',\n",
       " 'pyyaml',\n",
       " 'unsqueeze',\n",
       " 'proper',\n",
       " 'alykhan',\n",
       " 'multithreaded',\n",
       " 'largely',\n",
       " 'semiprivate',\n",
       " 'myisam',\n",
       " 'vagrant',\n",
       " 'binaryconvolution',\n",
       " 'nv',\n",
       " 'xbmc',\n",
       " 'weightparametername',\n",
       " 'treelite',\n",
       " 'weidong',\n",
       " 'december',\n",
       " 'posixsystem',\n",
       " 'rich',\n",
       " 'seeking',\n",
       " 'taizilongxu',\n",
       " 'netroncntkdark',\n",
       " 'autogenerates',\n",
       " 'teach',\n",
       " 'cxx',\n",
       " 'cognitive',\n",
       " 'toe',\n",
       " 'natalia',\n",
       " 'relabel',\n",
       " 'amd',\n",
       " 'cffi',\n",
       " 'mlp',\n",
       " 'robin',\n",
       " 'landing',\n",
       " 'listnode',\n",
       " 'iq',\n",
       " 'unobtrusive',\n",
       " 'drastically',\n",
       " 'onnxruntime',\n",
       " 'beginner',\n",
       " 'kaitai',\n",
       " 'student',\n",
       " 'evaluates',\n",
       " 'nvtx',\n",
       " 'participating',\n",
       " 'typestrtoprotomap',\n",
       " 'zsh',\n",
       " 'segementation',\n",
       " 'thc',\n",
       " 'gemm',\n",
       " 'redditstatic',\n",
       " 'mst',\n",
       " 'consult',\n",
       " 'usa',\n",
       " 'unsupported',\n",
       " 'scp',\n",
       " 'cron',\n",
       " 'bz',\n",
       " 'variant',\n",
       " 'sequential',\n",
       " 'qiwei',\n",
       " 'sshd',\n",
       " 'innodbmvcc',\n",
       " 'wsdl',\n",
       " 'bede',\n",
       " 'kjyw',\n",
       " 'broaden',\n",
       " 'intercept',\n",
       " 'readability',\n",
       " 'itemgroup',\n",
       " 'contraction',\n",
       " 'surrounding',\n",
       " 'earth',\n",
       " 'packagereference',\n",
       " 'cgen',\n",
       " 'routed',\n",
       " 'locating',\n",
       " 'segfaults',\n",
       " 'readlines',\n",
       " 'knuthmorrispratt',\n",
       " 'lobster',\n",
       " 'pinning',\n",
       " 'simplicity',\n",
       " 'tf',\n",
       " 'ford',\n",
       " 'corrupt',\n",
       " 'simonsan',\n",
       " 'fedora',\n",
       " 'testeth',\n",
       " 'phusionpassenger',\n",
       " 'boundary',\n",
       " 'logtime',\n",
       " 'dog',\n",
       " 'dockerfiles',\n",
       " 'numerically',\n",
       " 'supertab',\n",
       " 'natively',\n",
       " 'savegames',\n",
       " 'deleteuri',\n",
       " 'blueviolet',\n",
       " 'getinstance',\n",
       " 'threshold',\n",
       " 'laid',\n",
       " 'complains',\n",
       " 'quantitative',\n",
       " 'consumption',\n",
       " 'enode',\n",
       " 'uninstalling',\n",
       " 'userid',\n",
       " 'workspce',\n",
       " 'pyvn',\n",
       " 'gitbooks',\n",
       " 'netopt',\n",
       " 'xianggao',\n",
       " 'mssdk',\n",
       " 'cookiesession',\n",
       " 'cudnn',\n",
       " 'vnpy',\n",
       " 'baboon',\n",
       " 'csproj',\n",
       " 'toc',\n",
       " 'bring',\n",
       " 'magma',\n",
       " 'zombie',\n",
       " 'gifs',\n",
       " 'plausible',\n",
       " 'anywhere',\n",
       " 'preparation',\n",
       " 'infinite',\n",
       " 'pmwiki',\n",
       " 'logger',\n",
       " 'aleth',\n",
       " 'publickey',\n",
       " 'gans',\n",
       " 'perf',\n",
       " 'zhi',\n",
       " 'enumerate',\n",
       " 'elu',\n",
       " 'kubeflow',\n",
       " 'kera',\n",
       " 'soumith',\n",
       " 'physicalcpu',\n",
       " 'poorly',\n",
       " 'travisci',\n",
       " 'chilamkurthy',\n",
       " 'authentic',\n",
       " 'theano',\n",
       " 'signal',\n",
       " 'haarcascades',\n",
       " 'encouraged',\n",
       " 'tracing',\n",
       " 'mld',\n",
       " 'branchpushfork',\n",
       " 'instruct',\n",
       " 'syslog',\n",
       " 'consitute',\n",
       " 'vundle',\n",
       " 'demand',\n",
       " 'weekly',\n",
       " 'recurrent',\n",
       " 'safely',\n",
       " 'xla',\n",
       " 'darray',\n",
       " 'simultaneously',\n",
       " 'flake',\n",
       " 'manylinux',\n",
       " 'hasattr',\n",
       " 'dispatcher',\n",
       " 'htpc',\n",
       " 'warpcap',\n",
       " 'customized',\n",
       " 'demystified',\n",
       " 'booting',\n",
       " 'exhaustive',\n",
       " 'complicated',\n",
       " 'mkfifomkfifo',\n",
       " 'hd',\n",
       " 'prone',\n",
       " 'dnns',\n",
       " 'originator',\n",
       " 'outperform',\n",
       " 'sigspatial',\n",
       " 'reaching',\n",
       " 'pp',\n",
       " 'bank',\n",
       " 'bugfix',\n",
       " 'osrm',\n",
       " 'pow',\n",
       " 'july',\n",
       " 'delimited',\n",
       " 'usability',\n",
       " 'alg',\n",
       " 'inspection',\n",
       " 'jukebox',\n",
       " 'kw',\n",
       " 'devtalk',\n",
       " 'playlist',\n",
       " 'poll',\n",
       " 'halide',\n",
       " 'ch',\n",
       " 'resnet',\n",
       " 'logotype',\n",
       " 'transifex',\n",
       " 'ib',\n",
       " 'logocolor',\n",
       " 'requesturlheaders',\n",
       " 'linuxunixsigal',\n",
       " 'tian',\n",
       " 'kaitaistream',\n",
       " 'bayeswitnesses',\n",
       " 'interoperate',\n",
       " 'arp',\n",
       " 'soahttp',\n",
       " 'surf',\n",
       " 'usingtcnower',\n",
       " 'cgiwsgi',\n",
       " 'reverted',\n",
       " 'openmw',\n",
       " 'turned',\n",
       " 'bybit',\n",
       " 'sharding',\n",
       " 'norm',\n",
       " 'ambitious',\n",
       " 'stillok',\n",
       " 'differentiate',\n",
       " 'cuteness',\n",
       " 'rearranges',\n",
       " 'rejected',\n",
       " 'antiga',\n",
       " 'acceleration',\n",
       " 'nproc',\n",
       " 'fortunately',\n",
       " 'insertion',\n",
       " 'aria',\n",
       " 'mistake',\n",
       " 'sysctl',\n",
       " 'haarcascade',\n",
       " 'rough',\n",
       " 'slideshow',\n",
       " 'serialization',\n",
       " 'restartable',\n",
       " 'proc',\n",
       " 'testable',\n",
       " 'zcr',\n",
       " 'getpost',\n",
       " 'overwritten',\n",
       " 'tie',\n",
       " 'hyperparameters',\n",
       " 'bmpiucu',\n",
       " 'axis',\n",
       " 'ints',\n",
       " 'pooling',\n",
       " 'multiplier',\n",
       " 'approximated',\n",
       " 'ownership',\n",
       " 'appetite',\n",
       " 'overlaydb',\n",
       " 'waiting',\n",
       " 'decrypt',\n",
       " 'testnet',\n",
       " 'instantly',\n",
       " 'shap',\n",
       " 'pygithub',\n",
       " 'injected',\n",
       " 'obvious',\n",
       " 'autograd',\n",
       " 'rr',\n",
       " 'grpc',\n",
       " 'philosophy',\n",
       " 'huan',\n",
       " 'saner',\n",
       " 'hhatto',\n",
       " 'incoming',\n",
       " 'sirver',\n",
       " 'openra',\n",
       " 'tickk',\n",
       " 'finley',\n",
       " 'compatability',\n",
       " 'concat',\n",
       " 'wchar',\n",
       " 'distributive',\n",
       " 'busy',\n",
       " 'connecthttp',\n",
       " 'eranif',\n",
       " 'rnn',\n",
       " 'libwxsqlite',\n",
       " 'netcoreapp',\n",
       " 'flatten',\n",
       " 'advancement',\n",
       " 'protorpc',\n",
       " 'chown',\n",
       " 'deeplearningbook',\n",
       " 'sstephenson',\n",
       " 'sx',\n",
       " 'readlinereadlines',\n",
       " 'shanghai',\n",
       " 'nerdcommenter',\n",
       " 'hitcount',\n",
       " 'winehq',\n",
       " 'jetpack',\n",
       " 'virtually',\n",
       " 'optimizedrnnstack',\n",
       " 'pregenerated',\n",
       " 'convolutiontranspose',\n",
       " 'peer',\n",
       " 'yaochengji',\n",
       " 'spacetodepth',\n",
       " 'consideration',\n",
       " 'flexibility',\n",
       " 'tx',\n",
       " 'headget',\n",
       " 'themessh',\n",
       " 'sopt',\n",
       " 'differentiable',\n",
       " 'imagescaler',\n",
       " 'killeen',\n",
       " 'cppcheck',\n",
       " 'stateless',\n",
       " 'proceeding',\n",
       " 'luckily',\n",
       " 'fanart',\n",
       " 'miller',\n",
       " 'torchscript',\n",
       " 'codec',\n",
       " 'corruption',\n",
       " 'dims',\n",
       " 'berlin',\n",
       " 'cbg',\n",
       " 'humaoli',\n",
       " 'fsl',\n",
       " 'buildingwxwidgetswin',\n",
       " 'myisaminnodb',\n",
       " 'diagnostics',\n",
       " 'simplifies',\n",
       " 'consulting',\n",
       " 'printed',\n",
       " 'edmonds',\n",
       " 'xieguanglei',\n",
       " 'rqucbdtuftjjiefw',\n",
       " 'finance',\n",
       " 'sfttech',\n",
       " 'precedence',\n",
       " 'unicorn',\n",
       " 'pcap',\n",
       " 'diameter',\n",
       " 'nice',\n",
       " 'enclosing',\n",
       " 'ethereum',\n",
       " 'oanda',\n",
       " 'suggested',\n",
       " 'tends',\n",
       " 'glue',\n",
       " 'dispatching',\n",
       " 'openwrtandroid',\n",
       " 'newcomer',\n",
       " 'advise',\n",
       " 'prefixing',\n",
       " 'rfcs',\n",
       " 'affected',\n",
       " 'evaluator',\n",
       " 'ervandew',\n",
       " 'subscribing',\n",
       " 'localization',\n",
       " 'mod',\n",
       " 'gitgutter',\n",
       " 'aggregation',\n",
       " 'distutils',\n",
       " 'concerned',\n",
       " 'profiler',\n",
       " 'nano',\n",
       " 'nix',\n",
       " 'uclibc',\n",
       " 'simhash',\n",
       " 'fin',\n",
       " 'taking',\n",
       " 'cntkv',\n",
       " 'nankezhishi',\n",
       " 'cudahostcxx',\n",
       " 'employed',\n",
       " 'po',\n",
       " 'valuesvalues',\n",
       " 'interior',\n",
       " 'practically',\n",
       " 'genexpr',\n",
       " 'increasingly',\n",
       " 'majutsushi',\n",
       " 'checker',\n",
       " 'postget',\n",
       " 'redistributable',\n",
       " 'pad',\n",
       " 'rohon',\n",
       " 'whuslei',\n",
       " 'sgd',\n",
       " 'targetframework',\n",
       " 'runit',\n",
       " 'syn',\n",
       " 'reduces',\n",
       " 'plugins',\n",
       " 'selling',\n",
       " 'browsed',\n",
       " 'award',\n",
       " 'familiarise',\n",
       " 'pypython',\n",
       " 'uphold',\n",
       " 'deserves',\n",
       " 'etf',\n",
       " 'lin',\n",
       " 'valuescounts',\n",
       " 'impolite',\n",
       " 'alban',\n",
       " 'revision',\n",
       " 'pythonjava',\n",
       " 'imperative',\n",
       " 'chen',\n",
       " 'dark',\n",
       " 'gateios',\n",
       " 'cntk',\n",
       " 'packing',\n",
       " 'enthusiastic',\n",
       " 'staticmethod',\n",
       " 'bdsp',\n",
       " 'ctastrategyapp',\n",
       " 'cur',\n",
       " 'julycoding',\n",
       " 'nip',\n",
       " 'subsection',\n",
       " 'powershell',\n",
       " 'eepurl',\n",
       " 'sxplugin',\n",
       " 'autocompletion',\n",
       " 'addons',\n",
       " 'leveldb',\n",
       " 'hw',\n",
       " 'formatter',\n",
       " 'supposed',\n",
       " 'variadic',\n",
       " 'implies',\n",
       " 'wxgtk',\n",
       " 'gru',\n",
       " 'deepcopy',\n",
       " 'backpropagation',\n",
       " 'patented',\n",
       " 'resaving',\n",
       " 'hogwild',\n",
       " 'latestversion',\n",
       " 'opus',\n",
       " 'prevents',\n",
       " 'segfault',\n",
       " 'boilerplate',\n",
       " 'ultisnips',\n",
       " 'clock',\n",
       " 'genie',\n",
       " 'ramips',\n",
       " 'sarofeen',\n",
       " 'screw',\n",
       " 'perhaps',\n",
       " 'discport',\n",
       " 'dusty',\n",
       " 'outputdim',\n",
       " 'libsqlite',\n",
       " 'facilitates',\n",
       " 'coursera',\n",
       " 'substitution',\n",
       " 'costanza',\n",
       " 'netron',\n",
       " 'lexicographic',\n",
       " 'gross',\n",
       " 'replaying',\n",
       " 'podspec',\n",
       " 'purge',\n",
       " 'bundler',\n",
       " 'searched',\n",
       " 'slicing',\n",
       " 'datatype',\n",
       " 'assertion',\n",
       " 'plus',\n",
       " 'scan',\n",
       " 'lean',\n",
       " 'kid',\n",
       " 'trainer',\n",
       " 'locate',\n",
       " 'parity',\n",
       " 'operationalize',\n",
       " 'scheduling',\n",
       " 'consultancy',\n",
       " 'lucy',\n",
       " 'openrct',\n",
       " 'fep',\n",
       " 'wxmac',\n",
       " 'appends',\n",
       " 'showmaximized',\n",
       " 'meanvariancenormalization',\n",
       " 'reproducible',\n",
       " 'relocation',\n",
       " 'coinchange',\n",
       " 'sigmoid',\n",
       " 'mvcc',\n",
       " 'shaders',\n",
       " 'imagewidth',\n",
       " 'rabin',\n",
       " 'vnconda',\n",
       " 'ons',\n",
       " 'intrusively',\n",
       " 'jobbole',\n",
       " 'cntklib',\n",
       " 'moving',\n",
       " 'winning',\n",
       " 'layernormalization',\n",
       " 'wyh',\n",
       " 'mysqlinnodbmvcc',\n",
       " 'industry',\n",
       " 'passenger',\n",
       " 'meant',\n",
       " 'urlliburllib',\n",
       " 'rocm',\n",
       " 'prelu',\n",
       " 'luca',\n",
       " 'exporter',\n",
       " 'brightbox',\n",
       " 'describe',\n",
       " 'ndp',\n",
       " 'guillaume',\n",
       " 'staticmethodclassmethod',\n",
       " 'lstm',\n",
       " 'lenth',\n",
       " 'modding',\n",
       " 'metaclass',\n",
       " 'hashrate',\n",
       " 'changelogs',\n",
       " 'introspection',\n",
       " 'noted',\n",
       " 'rail',\n",
       " 'mkl',\n",
       " 'gan',\n",
       " 'pythondocs',\n",
       " 'accepted',\n",
       " 'topk',\n",
       " 'producer',\n",
       " 'blas',\n",
       " 'rbenv',\n",
       " 'alist',\n",
       " 'zshenv',\n",
       " 'ppa',\n",
       " 'sasank',\n",
       " 'qapp',\n",
       " 'pretrainedmodels',\n",
       " 'dpkg',\n",
       " 'listing',\n",
       " 'authoring',\n",
       " 'unsigned',\n",
       " 'incremented',\n",
       " 'orm',\n",
       " 'multilevel',\n",
       " 'afernandez',\n",
       " 'lutzroeder',\n",
       " 'tora',\n",
       " 'terryma',\n",
       " 'pragma',\n",
       " 'lballabio',\n",
       " 'lnk',\n",
       " 'batch',\n",
       " 'mmlspark',\n",
       " 'gimelshein',\n",
       " 'abcd',\n",
       " 'accidental',\n",
       " 'intelligence',\n",
       " 'svn',\n",
       " 'pythonz',\n",
       " 'consumed',\n",
       " 'salt',\n",
       " 'mwlp',\n",
       " 'mainengine',\n",
       " 'optionshead',\n",
       " 'discov',\n",
       " 'libosrm',\n",
       " 'zhuanlan',\n",
       " 'pyobject',\n",
       " 'mpi',\n",
       " 'everybody',\n",
       " 'aforementioned',\n",
       " 'sysml',\n",
       " 'ngx',\n",
       " 'edcbg',\n",
       " 'undocumented',\n",
       " 'dnn',\n",
       " 'improves',\n",
       " 'tedious',\n",
       " 'dennis',\n",
       " 'allocator',\n",
       " 'usermod',\n",
       " 'hardest',\n",
       " 'administer',\n",
       " 'tape',\n",
       " 'paperwork',\n",
       " 'worry',\n",
       " 'rpi',\n",
       " 'shot',\n",
       " 'sunflyer',\n",
       " 'unlike',\n",
       " 'maxdepth',\n",
       " 'caffe',\n",
       " 'hierarchy',\n",
       " 'staging',\n",
       " 'ackack',\n",
       " 'ethminer',\n",
       " 'glibcxx',\n",
       " 'mitm',\n",
       " 'gzipfile',\n",
       " 'pushrelabel',\n",
       " 'rigorous',\n",
       " 'dcba',\n",
       " 'abide',\n",
       " 'processor',\n",
       " 'thnn',\n",
       " 'toolset',\n",
       " 'cascadeclassifier',\n",
       " 'libgtk',\n",
       " 'pushed',\n",
       " 'typeerror',\n",
       " 'eldfkm',\n",
       " 'demograph',\n",
       " 'bdgcc',\n",
       " 'ceo',\n",
       " 'libclang',\n",
       " 'listsets',\n",
       " 'joe',\n",
       " 'errorwarning',\n",
       " 'decorator',\n",
       " 'kodi',\n",
       " 'reaped',\n",
       " 'ud',\n",
       " 'oneshot',\n",
       " 'llf',\n",
       " 'transpose',\n",
       " 'hughperkins',\n",
       " 'cxxd',\n",
       " 'skynet',\n",
       " 'pyhton',\n",
       " 'uriputput',\n",
       " 'nearest',\n",
       " 'refcnt',\n",
       " 'fixits',\n",
       " 'observe',\n",
       " 'translates',\n",
       " 'stackoverflowpython',\n",
       " 'concluded',\n",
       " 'btchenguang',\n",
       " 'explainer',\n",
       " 'onto',\n",
       " 'shutting',\n",
       " 'bellman',\n",
       " 'gps',\n",
       " 'frame',\n",
       " 'ctp',\n",
       " 'mixing',\n",
       " 'spatial',\n",
       " 'opensage',\n",
       " 'samana',\n",
       " 'karp',\n",
       " 'lerer',\n",
       " 'trigonometric',\n",
       " 'tba',\n",
       " 'posturllib',\n",
       " 'ietf',\n",
       " 'lastsuccessfulbuild',\n",
       " 'workload',\n",
       " 'personnel',\n",
       " 'swappairs',\n",
       " 'chenxofhit',\n",
       " 'ethcap',\n",
       " 'jetson',\n",
       " 'anker',\n",
       " 'si',\n",
       " 'releasenotes',\n",
       " 'managed',\n",
       " 'okexs',\n",
       " 'kirankotari',\n",
       " 'gc',\n",
       " 'notable',\n",
       " 'facility',\n",
       " 'xmuliang',\n",
       " 'driving',\n",
       " 'zhangyou',\n",
       " 'converter',\n",
       " 'ruanyifeng',\n",
       " 'vcvars',\n",
       " 'ob',\n",
       " 'anyway',\n",
       " 'shape',\n",
       " 'bg',\n",
       " 'explicitly',\n",
       " 'reusable',\n",
       " 'softmax',\n",
       " 'highlight',\n",
       " 'contrib',\n",
       " 'worked',\n",
       " 'unixbsd',\n",
       " 'statedb',\n",
       " 'csrf',\n",
       " 'postgres',\n",
       " 'msvc',\n",
       " 'dask',\n",
       " 'devinstall',\n",
       " 'fugitive',\n",
       " 'ke',\n",
       " 'opengl',\n",
       " 'afoo',\n",
       " 'saving',\n",
       " 'thoroughly',\n",
       " 'midpivot',\n",
       " 'regenerate',\n",
       " 'reader',\n",
       " 'mutable',\n",
       " 'skiplist',\n",
       " 'anybody',\n",
       " 'lc',\n",
       " 'scrooloose',\n",
       " 'bling',\n",
       " 'describing',\n",
       " 'moddable',\n",
       " 'guolin',\n",
       " 'germany',\n",
       " 'cnns',\n",
       " 'aop',\n",
       " 'useless',\n",
       " 'gwvo',\n",
       " 'xtp',\n",
       " 'conclusion',\n",
       " 'lazily',\n",
       " 'blender',\n",
       " 'dimension',\n",
       " 'millisec',\n",
       " 'directed',\n",
       " 'division',\n",
       " 'yg',\n",
       " 'libtbb',\n",
       " 'forgery',\n",
       " 'stopgradient',\n",
       " 'vcs',\n",
       " 'researcher',\n",
       " 'bias',\n",
       " 'gameworks',\n",
       " 'utilized',\n",
       " 'copylefted',\n",
       " 'rp',\n",
       " 'vetter',\n",
       " 'kwargs',\n",
       " 'war',\n",
       " 'exited',\n",
       " 'prepressing',\n",
       " 'libbz',\n",
       " 'dijkstra',\n",
       " 'stretch',\n",
       " 'mn',\n",
       " 'subcommand',\n",
       " 'sft',\n",
       " 'purpleroc',\n",
       " 'realize',\n",
       " 'gchanan',\n",
       " 'decouple',\n",
       " 'jpmml',\n",
       " 'rolling',\n",
       " 'yaflandia',\n",
       " 'applier',\n",
       " 'coinsused',\n",
       " 'yyuu',\n",
       " 'deploying',\n",
       " 'opaque',\n",
       " 'pythonyield',\n",
       " 'yml',\n",
       " 'warmup',\n",
       " 'monitor',\n",
       " 'cvoid',\n",
       " 'tailor',\n",
       " 'scalar',\n",
       " 'relying',\n",
       " 'editing',\n",
       " 'guolinke',\n",
       " 'op',\n",
       " 'rubygems',\n",
       " 'wei',\n",
       " 'pop',\n",
       " 'raison',\n",
       " 'luxen',\n",
       " 'notorious',\n",
       " 'acmid',\n",
       " 'unbuntu',\n",
       " 'ordinary',\n",
       " 'macosx',\n",
       " 'pyenv',\n",
       " 'cabbage',\n",
       " 'violation',\n",
       " 'autoclose',\n",
       " 'skin',\n",
       " 'ccmake',\n",
       " 'attachment',\n",
       " 'pmml',\n",
       " 'advertised',\n",
       " 'ankane',\n",
       " 'rnns',\n",
       " 'boring',\n",
       " 'rf',\n",
       " 'libstdc',\n",
       " 'impl',\n",
       " 'bib',\n",
       " 'backwards',\n",
       " 'mdassets',\n",
       " 'struggling',\n",
       " 'sit',\n",
       " 'everyday',\n",
       " 'appspot',\n",
       " 'april',\n",
       " 'torch',\n",
       " 'kn',\n",
       " 'nginxmysqlphpredisnagios',\n",
       " 'ropsten',\n",
       " 'patchput',\n",
       " 'programfiles',\n",
       " 'thin',\n",
       " 'pythonlist',\n",
       " 'ops',\n",
       " 'convolves',\n",
       " 'abcde',\n",
       " 'repack',\n",
       " 'sigaction',\n",
       " 'chruby',\n",
       " 'arxiv',\n",
       " 'simnow',\n",
       " 'getget',\n",
       " 'ord',\n",
       " 'sjf',\n",
       " 'mipsel',\n",
       " 'libwxbase',\n",
       " 'twapsnipericebergbestlimit',\n",
       " 'demosrc',\n",
       " 'contrast',\n",
       " 'fifo',\n",
       " 'gl',\n",
       " 'cnblogs',\n",
       " 'pyd',\n",
       " 'semantic',\n",
       " 'pytorch',\n",
       " 'strives',\n",
       " 'barrier',\n",
       " 'battleground',\n",
       " 'hope',\n",
       " 'jl',\n",
       " 'networksettings',\n",
       " 'selec',\n",
       " 'paszke',\n",
       " 'crossing',\n",
       " 'seq',\n",
       " 'respective',\n",
       " 'convtranspose',\n",
       " 'bitsgd',\n",
       " 'depthtospace',\n",
       " 'biggerafterpivot',\n",
       " 'eg',\n",
       " 'differentiation',\n",
       " 'tan',\n",
       " 'encrypt',\n",
       " 'xrange',\n",
       " 'clearer',\n",
       " 'fnusv',\n",
       " 'temp',\n",
       " 'multibyte',\n",
       " 'shirt',\n",
       " 'netroncntklight',\n",
       " 'classname',\n",
       " 'mrlevo',\n",
       " 'toolkits',\n",
       " 'hecking',\n",
       " 'unixipc',\n",
       " 'rbtree',\n",
       " 'arbitrarily',\n",
       " 'bcrypy',\n",
       " 'warn',\n",
       " 'traceback',\n",
       " 'straightforward',\n",
       " 'child',\n",
       " 'attributeerror',\n",
       " 'deduction',\n",
       " 'timing',\n",
       " 'tiger',\n",
       " 'participate',\n",
       " 'binarized',\n",
       " 'polished',\n",
       " 'tradervn',\n",
       " 'isolation',\n",
       " 'entertainment',\n",
       " 'wstring',\n",
       " 'sequentialconvolution',\n",
       " 'vswhere',\n",
       " 'simplemnist',\n",
       " 'mysingleton',\n",
       " 'incorporated',\n",
       " 'catch',\n",
       " 'feliciafay',\n",
       " 'convolutional',\n",
       " 'overhaul',\n",
       " 'selecting',\n",
       " 'geographic',\n",
       " 'daemonize',\n",
       " 'onnxmltools',\n",
       " 'asinh',\n",
       " 'rhel',\n",
       " 'colon',\n",
       " 'lrn',\n",
       " 'reduction',\n",
       " 'oftc',\n",
       " 'miscellaneous',\n",
       " 'toolsets',\n",
       " 'destruction',\n",
       " 'julia',\n",
       " 'scaler',\n",
       " 'massa',\n",
       " 'couch',\n",
       " 'nforum',\n",
       " 'mined',\n",
       " 'accessory',\n",
       " 'bdist',\n",
       " 'inputdim',\n",
       " 'unpooling',\n",
       " 'oschina',\n",
       " 'ming',\n",
       " 'piwheels',\n",
       " 'customization',\n",
       " 'javascriptxmlhttprequestcors',\n",
       " 'param',\n",
       " 'msl',\n",
       " 'shoulder',\n",
       " 'imageheight',\n",
       " 'auditwheel',\n",
       " 'rev',\n",
       " 'webjs',\n",
       " 'phone',\n",
       " 'msc',\n",
       " 'pythonk',\n",
       " 'cpueval',\n",
       " 'dilation',\n",
       " 'solves',\n",
       " 'breadth',\n",
       " 'miniconda',\n",
       " 'pythonweb',\n",
       " 'cii',\n",
       " 'magical',\n",
       " 'propertygroup',\n",
       " 'dcmake',\n",
       " ...}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "go_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
